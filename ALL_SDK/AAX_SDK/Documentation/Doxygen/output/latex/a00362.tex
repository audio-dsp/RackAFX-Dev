\hypertarget{a00362}{}\section{T\+I Guide}
\label{a00362}\index{T\+I Guide@{T\+I Guide}}
How to write A\+A\+X plug-\/ins for Avid\textquotesingle{}s T\+I-\/based platforms. 

\hypertarget{a00362_aax_ti_guide_contents}{}\subsection{Contents}\label{a00362_aax_ti_guide_contents}
\begin{DoxyItemize}
\item \hyperlink{a00362_aax_ti_guide_00_overview_of_ti_algorithms}{Overview of T\+I Algorithms in A\+A\+X} \item \hyperlink{a00362_aax_ti_guide_01_the_hdx_platform}{The H\+D\+X Platform} \item \hyperlink{a00362_aax_ti_guide_03_requirements_for_ti_plug_ins}{Requirements for T\+I Plug-\/\+Ins} \item \hyperlink{a00362_aax_ti_guide_04_ti_development_tools}{T\+I Development Tools} \item \hyperlink{a00362_aax_ti_guide_05_common_issues_with_ti_development}{Common Issues with T\+I Development} \item \hyperlink{a00362_aax_ti_guide_06_ti_optimization_guide}{T\+I Optimization Guide} \item \hyperlink{a00362_aax_ti_guide_07_error_codes}{Error Codes}\end{DoxyItemize}
 \hypertarget{a00362_aax_ti_guide_00_overview_of_ti_algorithms}{}\subsection{Overview of T\+I Algorithms in A\+A\+X}\label{a00362_aax_ti_guide_00_overview_of_ti_algorithms}
Avid\textquotesingle{}s hardware-\/accelerated audio systems allow A\+A\+X plug-\/ins to offload their real-\/time processing tasks to a dedicated processor, guaranteeing reliable performance at ultra-\/low latency. Avid\textquotesingle{}s T\+I-\/based products utilize Texas Instruments D\+S\+P chips to host plug-\/ins in a managed shell environment.

The A\+A\+X host handles all system-\/level communications and resources on the D\+S\+P and provides a consistent A\+P\+I to manage communication between the plug-\/in\textquotesingle{}s real-\/time algorithm and its other components. This design allows A\+A\+X plug-\/ins to use the same communication methods whether they are running natively, on a T\+I-\/based accelerated system, or in some other distributed environment.

Each A\+A\+X plug-\/in contains a real-\/time algorithm callback. For T\+I D\+S\+P-\/based platforms, this callback is compiled into a relocatable E\+L\+F D\+L\+L. This library is loaded onto the appropriate D\+S\+P by the host, and may share the D\+S\+P with other plug-\/ins if the host determines that the required system resources are available. 

 \hypertarget{a00362_aax_ti_guide_01_the_hdx_platform}{}\subsection{The H\+D\+X Platform}\label{a00362_aax_ti_guide_01_the_hdx_platform}
H\+D\+X is Avid\textquotesingle{}s P\+C\+I-\/based core mixer and plug-\/in accelerator platform. Each H\+D\+X card includes 18 T\+I C6727 D\+S\+Ps, each clocked at 350 M\+Hz. These D\+S\+Ps utilize a 32-\/bit floating-\/point architecture, with the option to perform 64-\/bit double-\/precision operations at some performance cost.

\hypertarget{a00362_subsection__dsp_characteristics_instruction_processing}{}\subsubsection{D\+S\+P characteristics\+: instruction processing}\label{a00362_subsection__dsp_characteristics_instruction_processing}
 The C6727 D\+S\+P utilizes a V\+L\+I\+W architecture and contains dual data paths. Each data path includes four independent functional units, so the D\+S\+P can accommodate up to 8 parallel instructions per cycle. To take advantage of this architecture, the T\+I compiler relies heavily on instruction pipelining for optimization.

In order to realize the maximum possible performance benefit from this architecture, H\+D\+X uses a four-\/sample processing quantum. Plug-\/ins that require additional processing time per callback, e.\+g. to mitigate the overhead cost of the chip\textquotesingle{}s D\+M\+A facilities, may optionally request a 16, 32, or 64-\/sample quantum. But please note that at higher block sizes, the number of potential I/\+O channels available to plug-\/ins on a chip will be reduced. By guaranteeing that each algorithm will be called with a consistent buffer size, the T\+I compiler is able to properly account for any possible iterative instruction pipelining, resulting in large performance gains.

\begin{DoxyRefDesc}{Host Compatibility Notes}
\item[\hyperlink{a00380__compatibility_notes000020}{Host Compatibility Notes}]32 and 64-\/sample quantum is available in Pro Tools 10.\+2 and higher\end{DoxyRefDesc}


\hypertarget{a00362_subsection__dsp_characteristics_memory}{}\subsubsection{D\+S\+P characteristics\+: memory}\label{a00362_subsection__dsp_characteristics_memory}
 Each D\+S\+P on the H\+D\+X platform includes 16 M\+B of external R\+A\+M and 256 k\+B of internal R\+A\+M. The D\+S\+P has the ability to execute code from either internal or external R\+A\+M, though the real-\/time performance cost of external R\+A\+M accesses is significant. The chip\textquotesingle{}s internal R\+A\+M is addressable at the core clock rate.

Each D\+S\+P also has a program cache of 32 k\+B. Plug-\/in code is loaded into this cache from internal memory, so for best performance your plug-\/in should not use more than 32 k\+B for its program code. You can look at the C\+C\+S-\/generated .map file to find your plug-\/in\textquotesingle{}s program code size.

\hypertarget{a00362_subsubsection__sdram_performance_}{}\paragraph{S\+D\+R\+A\+M performance}\label{a00362_subsubsection__sdram_performance_}
 Asynchronous access to data in the C6727\textquotesingle{}s S\+D\+R\+A\+M is very slow, requiring 50 cycles/word to read and 15 cycles/word to write. This is primarily due to clock domain bridging, lack of data caching, and the fact that data from the core is given a low priority in order to avoid stalling real-\/time D\+M\+A transfers. \hypertarget{a00362_subsubsection__executing_program_code_from_external_memory_}{}\paragraph{Executing program code from external memory}\label{a00362_subsubsection__executing_program_code_from_external_memory_}
 The T\+I C6727 supports executing program code from external memory. When executing from uncached external memory, expect cycle counts to increase by a factor of 4x to 5x compared with the equivalent internal-\/memory code. Assuming that no cache thrashing occurs, subsequent calls will be cached and thus the program\textquotesingle{}s location in either external or internal memory will produce similar cycle counts.

\begin{DoxyNote}{Note}
The C\+C\+Sv4 Profiler contains a bug that produces incorrect cycle counts for cached external-\/memory program code. Therefore, when gathering cycle count data for a plug-\/in that stores its program data in external memory, an R\+T\+I-\/based timing method should be used.
\end{DoxyNote}
\hypertarget{a00362_subsection__system_characteristics_dsphost_data_transfers}{}\subsubsection{System characteristics\+: D\+S\+P/host data transfers}\label{a00362_subsection__system_characteristics_dsphost_data_transfers}
 Plug-\/ins loaded onto the H\+D\+X platform may transfer arbitrarily large data blocks between the D\+S\+P and the host, within the limits of available D\+S\+P memory and system bandwidth.

\hypertarget{a00362_subsubsection__dsphost_bandwidth_}{}\paragraph{D\+S\+P/host bandwidth}\label{a00362_subsubsection__dsphost_bandwidth_}
 The recommended upper limit for D\+S\+P/host data transfer requests in an individual plug-\/in is 10 M\+B/s, divided by the maximum number of plug-\/in instances that will run on a single chip. On the H\+D\+X card, D\+S\+Ps are wired to the F\+P\+G\+A crossbar in groups of three, with a data bandwidth of approximately 67 M\+B/s for each group. The overall system bandwidth for each D\+S\+P is therefore approximately 20 M\+B/s. This bandwidth is shared by all data reads and writes, including custom data transfer requests.

H\+D\+X does not include any explicit plug-\/in bandwidth limiting constraints. If a plug-\/in\textquotesingle{}s data transfer requests bump up against the physical bandwidth limit for the system then this will delay the blocking data transfer request on the host, as the transfer will be held off for higher-\/priority operations on the D\+S\+P, and may also delay automation data from reaching other plug-\/ins on the three affected D\+S\+Ps.

\hypertarget{a00362_subsubsection__dsphost_data_transfer_characteristics_}{}\paragraph{D\+S\+P/host data transfer characteristics}\label{a00362_subsubsection__dsphost_data_transfer_characteristics_}
 The minimum data transfer size for all host-\/to-\/\+D\+S\+P communications in H\+D\+X is 128 bytes. This limit applies to all host-\/to-\/\+D\+S\+P data transfers, including data sent to buffered ports, unbuffered ports, and private data blocks (via the A\+A\+X Direct Data interface.)

Since each transfer has a minimum size of 128 bytes, the use of many small packets does not increase transfer efficiency or save system bandwidth. Quite the opposite\+: updating a single 64-\/byte packet would require less bandwidth than updating two 4-\/byte packets in an H\+D\+X system, since the former would require only one 128-\/byte transfer while the latter will require two.

\hypertarget{a00362_subsection__ti_shell_characteristics_memory_allocation}{}\subsubsection{T\+I Shell characteristics\+: Memory allocation}\label{a00362_subsection__ti_shell_characteristics_memory_allocation}
 \hypertarget{a00362_subsubsection__memory_resource_availability_}{}\paragraph{Memory resource availability}\label{a00362_subsubsection__memory_resource_availability_}
 The T\+I Shell code that is loaded onto each D\+S\+P uses approximately 56 k\+B of internal memory, leaving 200 k\+B of internal memory per D\+S\+P. This memory is shared between the plug-\/ins on the chip and holds the plug-\/ins\textquotesingle{} code and data, per-\/instance blocks declared in Describe(), and instance overhead.

As a general guideline, plug-\/in instances should not use more than 200 / n k\+B of internal memory, where n is the number of instances of your plug-\/in that will run on a single chip based on its cycle count requirements.

\hypertarget{a00362_subsubsection__shared_and_perinstance_memory_allocation_}{}\paragraph{Shared and per-\/instance memory allocation}\label{a00362_subsubsection__shared_and_perinstance_memory_allocation_}
 When a plug-\/in instance is created on a D\+S\+P, its program code is loaded onto that D\+S\+P. This copy of the program code is then re-\/used for all subsequent instances of the effect that are loaded onto the D\+S\+P. Static and global data are also shared between all instances of an effect on the D\+S\+P. Other allocations, such as coefficient and private data blocks, are per-\/instance.

\begin{DoxyRefDesc}{Host Compatibility Notes}
\item[\hyperlink{a00380__compatibility_notes000021}{Host Compatibility Notes}]Beginning in Pro Tools 11, A\+A\+X D\+S\+P algorithms also support optional temporary data spaces that can be described in the Describe module and are shared among all instances on a D\+S\+P. This is an alternative to declaring large data blocks on the stack for better memory management and to prevent stack overflows. Please refer to \hyperlink{a00088_ad8daad601b60fdbd6134fe0c8faa2fc4}{A\+A\+X\+\_\+\+I\+Component\+Descriptor\+::\+Add\+Temporary\+Data()} for usage instructions.\end{DoxyRefDesc}


\hypertarget{a00362_subsubsection__placing_data_into_external_memory_}{}\paragraph{Placing data into external memory}\label{a00362_subsubsection__placing_data_into_external_memory_}
 An A\+A\+X plug-\/in may optionally request that its private data or program code be placed into external memory. Because standard access calls to the D\+S\+P\textquotesingle{}s S\+D\+R\+A\+M are very slow, it is strongly recommended that all of a plug-\/in\textquotesingle{}s real-\/time data be placed in internal R\+A\+M, and the T\+I Shell will load a plug-\/in\textquotesingle{}s program code and all private plug-\/in data blocks into internal memory by default.

Requesting more than 256 k\+B of data in internal memory for plug-\/in data plus the memory required by the T\+I Shell will lead to undefined behavior, so it is important to explicitly request external memory for plug-\/in data when appropriate.

For private data blocks that should be loaded into external memory, use the \hyperlink{a00206_a9f1ef2cb64daf30eaf145dfbb8cd0d00a75aef62fea40f9bba18502add99130b2}{A\+A\+X\+\_\+e\+Private\+Data\+Options\+\_\+\+External} flag when calling \hyperlink{a00088_a125949841a13e97ff93fa321f2050433}{A\+A\+X\+\_\+\+I\+Component\+Descriptor\+::\+Add\+Private\+Data()} . This flag will be ignored by the host, so Native A\+A\+X plug-\/ins will have the same functionality with or without this property.

To load program code, static data, or global variables into external memory, use the {\ttfamily T\+I S\+E\+C\+T\+I\+O\+N} pragmas. For example, {\ttfamily \#pragma C\+O\+D\+E\+\_\+\+S\+E\+C\+T\+I\+O\+N\+\_\+(\char`\"{}.\+extmem\char`\"{})} can be used before function definitions that are either initialization code, or infrequently used background code. For static variables, use {\ttfamily \#pragma D\+A\+T\+A\+\_\+\+S\+E\+C\+T\+I\+O\+N\+\_\+(\char`\"{}.\+extmemdata\char`\"{})} before each variable definition.

\hypertarget{a00362_subsubsection__dma_support_}{}\paragraph{D\+M\+A support}\label{a00362_subsubsection__dma_support_}
 Because of the slower access time of external R\+A\+M, you should consider using a \hyperlink{a00340}{D\+M\+A transfer} for recurring transfers, and possibly even for larger one-\/time transfers. This is of particular relevance for data reads, which must traverse the various clock domains and priority switches twice (address send, and then data return.)

The T\+I Shell supports three D\+M\+A modes\+: Scatter (for transfers from internal to external memory), Gather (for transfers from external to internal memory), and Burst (contiguous block copies). The Scatter mode can accomplish transfer speeds of up to 2.\+1 D\+S\+P cycles/byte transferred, while the Gather mode can accomplish 2.\+7 cycles/byte transferred.

The Scatter and Gather D\+M\+A facilities use a linear buffer for internal memory and a F\+I\+F\+O for external memory. It is possible to transfer to or from multiple offsets within the external memory F\+I\+F\+O using an offset table, which can contain up to 65,536 (2Ì‚16) entries. The offset (burst) length may be 4, 8, 16, 32, or 64 bytes long.

The T\+I Shell also supports a Burst D\+M\+A mode which implements linear data reads or writes.

For more information on D\+M\+A support and for example code, see {\ttfamily \textbackslash{}Example\+Plug\+Ins\textbackslash{}Demo\+Gain\+\_\+\+D\+M\+A} in the S\+D\+K.

\hypertarget{a00362_subsection__ti_shell_characteristics_data_packet_services}{}\subsubsection{T\+I Shell characteristics\+: Data packet services}\label{a00362_subsection__ti_shell_characteristics_data_packet_services}
 In addition to supporting direct transfers of arbitrary data via D\+M\+A, the T\+I Shell also supports a packetized data delivery mechanism for host-\/to-\/\+D\+S\+P data transfers. Packet delivery ports may be either unbuffered or buffered, and are described using the \hyperlink{a00206_ab5677b173ad8647c24d34d28272d11fc}{A\+A\+X\+\_\+\+E\+Data\+In\+Port\+Type} parameter in \hyperlink{a00131_a76ab9a0bef4cd6b6aa7144ed1adbe8a3}{A\+A\+X\+\_\+\+V\+Component\+Descriptor\+::\+Add\+Data\+In\+Port()}.

\hypertarget{a00362_subsubsection__unbuffered_ports_}{}\paragraph{Unbuffered ports}\label{a00362_subsubsection__unbuffered_ports_}
 Unbuffered ports use a straightforward implementation that delivers posted packets to the algorithm as soon as possible. In an unbuffered port, newer packets will always override older packets. Therefore, an algorithm may not receive every packet that was posted to an unbuffered port, but it will always receive the most up-\/to-\/date information possible.

Unbuffered ports deliver their data without blocking or synchronizing with the algorithm\textquotesingle{}s execution. Although bus arbitration guarantees that a read from the algorithm callback will not occur in the middle of a write from the host, it is important to note that the data in an unbuffered port may change during algorithm execution.

\hypertarget{a00362_subsubsection__buffered_ports_}{}\paragraph{Buffered ports}\label{a00362_subsubsection__buffered_ports_}
 Buffered data ports store incoming packets in a host-\/managed queue. This queue acts as a buffer and provides the host with more flexibility in how it delivers packets. A key feature of buffered data ports is that new data will never be delivered to these ports during algorithm execution.

The behavior of buffered data ports varies depending on the host platform. In H\+D\+X plug-\/ins, Buffered data ports use a F\+I\+F\+O to queue data packets as they are posted. New packets are dequeued and delivered to the algorithm individually, with the next packet arriving before each algorithm render callback.

\hypertarget{a00362_subsubsection__data_port_overhead_and_restrictions_}{}\paragraph{Data port overhead and restrictions}\label{a00362_subsubsection__data_port_overhead_and_restrictions_}
 Each H\+D\+X D\+S\+P supports a maximum of 164 buffered data ports, which matches the maximum I/\+O limit for each D\+S\+P. System overhead costs associated with using the on-\/chip packet services are as follows\+: \subparagraph*{Memory Overhead}

 
\begin{DoxyItemize}
\item The memory overhead for an unbuffered data port is simply the size of the data packet.  
\item This D\+S\+P memory overhead for a buffered data port is two times the size of the data packet. A large ($>$100-\/element) packet queue is also allocated on the host.  
\end{DoxyItemize}\subparagraph*{C\+P\+U overhead}

 Unbuffered ports do not incur any additional C\+P\+U overhead.

Individual buffered ports do incur non-\/trivial C\+P\+U overhead. For example, in Pro Tools 10.\+2 each buffered port requires 5 cycles of overhead per render callback. This overhead can quickly add up in \char`\"{}small\char`\"{} plug-\/ins that contain many buffered data ports. Therefore, we strongly recommend that plug-\/ins use consolidated coefficient packets when possible in order to minimize this overhead. This optimization can result in large performance gains for callbacks that require 1000 or fewer cycles to operate.

The trade-\/off of this optimization is that more work ends up being done on the host and more data must be transmitted to the algorithm, since the entire coefficient packet must be re-\/calculated and re-\/sent every time any of its input parameters change. This is usually beneficial trade-\/off to make, especially given the 128-\/byte per-\/transfer minimum discussed above. However, care must be taken in extreme cases such as when packet delivery threatens to bump up against the maximum recommended bandwidth for host/\+D\+S\+P data transfers.

\hypertarget{a00362_subsection__ti_shell_characteristics_instance_allocation}{}\subsubsection{T\+I Shell characteristics\+: Instance allocation}\label{a00362_subsection__ti_shell_characteristics_instance_allocation}
 \hypertarget{a00362_subsubsection__multishell_packing_}{}\paragraph{Multi-\/shell packing}\label{a00362_subsubsection__multishell_packing_}
 With a few exceptions, A\+A\+X D\+S\+P plug-\/ins will share D\+S\+Ps with other plug-\/ins. This occurs transparently to the plug-\/in due to the fact that all system resource management is handled by the T\+I Shell.

When a new plug-\/in instance is created, the T\+I Shell and A\+A\+X host will attempt to intelligently allocate it to a D\+S\+P based on both memory and C\+P\+U resource requirements. If one plug-\/in on the chip requires a large amount of memory and very few processing cycles, it may be packed with another plug-\/in that does not require much memory but that is very C\+P\+U intensive.

The exceptions to this model are plug-\/ins that use D\+M\+A, register for a background processing callback, register a maximum number of instances per chip or use a processor affinity constraint when reporting C\+P\+U requirements. With the exception of a processor affinity, these plug-\/ins will receive dedicated D\+S\+Ps to which only additional instances of the same plug-\/in type will be added.

\begin{DoxyRefDesc}{Host Compatibility Notes}
\item[\hyperlink{a00380__compatibility_notes000022}{Host Compatibility Notes}]Beginning with Pro Tools 10.\+2, the T\+I shell supports a \char`\"{}processor affinity\char`\"{} property, which indicates that a D\+S\+P Process\+Proc should be preferentially loaded onto the same D\+S\+P as other instances from the same D\+L\+L binary. This is a requirement for some designs that must share global data between different processing configurations.~\newline
 ~\newline
 Note that this property should only be used when absolutely required, as it will constrain the D\+S\+P manager and reduce overall D\+S\+P plug-\/in instance counts on the system.\end{DoxyRefDesc}


\hypertarget{a00362_subsubsection__dsp_shuffles_}{}\paragraph{D\+S\+P Shuffles}\label{a00362_subsubsection__dsp_shuffles_}
 A D\+S\+P shuffle will occur in Pro Tools when the engine must re-\/allocate D\+S\+P resources in order to make more processing power available. A shuffle will force the re-\/instantiation of the plug-\/in\textquotesingle{}s D\+S\+P algorithm component, potentially on a new chip, while leaving the plug-\/in\textquotesingle{}s host objects intact. During a shuffle, the engine will perform the following steps\+: 
\begin{DoxyEnumerate}
\item Disconnect audio from an effect  
\item Call instance initialization with the removing instance flag on the old location  
\item Repeat for all instances of all D\+S\+P Effects in the system  
\item Load the effect in the new location  
\item Re-\/send the last packets to all data-\/in ports  
\item Call private data init for any private data  
\item Call instance init with the \textquotesingle{}adding instance\textquotesingle{} flag, in the new location  
\item Begin audio processing  
\item Reconnect audio  
\item Repeat the instantiation and connection process for all instances of all D\+S\+P Effects in the system  
\end{DoxyEnumerate}

Note that the system may perform some audio processing with each new instance before all of the Effect instances in the system have been re-\/instantiated.

\hypertarget{a00362_subsection__additional_ti_shell_services}{}\subsubsection{Additional T\+I Shell services}\label{a00362_subsection__additional_ti_shell_services}


\hypertarget{a00362_subsubsection__background_processing_}{}\paragraph{Background processing}\label{a00362_subsubsection__background_processing_}
 A\+A\+X plug-\/ins may request idle time from the main T\+I\+Shell thread. This results in a true idle context callback which can be used for non-\/critical \hyperlink{a00341}{background processing} tasks on the D\+S\+P. This facility restricts the D\+S\+P to only allocate plug-\/in instances of the same type.

A plug-\/in\textquotesingle{}s background processing callback is not provided with a reference to the plug-\/in\textquotesingle{}s data structures and must therefore access plug-\/in data via global variables. The background process will be interrupted by system events and the audio render callback. For more information and an example on how to create a plug-\/in that relies on background processing, see {\ttfamily \textbackslash{}Example\+Plugins\textbackslash{}Demo\+Gain\+\_\+\+Background} in the S\+D\+K. 

 \hypertarget{a00362_aax_ti_guide_03_requirements_for_ti_plug_ins}{}\subsection{Requirements for T\+I Plug-\/\+Ins}\label{a00362_aax_ti_guide_03_requirements_for_ti_plug_ins}
\hypertarget{a00362_subsection__plugin_description}{}\subsubsection{Plug-\/in description}\label{a00362_subsection__plugin_description}
To support A\+A\+X T\+I D\+S\+P platforms, a plug-\/in must add a T\+I Process\+Proc (real-\/time processing entrypoint) for each of its algorithms. This is done via a call to \hyperlink{a00088_aa8443e720e48046444a2e9f712f0864b}{A\+A\+X\+\_\+\+I\+Component\+Descriptor\+::\+Add\+Process\+Proc\+\_\+\+T\+I()}, which is parametrized with the names of both the algorithm\textquotesingle{}s T\+I D\+L\+L and of its exported entrypoint.

At minimum, the T\+I Process\+Proc requires the following A\+A\+X Properties\+: 
\begin{DoxyItemize}
\item A T\+I plug-\/in I\+D\+: \hyperlink{a00283_a6571f4e41a5dd06e4067249228e2249ea75f174df4efbeca86eaada126c1d9214}{A\+A\+X\+\_\+e\+Property\+\_\+\+Plug\+In\+I\+D\+\_\+\+T\+I}  
\item The audio buffer size that will be used by the Process\+Proc\+: \hyperlink{a00283_a6571f4e41a5dd06e4067249228e2249ea09fbd1cbcae0e86ad81005258dc1b67e}{A\+A\+X\+\_\+e\+Property\+\_\+\+D\+S\+P\+\_\+\+Audio\+Buffer\+Length}, set with a value from \hyperlink{a00206_ab33e0f1ecf04ca4161fa8d8de5845d67}{A\+A\+X\+\_\+\+E\+Audio\+Buffer\+Length\+D\+S\+P}  
\end{DoxyItemize}

\hypertarget{a00362_subsection__performance_measurement_and_reporting}{}\subsubsection{Performance measurement and reporting}\label{a00362_subsection__performance_measurement_and_reporting}
In order to determine each algorithm\textquotesingle{}s resource requirements, the host collects cycle count information from the plug-\/in via the plug-\/in\textquotesingle{}s Describe callback. Each plug-\/in Effect is responsible for correctly reporting its algorithms\textquotesingle{} cycle counts for each accelerated platform that it supports. For plug-\/ins that use D\+M\+A or background threads, a maximum per-\/chip instance count is also required.

\begin{DoxyNote}{Note}
All reported values must represent the algorithm\textquotesingle{}s worst case performance.
\end{DoxyNote}
Each of these values are reported as properties of a given algorithm Process\+Proc and are provided by the plug-\/in via \hyperlink{a00088_aa8443e720e48046444a2e9f712f0864b}{A\+A\+X\+\_\+\+I\+Component\+Descriptor\+::\+Add\+Process\+Proc\+\_\+\+T\+I()}. If an effect does not report its cycle count usage then it will be limited to a single instance per T\+I chip. This can be useful during development, but is not a supported mode for general use; all shipped plug-\/ins must correctly report their cycle requirements.

Development Builds of Pro Tools include Digi\+Shell, a utility that can be used to accurately measure plug-\/in cycle count requirements. For more information about Digi\+Shell, see \hyperlink{a00365}{D\+S\+H Guide}.

\hypertarget{a00362_subsubsection__shared_vs_perinstance_cycles_}{}\paragraph{Shared vs. per-\/instance cycles}\label{a00362_subsubsection__shared_vs_perinstance_cycles_}
 Because a single call into a plug-\/in is used to process multiple instances of that effect on that chip, two cycle count properties must be reported for each T\+I algorithm\+: 
\begin{DoxyEnumerate}
\item \hyperlink{a00283_a6571f4e41a5dd06e4067249228e2249ea3e5b289333ba49f5a33de40d89fa4ade}{A\+A\+X\+\_\+e\+Property\+\_\+\+T\+I\+\_\+\+Shared\+Cycle\+Count}  This property describes the algorithm\textquotesingle{}s one-\/time processing overhead that doesn\textquotesingle{}t change as instances are added to a chip.  
\item \hyperlink{a00283_a6571f4e41a5dd06e4067249228e2249ea5d8e5be9f3698a9c67a578c29da66405}{A\+A\+X\+\_\+e\+Property\+\_\+\+T\+I\+\_\+\+Instance\+Cycle\+Count}  This property describes the additional cycle counts that each instance adds to the base shared overhead.  
\end{DoxyEnumerate}

Many plug-\/ins exhibit different performance characteristics for both of these metrics depending on the plug-\/in\textquotesingle{}s state. When reporting a plug-\/in\textquotesingle{}s shared and per-\/instance cycle count requirements it is important to ensure that the reported values are the {\itshape maximum possible requirements} of the algorithm.

Often a plug-\/in will experience its worst-\/case per-\/instance processing load in one configuration and its worst-\/case shared processing load in another configuration. In this situation, the plug-\/in\textquotesingle{}s reported cycle count requirements should reflect the state in which the {\itshape sum} of the two metrics is highest.

It\textquotesingle{}s a common practice to not describe \hyperlink{a00283_a6571f4e41a5dd06e4067249228e2249ea5d8e5be9f3698a9c67a578c29da66405}{A\+A\+X\+\_\+e\+Property\+\_\+\+T\+I\+\_\+\+Instance\+Cycle\+Count} and \hyperlink{a00283_a6571f4e41a5dd06e4067249228e2249ea3e5b289333ba49f5a33de40d89fa4ade}{A\+A\+X\+\_\+e\+Property\+\_\+\+T\+I\+\_\+\+Shared\+Cycle\+Count} for the plug-\/ins during development and debugging process of the D\+S\+P plug-\/ins. This is acceptable, although in this case the one instance of such a plug-\/in will require the whole chip. In A\+A\+X S\+D\+K example plug-\/ins this is implemented using {\ttfamily A\+A\+X\+\_\+\+T\+I\+\_\+\+B\+I\+N\+A\+R\+Y\+\_\+\+I\+N\+\_\+\+D\+E\+V\+E\+L\+O\+P\+M\+E\+N\+T} macros. If defined, it turns off the cycle count properties for the plug-\/in.

\hypertarget{a00362_subsubsection__measuring_shared_cycles_}{}\paragraph{Measuring shared cycles}\label{a00362_subsubsection__measuring_shared_cycles_}
 Measuring shared cycle counts requires instantiating multiple instances of an effect and observing how the processing time changes as instances are added. The shared and instance cycle counts are then calculated by performing a linear regression on the number of uncached cycle counts as the number of plug-\/in instances on the chip increases.

Note that these values will differ between debug and release builds of an algorithm, so a plug-\/in\textquotesingle{}s describe function should report the correct cycle count values based on the relevant build configuration.

Digi\+Shell includes the ability to measure shared cycle counts using the {\ttfamily D\+A\+E.\+cyclesshared} command. For more information about performance profiling using Digi\+Shell, see \hyperlink{a00365_subsection__cyclessharedtest}{Cycle count performance test}.

\begin{DoxyNote}{Note}
H\+D\+X requires reporting of an algorithm\textquotesingle{}s {\itshape worst-\/case} cycle counts.
\end{DoxyNote}
\hypertarget{a00362_subsubsection__dma_and_background_thread_performance_reporting_}{}\paragraph{D\+M\+A and background thread performance reporting}\label{a00362_subsubsection__dma_and_background_thread_performance_reporting_}
 For algorithms that use \hyperlink{a00340}{D\+M\+A} or \hyperlink{a00341}{background thread} facilities, the maximum number of algorithm instances that will fit on a chip is difficult to predict from cycle counts alone. Due to the asynchronous behavior and limited capacity of the D\+M\+A system, the D\+M\+A system may begin to miss its deadlines before the C\+P\+U is fully loaded. In addition, due to differences in background processing requirements between algorithms, an effect\textquotesingle{}s background process may begin to miss its deadlines and be starved before the interrupt-\/time audio processing is at capacity. Plug-\/ins that use these facilities must therefore report the maximum number of instances that will run reliably at a given sample rate, in addition to reporting their shared and per-\/instance cycle counts as above.

Maximum reliable instance counts are reported using an additional property, \hyperlink{a00283_a6571f4e41a5dd06e4067249228e2249ea5b85e213113b7f0f7ee4bac4f5eaa59d}{A\+A\+X\+\_\+e\+Property\+\_\+\+T\+I\+\_\+\+Max\+Instances\+Per\+Chip}. A plug-\/in should register separate components for the following three sample rate ranges in order to register distinct values for this property\+: 
\begin{DoxyEnumerate}
\item Sample rates from 42k\+Hz to 50k\+Hz  
\item Sample rates from 84k\+Hz to 100k\+Hz  
\item Sample rates from 168k\+Hz to 200k\+Hz  
\end{DoxyEnumerate}

Notes regarding D\+M\+A and background thread performance reporting\+: 
\begin{DoxyItemize}
\item Because the number of instances will decrease as sample rate increases, the plug-\/in must be tested at the highest available pulled-\/up sample rate (i.\+e. 50k\+Hz instead of 48k\+Hz) in each of these three ranges.  
\item On the H\+D\+X platform, effects that use D\+M\+A or background threads will not be mixed with effects of other types on a given chip.  
\item The maximum number of instances per D\+S\+P cannot be measured via D\+S\+H in these cases, so careful listening tests must be manually performed in order to determine whether a certain number of instances of a D\+M\+A or background-\/enabled plug-\/in actually operate correctly on a D\+S\+P. 
\end{DoxyItemize}

\hypertarget{a00362_subsubsection__dynamic_resource_usage_}{}\paragraph{Dynamic resource usage}\label{a00362_subsubsection__dynamic_resource_usage_}
 All resources used by an A\+A\+X D\+S\+P plug-\/in algorithm are considered static. Plug-\/ins may not dynamically change the amount of memory or D\+S\+P cycles that are allocated to them after these metrics are provided in Describe.

The ability to dynamically change D\+S\+P cycle count requirements at run time is provided in the A\+A\+X S\+D\+K but is not currently supported by any host.

\hypertarget{a00362_subsection__plugin_compilation_and_packaging}{}\subsubsection{Plug-\/in compilation and packaging}\label{a00362_subsection__plugin_compilation_and_packaging}
 \hypertarget{a00362_subsubsection__exported_symbols_}{}\paragraph{Exported symbols}\label{a00362_subsubsection__exported_symbols_}
 Each T\+I algorithm (E\+L\+F D\+L\+L) may contain multiple entrypoints. A single D\+L\+L may be used for all of your plug-\/in\textquotesingle{}s entrypoints and program code, or you may divide your plug-\/in\textquotesingle{}s entrypoints and program code between multiple D\+L\+Ls.

Your plug-\/in must export one \char`\"{}\+C\char`\"{}-\/style callback for each algorithm Process\+Proc that your plug-\/in registers. This entrypoint must conform to the standard A\+A\+X real-\/time algorithm callback prototype\+:


\begin{DoxyCode}
\textcolor{preprocessor}{# include "elf\_linkage.h"} \textcolor{comment}{// Includes required TI\_EXPORT definition}
\textcolor{keyword}{extern} \textcolor{stringliteral}{"C"}
TI\_EXPORT
\textcolor{keywordtype}{void}
MyEffect\_AlgorithmProcessFunction(
    SMyEffect\_Alg\_Context * \textcolor{keyword}{const}  inInstancesBegin  [],
    \textcolor{keyword}{const} \textcolor{keywordtype}{void} *    inInstancesEnd)
\end{DoxyCode}
  Listing 1.\+1\+: The standard A\+A\+X real-\/time algorithm callback prototype

For Code Composer Studio projects from Code Composer Studio version 5 and higher (running Code Generation Tools 7.\+4.\+x or higher), you should include the following header instead of elf\+\_\+linkage.\+h\+:


\begin{DoxyCode}
\textcolor{preprocessor}{# include "elf\_linkage\_aax\_ccsv5.h"}
\end{DoxyCode}
  Listing 1.\+2\+: Header which should be included into all C\+C\+Sv5 plug-\/in projects.

It is located in A\+A\+X\+\_\+\+S\+D\+K/\+T\+I/\+C\+C\+Sv5 folder, so you will also need to add this path to the include path of your projects.

\begin{DoxyNote}{Note}

\begin{DoxyItemize}
\item There is a compiler option in Code Composer Studio that will add an underscore to the exported entrypoint\textquotesingle{}s name. We recommend keeping this option disabled in order to avoid ambiguity between the exported symbol name and the function name as it appears in your source code.  
\item If you encounter undefined symbol errors when linking to a D\+S\+P library that uses a C-\/style interface then add the extern \char`\"{}\+C\char`\"{} keyword before the lib function prototypes. This should resolve the majority of such linker errors. 
\end{DoxyItemize}
\end{DoxyNote}
\hypertarget{a00362_subsubsection__packaging_}{}\paragraph{Packaging}\label{a00362_subsubsection__packaging_}
 The E\+L\+F D\+L\+Ls for an A\+A\+X D\+S\+P plug-\/in must be placed in the ./\+Content/\+Resources directory within the plug-\/in bundle. 

 \hypertarget{a00362_aax_ti_guide_04_ti_development_tools}{}\subsection{T\+I Development Tools}\label{a00362_aax_ti_guide_04_ti_development_tools}
Development for T\+I algorithms is primarily performed in T\+I\textquotesingle{}s Code Composer Studio. Code Composer Studio (C\+C\+S) is a full-\/featured, Eclipse-\/based I\+D\+E providing J\+T\+A\+G hardware debugger support, a hardware simulator, and a suite of profiling tools. Most importantly, C\+C\+S includes an excellent C compiler that is capable of providing highly optimized D\+S\+P instructions without too much tuning.

 \begin{DoxyNote}{Note}
As of this writing, Code Composer Studio for Mac does not support the C6000 series processor. C\+C\+S for Windows is required for A\+A\+X D\+S\+P plug-\/in development. See \href{http://processors.wiki.ti.com/index.php/MacOS_Host_Support_CCSv7}{\tt Mac\+O\+S Host Support C\+C\+Sv7} on the Texas Instruments wiki for current compatibility information.
\end{DoxyNote}
\hypertarget{a00362_subsection__code_composer_studio}{}\subsubsection{Code Composer Studio}\label{a00362_subsection__code_composer_studio}
The A\+A\+X S\+D\+K supports Code Composer Studio versions 4 (\char`\"{}\+C\+C\+Sv4\char`\"{}) and higher (\char`\"{}\+C\+C\+Sv5\char`\"{}, etc.), with hardware debugging support beginning in version 4.\+2. As of the writing of this documentation, C\+C\+S versions 4, 5, and 7 have been tested by Avid.

\begin{DoxyNote}{Note}
This documentation was originally written for C\+C\+Sv4 and was later updated with instructions for updating from C\+C\+Sv4 to C\+C\+Sv5. Versions 5 and higher use a different project file format from version 4; when this documentation describes changes required for version 5 then these changes will also be required by other later versions which use this new project format.
\end{DoxyNote}
\hypertarget{a00362_subsubsection__installation_}{}\paragraph{Installation}\label{a00362_subsubsection__installation_}

\begin{DoxyEnumerate}
\item Download and install the latest Code Composer Studio from T\+I\textquotesingle{}s website.

\begin{DoxyNote}{Note}
Windows 10 requires Code Composer Studio version 6.\+1.\+3 or higher

As of Code Composer Studio version 7 T\+I does not charge for licenses. You can simply download the tool and start using it. Along with this the end user license agreement has changed to a simple T\+S\+P\+A compatible license. For more information see the T\+I web site.  
\end{DoxyNote}

\item The default installation will work fine, but a custom install will be smaller. You only need support for the C6000 chipset and the Spectrum Digital J\+T\+A\+G drivers, so you can deselect all the other chipsets and J\+T\+A\+G drivers.  
\item Go to{\itshape  } {\itshape  \href{https://www-a.ti.com/downloads/sds_support/TICodegenerationTools/download.htm}{\tt T\+I\textquotesingle{}s Code Generation Tools}} {\itshape  } page. You will need to log in. 
\item Download and install the C6000 Code Generation Tools v7.\+0.\+x or later, using the typical installation settings. For \hyperlink{a00288}{A\+A\+X} D\+S\+P development you will only need support for the C6000 chipset and, if you will be using a hardware debugger, for the Spectrum Digital J\+T\+A\+G drivers, so you may deselect all the other chipsets and J\+T\+A\+G drivers.


\begin{DoxyEnumerate}
\item Launch C\+C\+S and go to Help $>$ Install New Software...  
\item In the opened dialog select \char`\"{}\+Code Generation Tools Updates\char`\"{} in the \char`\"{}\+Work with\+:\char`\"{} drop-\/down list.  
\item Select \char`\"{}\+T\+I Compiler Updates\char`\"{} $>$ \char`\"{}\+C6000 Compiler Tools \mbox{[}version\mbox{]}\char`\"{}.  
\item Press Next and continue installation using the \char`\"{}typical\char`\"{} installation settings. 
\end{DoxyEnumerate}

As of the publishing of this version of the A\+A\+X S\+D\+K Avid is internally using v7.\+4.\+6. Avid has tested 7.\+4.\+4 and 7.\+4.\+6, but we assume that later revisions will work as well. The latest C\+G\+Tools version available as of this writing is v7.\+4.\+21.

For more information about configuring your C\+C\+S workspace with C\+G\+Tools v7.\+4.\+x, see \hyperlink{a00362_subsubsection__workspace_setup_}{Workspace setup} 
\end{DoxyEnumerate}

\hypertarget{a00362_subsubsection__workspace_setup_}{}\paragraph{Workspace setup}\label{a00362_subsubsection__workspace_setup_}
 The idea of a C\+C\+S workspace is similar to a Visual Studio solution file. Note that workspaces tend to store absolute paths and developer-\/specific info, so you may wish to avoid checking them in to your source control server. \subparagraph*{Setting up workspace-\/global macros }

 {\itshape  To set up workspace global macros\+: } 
\begin{DoxyEnumerate}
\item When you open C\+C\+S for the first time, select a directory for your \char`\"{}workspace\char`\"{}. As mentioned above, we recommend that this be outside of your source tree.  \begin{DoxyNote}{Note}
Pay attention that you can not reuse your Code Composer Studio workspace after updating to a later versions. In particular, we have found the C\+C\+Sv4 workspaces are incompatible with C\+C\+Sv5. After updating your system to a later Code Composer Studio version you must create a new workspace and import your existing projects into this new workspace. 
\end{DoxyNote}

\item Go to File $>$ Import... and select Code Composer Studio $>$ Build Variables (C\+C\+S $>$ Managed Build Macros in C\+C\+Sv4.) Click Next.  
\item Browse to T\+I/\+Common/macros.\+ini in your A\+A\+X S\+D\+K directory and click Finish.  
\item This will define an \char`\"{}\+S\+D\+K\+\_\+\+S\+O\+U\+R\+C\+E\+\_\+\+R\+O\+O\+T\char`\"{} Linked Resource path variable and Managed Build macro, which associates the C\+C\+S workspace with a single A\+A\+X S\+D\+K installation. \begin{DoxyNote}{Note}
A side effect of this is that you cannot use projects from multiple distinct A\+A\+X S\+D\+K installations in the same C\+C\+S workspace.  
\end{DoxyNote}

\item To verify that the correct path has been set, go to Window $>$ Preferences... and look in General $>$ Workspace $>$ Linked Resources, and C/\+C++ $>$ Build $>$ Build Variables (C/\+C++ $>$ Managed Build $>$ Macros for C\+C\+Sv4.) 
\end{DoxyEnumerate}\subparagraph*{Importing projects into your workspace }

 {\itshape  To import projects into your workspace\+:} 
\begin{DoxyEnumerate}
\item In the I\+D\+E, go to Project $>$ Import Existing C\+C\+S/\+C\+C\+E Eclipse Project  
\item In Select search-\/directory, select the root of your A\+A\+X S\+D\+K installation  
\item The projects in the resulting Projects list will automatically be selected  
\item Click Finish, and then wait while the projects are imported.  
\end{DoxyEnumerate}

In order to import C\+C\+Sv4 projects into later versions of Code Composer Studio it is necessary to add a .cdtproject file to the project. If you don\textquotesingle{}t have this file in your project, then you can copy it from any other existing project which was created using C\+C\+Sv5 or later. Otherwise you will most likely see something similar to this error\+:

{\itshape \begin{quote}
\char`\"{}\+Error\+: Import failed for project \textquotesingle{}xxxx\textquotesingle{} because its meta-\/data cannot be interpreted.\char`\"{}\end{quote}
}

If you try to build this newly imported C\+C\+Sv4 project in a later version of Code Composer Studio then you will get the warning\+:

{\itshape \begin{quote}
\char`\"{}\+This project was created using a version of compiler that is not currently installed\+: 7.\+0.\+5 \mbox{[}\+C6000\mbox{]}. Another version of the compiler will be used during build\+: 7.\+4.\+6. Please install the compiler of the required version, or migrate the project to one of the available compiler versions by adjusting project properties.\char`\"{}\end{quote}
}

This warning may be cleared by changing Properties $>$ General $>$ Compiler Version from T\+I v7.\+0.\+x to the current version (e.\+g. T\+I v7.\+4.\+x). After that the {\itshape \char`\"{}\+Output format\char`\"{}} field, which is next one to the {\itshape \char`\"{}\+Compiler version\char`\"{}} field and is typically grayed out, will become active. You should choose \char`\"{}eabi (\+E\+L\+F)\char`\"{} there. Otherwise Code Composer the build will fail with errors\+: 
\begin{DoxyItemize}
\item {\itshape \char`\"{}-\/-\/dynamic=lib not supported when producing T\+I-\/\+C\+O\+F\+F output files\char`\"{}} 
\item {\itshape \char`\"{}-\/-\/export=\+\_\+auto\+\_\+init\+\_\+elf not supported when producing T\+I-\/\+C\+O\+F\+F output\char`\"{}} 
\end{DoxyItemize}

\begin{DoxyNote}{Note}
After successful convertion of the project and successful build, the remeasurement of cycle count should be done, because it may change. Most likely it will decrease, as compared to the version which was built with C\+C\+Sv4, but that is not guaranteed. Also the size of the D\+L\+L may increase, which may require reducing code size in order to properly instantiate the plug-\/in.
\end{DoxyNote}
\hypertarget{a00362_subsubsection__creating_new_projects_}{}\paragraph{Creating new projects}\label{a00362_subsubsection__creating_new_projects_}
\subparagraph*{New project setup}

 {\itshape  Use the following settings in the \char`\"{}\+New Project...\char`\"{} wizard. Defaults are in italics.} 
\begin{DoxyItemize}
\item Project Type\+: {\ttfamily C6000}  
\item Output type\+: {\ttfamily Executable}  
\item Device Variant\+: {\ttfamily Generic C67x+ Device}  
\item Device Endianness\+: {\ttfamily little}  
\item Code Generation Tools\+: {\ttfamily 7.\+4.\+6} or later ({\ttfamily 7.\+0.\+5} for C\+C\+Sv4)  
\item Output format\+: eabi (E\+L\+F) (in C\+C\+Sv4 this field will be grayed out.) 
\item Linker Command File\+: {\ttfamily Common\+Plug\+In\+\_\+\+Linker\+Cmd.\+cmd} (see note below)  
\item Runtime Support Library\+: {\itshape  $<$automatic$>$}  
\end{DoxyItemize}

\begin{DoxyNote}{Note}
You can edit the Linker Command File setting to use the {\ttfamily S\+D\+K\+\_\+\+S\+O\+U\+R\+C\+E\+\_\+\+R\+O\+O\+T} macro by manually editing the project\textquotesingle{}s .project X\+M\+L file or by adding the file to your project using a relative path. See the S\+D\+K sample plug-\/in projects for an example.
\end{DoxyNote}
\hypertarget{a00362_subsubsection__recommended_settings_for_aax_plugin_projects_}{}\paragraph{Recommended settings for A\+A\+X plug-\/in projects}\label{a00362_subsubsection__recommended_settings_for_aax_plugin_projects_}
  Tool Settings   C6000 Compiler   Include Options   -\/{\ttfamily include\+\_\+path \char`\"{}\$\{\+S\+D\+K\+\_\+\+S\+O\+U\+R\+C\+E\+\_\+\+R\+O\+O\+T\}/\+Interfaces\char`\"{}}  -\/{\ttfamily include\+\_\+path \char`\"{}\$\{\+S\+D\+K\+\_\+\+S\+O\+U\+R\+C\+E\+\_\+\+R\+O\+O\+T\}/\mbox{[}\+Plug-\/in directory\mbox{]}\char`\"{}}

The {\ttfamily S\+D\+K\+\_\+\+S\+O\+U\+R\+C\+E\+\_\+\+R\+O\+O\+T} macro is defined via the macros.\+ini file, located in the S\+D\+K\textquotesingle{}s /\+T\+I/\+C\+C\+Sv4 directory. If you encounter errors using this macro, import the file using File $>$ Import... $>$ C\+C\+S $>$ Managed Build Macros.

 Tool Settings   C6000 Compiler   Command Files   {\ttfamily -\/cmd\+\_\+file \char`\"{}\$\{\+S\+D\+K\+\_\+\+S\+O\+U\+R\+C\+E\+\_\+\+R\+O\+O\+T\}\textbackslash{}\textbackslash{}\+T\+I\textbackslash{}\textbackslash{}\+C\+C\+Sv4\textbackslash{}\textbackslash{}\+Common\+Plug\+In\+\_\+\+Compiler\+Cmd.\+cmd\char`\"{}}

This file contains additional compiler commands that should be common to all A\+A\+X plug-\/in projects

 Tool Settings   C6000 Linker   Basic Options   {\ttfamily -\/o \char`\"{}\$\{\+Config\+Dir\}/\$\{\+Package\+Name\}/\+Contents/\+Resources/\$\{\+Proj\+Name\}.\+dll\char`\"{}}

This path will ensure that your compiled T\+I D\+L\+L is placed in the appropriate location inside your A\+A\+X plug-\/in bundle.

 Tool Settings   C6000 Linker   Runtime Environment   (No \char`\"{}\+Initialization model\char`\"{} options set) ~\newline
  Build Settings   Artifact name   {\ttfamily \$\{Config\+Dir\}/\$\{Package\+Name\}/\+Contents/\+Resources/\$\{Proj\+Name\}}

This path will ensure that your compiled T\+I D\+L\+L is placed in the appropriate location inside your A\+A\+X plug-\/in bundle.

 Build Settings   Artifact extension   {\ttfamily dll}

A\+A\+X T\+I libraries should use the .dll extension

 Binary Parser   Elf Parser

A\+A\+X T\+I libraries should use the Elf binary parser only

 Macros   Project   User Macros   Config\+Dir = {\ttfamily \$\{Out\+Dir\}/\$\{Config\+Name\}}  Int\+Dir = {\ttfamily \$\{Config\+Dir\}/int/\$\{Package\+Name\}/\+T\+I/\$\{Proj\+Name\}}  Out\+Dir = {\ttfamily \$\{Proj\+Dir\+Path\}/../../\+Win\+Build}  Package\+Name = \mbox{[}Plug-\/in name\mbox{]}

These macros are used by the other settings here to ensure proper path set-\/up and artifact naming. Don\textquotesingle{}t worry that {\ttfamily Config\+Name} shows up as undefined -\/ it will be defined as Debug/\+Release at compilation.

\hypertarget{a00362_subsubsection__recommended_release_configuration_settings_}{}\paragraph{Recommended Release configuration settings}\label{a00362_subsubsection__recommended_release_configuration_settings_}
  Tool Settings   C6000 Compiler   Basic Options   {\ttfamily -\/symdebug\+:none}  {\ttfamily -\/\+O3}

 Tool Settings   C6000 Compiler   Predefined Symbols   {\ttfamily -\/define=N\+D\+E\+B\+U\+G}

 Tool Settings   C6000 Compiler   Optimizations   {\ttfamily -\/os}  {\ttfamily -\/on2}  {\ttfamily -\/op3}

 Tool Settings   C6000 Compiler   Assembler Options   {\ttfamily -\/keep\+\_\+asm} 

\hypertarget{a00362_subsubsection__other_useful_project_settings_}{}\paragraph{Other useful project settings}\label{a00362_subsubsection__other_useful_project_settings_}
  Tool Settings   C6000 Compiler   Predefined Symbols   {\ttfamily -\/define \+\_\+\+D\+E\+B\+U\+G}

This option is useful for differentiating cycle count reporting for Debug vs. Release builds.

 Tool Settings   C6000 Compiler   Directory Specifier   {\ttfamily -\/ft \char`\"{}\$\{\+Int\+Dir\}\char`\"{}}  {\ttfamily -\/fr \char`\"{}\$\{\+Int\+Dir\}\char`\"{}}  {\ttfamily -\/fs \char`\"{}\$\{\+Int\+Dir\}\char`\"{}}

Useful for collecting intermediate files

 Tool Settings   C6000 Linker   Basic Options   {\ttfamily -\/m \char`\"{}\$\{\+Int\+Dir\}/\$\{\+Proj\+Name\}.\+map\char`\"{}}

Useful for placing the map file alongside all other intermediates

 Tool Settings   C6000 Linker   File Search Path   {\ttfamily -\/l (nothing)}

You can exclude libc.\+a, which is included by default, from this option unless you require C library features.

\hypertarget{a00362_subsubsection__adding_files_and_folders_}{}\paragraph{Adding files and folders}\label{a00362_subsubsection__adding_files_and_folders_}
 In C\+C\+S, dragging files into the project, using \char`\"{}\+Add Files to Project...\char`\"{}, or using \char`\"{}\+Link Files to Project...\char`\"{} will either copy the file into the project directory or create an absolute path to the file. This is usually not the desired behavior. Use the following steps to add a file using a relative path\+: {\itshape  ~} 
\begin{DoxyEnumerate}
\item Right click on the project you\textquotesingle{}d like to add files to, and select New $>$ File (N\+O\+T \char`\"{}\+Source File\char`\"{} or \char`\"{}\+Header File\char`\"{}).  
\item Click "Advanced $>$$>$".  
\item Check the box that says \char`\"{}\+Link to the file in the system\char`\"{}. Click \char`\"{}\+Variables...\char`\"{}  
\item Select the appropriate variable (usually either {\ttfamily S\+D\+K\+\_\+\+S\+O\+U\+R\+C\+E\+\_\+\+R\+O\+O\+T} or {\ttfamily S\+O\+U\+R\+C\+E\+\_\+\+R\+O\+O\+T}) and click \char`\"{}\+Extend...\char`\"{}  
\item Find the file you want to add. Click O\+K. Click Finish.  
\end{DoxyEnumerate}

Note that, when adding folders, {\itshape everything} in the folder will be built by default. You can exclude files to work around this behavior.

\hypertarget{a00362_subsection__the_tms320c6000_cpp_compiler}{}\subsubsection{The T\+M\+S320\+C6000 C++ compiler}\label{a00362_subsection__the_tms320c6000_cpp_compiler}
 One of the primary goals of A\+A\+X is to provide a platform-\/agnostic development architecture in which products can easily be developed and re-\/used across a wide variety of platforms. However, it is still occasionally necessary to write platform-\/specific code. This section will document methods for producing code that is specific to the T\+I C6727 platform using the T\+M\+S320\+C6000 C++ compiler.

\hypertarget{a00362_subsubsection__cpp_standard_support_}{}\paragraph{C++ standard support}\label{a00362_subsubsection__cpp_standard_support_}
 The T\+M\+S320\+C6000 compiler supports C++ as defined in the I\+S\+O/\+I\+E\+C 14882\+:1998 standard. The exceptions to the standard are as follows\+: 
\begin{DoxyItemize}
\item Complete C++ standard library support is not included. C subset and basic language support is included.  
\item These C++ headers for C library facilities are not included\+: 
\begin{DoxyItemize}
\item {\ttfamily $<$clocale$>$ } 
\item {\ttfamily $<$csignal$>$}  
\item {\ttfamily $<$cwchar$>$}  
\item {\ttfamily $<$cwctype$>$}  
\item {\ttfamily $<$ciso646$>$}  
\end{DoxyItemize}
\item These C++ headers are the only C++ standard library header files included\+: 
\begin{DoxyItemize}
\item {\ttfamily $<$new$>$}  
\item {\ttfamily $<$typeinfo$>$}  
\end{DoxyItemize}
\item No support for {\ttfamily bad\+\_\+cast} or {\ttfamily bad\+\_\+type\+\_\+id} is included in the typeinfo header.  
\item Run-\/time type information (R\+T\+T\+I) is disabled by default. R\+T\+T\+I can be enabled with the -\/rtti compiler option.  
\item The {\ttfamily reinterpret\+\_\+cast} type does not allow casting a pointer to member of one class to a pointer to member of a another class if the classes are unrelated.  
\item Two-\/phase name binding in templates, as described in tesp.\+res and temp.\+dep of the standard, is not implemented.  
\item The export keyword for templates is not implemented.  
\item A typedef of a function type cannot include member function cv-\/qualifiers.  
\item A partial specialization of a class member template cannot be added outside of the class definition.  
\end{DoxyItemize}

\hypertarget{a00362_subsubsection__predefined_environment_symbols_}{}\paragraph{Predefined environment symbols}\label{a00362_subsubsection__predefined_environment_symbols_}
 The following symbols are predefined by the compiler on the T\+I architecture, and should be used in code concerned with cross-\/platform support\+:


\begin{DoxyItemize}
\item {\ttfamily \+\_\+\+T\+M\+S320\+C6\+X} Identifies that the chip is a C6000 variant. This is the symbol that we commonly use to distinguish whether code is being compiled for A\+A\+X-\/\+Native (Mac/\+Windows) or A\+A\+X-\/\+T\+I. 
\item {\ttfamily \+\_\+\+T\+M\+S320\+C6700\+\_\+\+P\+L\+U\+S} Identifies that the chip is a C6700-\/plus variant  
\end{DoxyItemize}

Although you should not require them for A\+A\+X development, equivalent assembly predefines are as follows\+:


\begin{DoxyItemize}
\item {\ttfamily .T\+M\+S320\+C6\+X} Identifies that the chip is a C6000 variant  
\item {\ttfamily .T\+M\+S320\+C6700\+\_\+\+P\+L\+U\+S} Identifies that the chip is a C6700-\/plus variant 
\end{DoxyItemize}

\hypertarget{a00362_subsubsection__loop_controls_}{}\paragraph{Loop controls}\label{a00362_subsubsection__loop_controls_}
 The T\+I compiler supports several pragmas that can be used to give the compiler additional information about loops.


\begin{DoxyItemize}
\item {\ttfamily \#pragma M\+U\+S\+T\+\_\+\+I\+T\+E\+R\+A\+T\+E( min, max, multiple )}  This pragma helps the compiler optimize loops. min is the minimum number of times the loop will execute, max is the maximum number of times the loop will execute, and modulo is used if the loop will only execute a certain multiple of some number. ~\newline
  
\item {\ttfamily \#pragma P\+R\+O\+B\+\_\+\+I\+T\+E\+R\+A\+T\+E( min , max )}  If extreme cases prevent the use of {\ttfamily M\+U\+S\+T\+\_\+\+I\+T\+E\+R\+A\+T\+E}, {\ttfamily P\+R\+O\+B\+\_\+\+I\+T\+E\+R\+A\+T\+E} allows you to specify the usual number of times a loop executes. For example, {\ttfamily P\+R\+O\+B\+\_\+\+I\+T\+E\+R\+A\+T\+E} could be applied to a loop that executes for eight iterations in the majority of cases but that sometimes may execute more or less than eight iterations. ~\newline
  
\item {\ttfamily pragma U\+N\+R\+O\+L\+L( n )}  Helps the compiler use S\+I\+M\+D instructions, where {\ttfamily n} is the unrolling factor. By specifying {\ttfamily U\+N\+R\+O\+L\+L(1)} you can prevent the compiler from automatically unrolling a loop. In general, we recommend using {\ttfamily M\+U\+S\+T\+\_\+\+I\+T\+E\+R\+A\+T\+E} instead unless you have specifically identified a situation where manually unrolling a loop improves performance.  
\end{DoxyItemize}

\hypertarget{a00362_subsection__digishell_test_tool}{}\subsubsection{Digi\+Shell test tool (\+D\+S\+H)}\label{a00362_subsection__digishell_test_tool}
 Digi\+Shell is a software tool that provides a general framework for running tests on Avid audio hardware. As a command-\/line application, Digi\+Shell may be driven as part of a standard, automated test suite for maximum test coverage. D\+S\+H supports loading all types of A\+A\+X plug-\/ins including Native and D\+S\+P, and is especially useful when running performance and cancellation tests of A\+A\+X-\/\+T\+I types. Digi\+Shell is included in Pro Tools Development Builds as {\ttfamily dsh.\+exe} (Windows) or as {\ttfamily dsh} in the {\ttfamily Command\+Line\+Tools} directory (Mac).

More information on D\+S\+H test tool can be found in \hyperlink{a00365}{D\+S\+H Guide}.

\hypertarget{a00362_subsection__hardware_debugging}{}\subsubsection{Hardware Debugging}\label{a00362_subsection__hardware_debugging}
 \hypertarget{a00362_subsubsection__requirements_}{}\paragraph{Requirements}\label{a00362_subsubsection__requirements_}
 Relocatable E\+L\+F D\+L\+Ls (T\+I algorithms) can be debugged with some help from the D\+I\+D\+L loader, the T\+I Shell Manager, and a script called D\+L\+L\+View\+\_\+\+Elf\+\_\+\+Avid.\+js.

These are the minimum requirements for hardware debugging for T\+I plug-\/ins\+: 
\begin{DoxyItemize}
\item Code Composer Studio version 4.\+2 or later  
\item X\+D\+S510 hardware debugger  
\item J\+T\+A\+G-\/enabled H\+D\+X card  
\end{DoxyItemize}

We recommend using Spectrum Digital\textquotesingle{}s X\+D\+S510 U\+S\+B Plus J\+T\+A\+G Emulator, as it is the only one our internal developers have used and tested in-\/house. Both Spectrum Digital and T\+I have useful technical reference/installation guides, both of which can be found on the A\+A\+X Developer Forum under the \textquotesingle{}Development Tools\textquotesingle{} discussion.

\hypertarget{a00362_subsubsection__how_it_works_}{}\paragraph{How it works}\label{a00362_subsubsection__how_it_works_}
 The ridl E\+L\+F loader inside D\+I\+D\+L stores a module and segment list containing the paths of all loaded modules and where their segments are loaded. The T\+I Shell Manager gets a serialized version of this table and loads it to a block of external memory on the chip at a known location. The D\+L\+L\+View\+\_\+\+Elf\+\_\+\+Avid.\+js script queries this memory via the debugger and extracts the paths of the modules and the E\+L\+F segment load locations, which it then passes on to the {\ttfamily G\+E\+L\+\_\+\+Symbol\+Add\+E\+L\+F\+Rel} scripting console command (new to C\+C\+Sv4.\+2). You can also use that command directly at the console.

\hypertarget{a00362_subsubsection__connecting_a_jtag_emulator}{}\paragraph{Connecting a J\+T\+A\+G Emulator}\label{a00362_subsubsection__connecting_a_jtag_emulator}
 A J\+T\+A\+G-\/enabled H\+D\+X development card includes a \char`\"{}riser\char`\"{} P\+C\+B section extending about a centimeter above the production card P\+C\+B. This riser includes two J\+T\+A\+G connectors. The two connectors correspond to the two banks of 9 D\+S\+Ps on the H\+D\+X card. Assuming that you are instantiating your plug-\/in for debugging on the first available D\+S\+P, you will want to connect your J\+T\+A\+G emulator to the connector that is closest to the card\textquotesingle{}s user-\/visible ports. This connector corresponds to the first 9 D\+S\+Ps on the card.

\hypertarget{a00362_subsubsection__linking_to_tishellout_}{}\paragraph{Linking to T\+I\+Shell.\+out}\label{a00362_subsubsection__linking_to_tishellout_}
 Hardware debugging, as well as several other debugging facilities, requires that the D\+S\+P plug-\/in project is linked to T\+I\+Shell.\+out in Code Composer Studio.

{\itshape  To link a plug-\/in project to T\+I\+Shell.\+out, follow these steps\+:} 
\begin{DoxyEnumerate}
\item Open the plug-\/in project\textquotesingle{}s properties window and navigate to the {\itshape C/\+C++ Build $>$ Tool Settings $>$ C6000 Linker $>$ File Search Path} properties pane.  
\item Add \char`\"{}\+T\+I\+Shell.\+out\char`\"{} to the \char`\"{}\+Include library file\char`\"{} ({\ttfamily -\/l}) property list.  
\item Under \char`\"{}\+Add $<$dir$>$ to library search path\char`\"{} ({\ttfamily -\/i}), add the file path of the Pro Tools build you will be using to test the plug-\/in. This directory should already include the build\textquotesingle{}s T\+I\+Shell.\+out file.  
\item Repeat this process for each Configuration of the plug-\/in project that you will be testing.  
\item Add \char`\"{}\mbox{[}path to A\+A\+X S\+D\+K root\mbox{]}\textbackslash{}\textbackslash{}\+T\+I\char`\"{} to the project\textquotesingle{}s list of source file include directories  
\end{DoxyEnumerate}

\hypertarget{a00362_subsubsection__adding_the_hdx_target_descriptor_file_}{}\paragraph{Adding the H\+D\+X Target Descriptor File}\label{a00362_subsubsection__adding_the_hdx_target_descriptor_file_}
 {\itshape  To add the H\+D\+X Target Descriptor File\+:} 
\begin{DoxyEnumerate}
\item In the I\+D\+E, go to Window $>$ Preferences, C\+C\+S $>$ Debug. Point the \char`\"{}\+Shared target configuration directory\char`\"{} to /\+T\+I/\+Common in your A\+A\+X S\+D\+K source tree  
\item In the I\+D\+E, go to Window $>$ Show View $>$ Target Configurations.  
\item Click refresh if you don\textquotesingle{}t see the configuration file  
\item Right click Raven\+\_\+\+C672x\+\_\+\+X\+D\+S510\+\_\+\+U\+S\+B.\+ccxml, and click \char`\"{}\+Set as Default\char`\"{}.  
\end{DoxyEnumerate}

\hypertarget{a00362_subsubsection__setting_up_the_dllview_script_}{}\paragraph{Setting up the D\+L\+L\+View script}\label{a00362_subsubsection__setting_up_the_dllview_script_}
 Once you have successfully installed the X\+D\+S510, you will have to do a little bit of setup with C\+C\+S. Before starting this process, verify that you are running C\+C\+Sv4.\+2 or later and the C6000 code generation tools v7.\+4 or later (or 7.\+0.\+5 for C\+C\+Sv4). C\+C\+S should recognize the installed emulator and prompt you to download the necessary drivers. Once completed, you will then want to setup your D\+L\+L\+View script.

{\itshape  To set up the D\+L\+L\+View script\+:} 
\begin{DoxyEnumerate}
\item In the I\+D\+E, open the Scripting Console under View $>$ Scripting Console  
\item At the Scripting console, type one of the following to load the D\+L\+L\+View script (insert your own source tree path, and make sure to load the version that corresponds to your installed C\+C\+S version)\+:  Code Composer Studio 4\+: {\ttfamily load\+J\+S\+File \char`\"{}\mbox{[}\+P\+A\+T\+H T\+O A\+A\+X S\+D\+K\mbox{]}/\+T\+I/\+C\+C\+Sv4/dll\+View\+\_\+\+Elf\+\_\+\+Avid.\+js\char`\"{} true } Code Composer Studio 5 and later\+: {\ttfamily load\+J\+S\+File \char`\"{}\mbox{[}\+P\+A\+T\+H T\+O A\+A\+X S\+D\+K\mbox{]}/\+T\+I/\+C\+C\+Sv5/dll\+View\+\_\+\+Elf\+\_\+\+Avid.\+js\char`\"{} true }  
\end{DoxyEnumerate}

You should now see a new menu item under the Scripts menu\+: \char`\"{}\+D\+L\+L\+View -\/\+Load Pro Tools Plug-\/\+In Symbols\char`\"{} This should load every time C\+C\+S starts.

\hypertarget{a00362_subsubsection__loading_symbols_for_debugging_}{}\paragraph{Loading Symbols for Debugging}\label{a00362_subsubsection__loading_symbols_for_debugging_}
 You will need to get your code loaded and running on the T\+I before you load symbols. You can do this directly through Pro Tools, or by using our Digi\+Shell test tool. If using the Digi\+Shell test tool, load the D\+A\+E dish and then a plug-\/in via the following commands\+:  {\ttfamily load\+\_\+dish D\+A\+E}   Loads the D\+A\+E dish  {\ttfamily run }  Lists available plug-\/ins with their index and spec  {\ttfamily run$<$index$>$}   Instantiates the $<$index$>$ plug-\/in

Use the D\+L\+L\+View script to load symbols for E\+L\+F D\+L\+Ls. After setting up the D\+L\+L\+View script and connecting to the desired chip in the Debug pane, run the \char`\"{}\+D\+L\+L\+View -\/\+Load Pro Tools Plug-\/\+In Symbols\char`\"{} script from the Scripts menu in Code Composer Studio.

\begin{DoxyNote}{Note}
The chip will need to be Suspended in the debugger in order to load symbols.
\end{DoxyNote}
{\itshape  To load symbols for debugging\+:} 
\begin{DoxyEnumerate}
\item In C\+C\+S, Launch the T\+I Debugger (Target $>$ Launch T\+I Debugger)  
\item Connect the debug target to the appropriate chip 
\item Suspend the chip  
\item Run Scripts $>$ D\+L\+L\+View -\/\+Load Pro Tools Plug-\/\+In Symbols. \begin{DoxyNote}{Note}
This script can take a moment to load; look at the Scripting Console to view its progress if you like 

This script may print a warning about T\+I\+Shell.\+out not existing. This warning is benign for plug-\/in debugging since the T\+I\+Shell symbols are not required in this case.  
\end{DoxyNote}

\end{DoxyEnumerate}

This will load symbols for all symbol-\/rich modules running on the chip(s) connected to the debugger. If you load or unload plug-\/ins after this, you can simply repeat the \char`\"{}\+D\+L\+L\+View -\/\+Load Pro Tools Plug-\/\+In Symbols\char`\"{} command, which will synchronize the debugger with the current configuration.

\begin{DoxyNote}{Note}
When running a plug-\/in in Pro Tools, the first D\+S\+P chip is reserved for the H\+D\+X mixer. Therefore the first available D\+S\+P chip for plug-\/in instantiation is {\ttfamily C672x\+\_\+1}. Under D\+S\+H, the first available D\+S\+P chip is {\ttfamily C672x\+\_\+0}.
\end{DoxyNote}
\hypertarget{a00362_subsubsection__breaking_on_first_entry_into_algorithm_}{}\paragraph{Breaking on first entry into algorithm}\label{a00362_subsubsection__breaking_on_first_entry_into_algorithm_}
 To break on the first entry into the plug-\/in\textquotesingle{}s processing routine, use the manual single-\/buffer processing mode in D\+S\+H\+:  {\ttfamily piproctrigger manual}   {\ttfamily run$<$index$>$ }  Attach debugger, suspend the chip, load symbols, set breakpoint, resume   {\ttfamily piproctrigger auto }

\hypertarget{a00362_subsubsection__breaking_on_algorithm_initialization}{}\paragraph{Breaking in the on-\/chip algorithm initialization callback}\label{a00362_subsubsection__breaking_on_algorithm_initialization}
 It is not currently possible to hit a breakpoint in the optional on-\/chip algorithm initialization callback for a plug-\/in. If you need to troubleshoot this callback then you should use tracing to print debug information to a log file.

\hypertarget{a00362_subsection__tracing}{}\subsubsection{Tracing}\label{a00362_subsection__tracing}
Avid\textquotesingle{}s A\+A\+X D\+S\+P platforms provide tracing functionality based on Avid\textquotesingle{}s \hyperlink{a00364}{Digi\+Trace} tool.

To enable trace logging for T\+I plug-\/ins, use the \hyperlink{a00158_ab53f1d6a94f8b6ebb3a101f71bfe4e82}{A\+A\+X\+\_\+\+T\+R\+A\+C\+E} or \hyperlink{a00158_ac2aa820ece56bb59140ad561218db4b3}{A\+A\+X\+\_\+\+T\+R\+A\+C\+E\+\_\+\+R\+E\+L\+E\+A\+S\+E} macros defined in {\ttfamily \hyperlink{a00158}{A\+A\+X\+\_\+\+Assert.\+h}}. A separate macro, \hyperlink{a00158_a168ee44fd7a5485ab50160db36fb2988}{A\+A\+X\+\_\+\+A\+S\+S\+E\+R\+T}, is also available for conditional tracing. These macros are cross-\/platform and will function whether the algorithm is running on the T\+I or on the host.

\hypertarget{a00362_subsubsection__tracing_requirements_}{}\paragraph{Tracing requirements}\label{a00362_subsubsection__tracing_requirements_}

\begin{DoxyItemize}
\item The \hyperlink{a00158_a168ee44fd7a5485ab50160db36fb2988}{A\+A\+X\+\_\+\+A\+S\+S\+E\+R\+T} and \hyperlink{a00158_ab53f1d6a94f8b6ebb3a101f71bfe4e82}{A\+A\+X\+\_\+\+T\+R\+A\+C\+E} macros are debug-\/only and will not provide tracing output from release builds of your plug-\/in. \hyperlink{a00158_ac2aa820ece56bb59140ad561218db4b3}{A\+A\+X\+\_\+\+T\+R\+A\+C\+E\+\_\+\+R\+E\+L\+E\+A\+S\+E} may be used for tracing in both debug and release configurations.  
\item These macros require that the {\ttfamily D\+T\+F\+\_\+\+A\+A\+X\+P\+L\+U\+G\+I\+N\+S} facility is enabled in the Digi\+Trace configuration file. You can toggle this facility to enable or disable A\+A\+X algorithm-\/level tracing.  
\item In order for tracing to be successful on T\+I platforms, your plug-\/in\textquotesingle{}s E\+L\+F D\+L\+L must dynamically link against T\+I\+Shell.\+out, a component that is installed alongside the Pro Tools application. This file includes the \textquotesingle{}glue\textquotesingle{} that is required in order for the linker to resolve the Digi\+Trace entrypoint symbol in the D\+L\+L.  
\end{DoxyItemize}

To link your plug-\/in project to T\+I\+Shell.\+out in Code Composer Studio, follow the steps listed in \hyperlink{a00362_subsubsection__linking_to_tishellout_}{Linking to T\+I\+Shell.\+out} .

\hypertarget{a00362_subsubsection__tracing_example_}{}\paragraph{Tracing example}\label{a00362_subsubsection__tracing_example_}



\begin{DoxyCode}
int32\_t
\hyperlink{a00149_aaa22112139aa627574b1ef562f579d43}{AAX\_CALLBACK}
MyExamplePlugIn\_AlgorithmInit ( SExample\_Alg\_Context \textcolor{keyword}{const} *
     inInstance , \hyperlink{a00206_aff5646376a3c93f032cf2400e0885023}{AAX\_EComponentInstanceInitAction} inAction )
\{
    \hyperlink{a00158_ac2aa820ece56bb59140ad561218db4b3}{AAX\_TRACE\_RELEASE} (
      \hyperlink{a00158_a8a6953f26f36747357d5d95f96dcf68d}{kAAX\_Trace\_Priority\_Normal} ,
      \textcolor{stringliteral}{"MyExamplePlugIn\_AlgorithmInit called for action : %d"},
      inAction );
    \textcolor{keywordflow}{return} 0;
\} 
\end{DoxyCode}
  Listing 2\+: Adding trace code on T\+I

\hypertarget{a00362_subsubsection__usage_notes_}{}\paragraph{Usage notes}\label{a00362_subsubsection__usage_notes_}

\begin{DoxyItemize}
\item When running on the D\+S\+P, the actual handling of each tracing call occurs in a separate thread. This can lead to incorrect data reporting if volatile data, such as a pointer to an audio sample, is passed in to the tracing statement as a parameter.  
\item D\+S\+P tracing is most reliable when using debug T\+I builds and when all T\+I compiler optimizations have been disabled  
\item Known and resolved issues with D\+S\+P tracing are logged on the \hyperlink{a00374}{Known Issues} page  
\end{DoxyItemize}

\hypertarget{a00362_subsection__testing_in_pro_tools}{}\subsubsection{Testing in Pro Tools}\label{a00362_subsection__testing_in_pro_tools}
 \hypertarget{a00362_subsubsection__the_system_usage_window_}{}\paragraph{The System Usage window}\label{a00362_subsubsection__the_system_usage_window_}
 The System Usage window in Pro Tools includes some features specifically targeted at testing D\+S\+P plug-\/ins, and particularly for testing shuffle events. Starting in Pro Tools 10, the System Usage window includes the following test features\+: 
\begin{DoxyItemize}
\item Shift + Drag D\+S\+P Meter -\/ This shuffles everything on the chosen chip to another chip, which allows you to quickly test shuffle for a given chip.  
\item Hover mouse over D\+S\+P -\/ Presents a tooltip to show the running plug-\/ins on a chip  
\item Cmd+\+Option+\+Shift Hover -\/ Detailed debugging tooltip info  
\item Cmd+\+Option+\+Shift Click -\/ Forces a full shuffle of all chips / cards 
\item Click on empty chip -\/ Reserves a D\+S\+P to prevent allocation on that chip 
\end{DoxyItemize}

\hypertarget{a00362_subsubsection__dsp_information_tooltip_}{}\paragraph{D\+S\+P information tooltip}\label{a00362_subsubsection__dsp_information_tooltip_}
 Pro Tools can display additional information for D\+S\+P plug-\/ins using some debug tooltips that are hidden in the plug-\/in window header and the System Usage window.

The tooltip in the plug-\/in window header displays information about the particular plug-\/in instance that is currently shown in the window. To display this tooltip, hold Command-\/\+Option-\/\+Shift (Mac) or Control-\/\+Alt-\/\+Shift (Windows) and hover the mouse cursor over the D\+S\+P $>$ Native button in the plug-\/in header.

The tooltip in the System Usage window displays usage information for each D\+S\+P chip in the system. You can reveal this tooltip for a particular chip by mousing over the chip\textquotesingle{}s usage meter while holding Command-\/\+Option-\/\+Shift (Mac) or Control-\/\+Alt-\/\+Shift (Windows). This tooltip shows the chip\textquotesingle{}s total allocated cycles, internal, and external memory.

The information in these tooltips is generally targeted at systems-\/level debugging, but can prove useful for some plug-\/in troubleshooting as well.

  Figure 1\+: D\+S\+P tooltip in the Pro Tools plug-\/in window header. 

  Figure 2\+: D\+S\+P tooltip in the Pro Tools System Usage window. 



 \hypertarget{a00362_aax_ti_guide_05_common_issues_with_ti_development}{}\subsection{Common Issues with T\+I Development}\label{a00362_aax_ti_guide_05_common_issues_with_ti_development}
 \hypertarget{a00362_subsection__data_structure_compatibility}{}\subsubsection{Data structure compatibility}\label{a00362_subsection__data_structure_compatibility}
A\+A\+X D\+S\+P plug-\/ins use a set of custom data structures to exchange information with host. In order to preserve a consistent binary interface between the plug-\/in\textquotesingle{}s host and algorithm, the layout of these structures must be identical on both platforms. Each structure must have the same size when compiled by both the host platform compiler and the T\+I D\+S\+P compiler, and any members that are referenced by both the host code and the D\+S\+P code must reside at the same offset within the struct on both platforms.

In order to satisfy this requirement, it is essential that an A\+A\+X plug-\/in\textquotesingle{}s algorithm context structure and any other data structures that are passed between the host and the D\+S\+P use appropriate alignment. Data structures are usually aligned to 32-\/bit boundaries, and both Intel and T\+I compilers use identical struct alignment and packing for most cases. However, this behavior is not explicitly defined in the C standard.

Furthermore, different compilers may use different sizes for some built-\/in data types. It is therefore very important to use explicitly-\/sized types such as {\ttfamily int32\+\_\+t} and {\ttfamily float} rather than ambiguous types such as {\ttfamily bool} or {\ttfamily int}. One particularly tricky data type is pointers, which may be compiled as 64-\/bit values on a 64-\/bit Intel system but as 32-\/bit values on the T\+I D\+S\+P.

Here are some specific scenarios when an unexpected difference in alignment or data type size may occur and cause an A\+B\+I incompatibility between a plug-\/in\textquotesingle{}s host and D\+S\+P components\+:


\begin{DoxyItemize}
\item \hyperlink{a00362_subsubsection__nested_structures}{Nested structures}  
\item \hyperlink{a00362_subsubsection__pragma_pack}{Usage of pragma pack}  
\item \hyperlink{a00362_subsubsection__dynamic_allocation_of_memory}{Dynamic allocation of memory in structures and algorithm}  
\item \hyperlink{a00362_subsubsection__incorrect_use_of_pointer_data}{Incorrect use of pointer data}  
\item \hyperlink{a00362_subsubsection__pointer_data_size_incompatibility}{Pointer data size incompatibility}  
\end{DoxyItemize}

\hypertarget{a00362_subsubsection__nested_structures}{}\paragraph{Nested structures}\label{a00362_subsubsection__nested_structures}
It can be particularly difficult to debug alignment issues in nested data structures. One reason is that nested structs do not necessarily have the same alignment as the parent struct. A nested structure will have the alignment that is set preceding its declaration, not the alignment of the structure in which it is contained.

Aside from avoiding nested structs entirely, one way to avoid potential issues is to make sure that nested structs always contain a double. This will guarantee that the structure is double-\/word aligned. We have also found that placing nested structs near the beginning of the parent struct results in more consistent alignment between Intel and T\+I compilers, even in cases where the actual alignment of each member is strictly ambiguous according to the standard.

Another important rule of thumb with nested structs is to define them inline in the enclosing structure. We have found that including one data structure as a member in another data structure will only be reliably aligned between Visual Studio and the T\+I compiler tools if the member structure\textquotesingle{}s type is defined in-\/line. This does not appear to be an issue between clang and the T\+I compiler -\/ the data structure alignment for the nested structure is consistent between those two compilers regardless of the location of the internal structure\textquotesingle{}s definition.


\begin{DoxyCode}
\textcolor{preprocessor}{#include AAX\_ALIGN\_FILE\_ALG}
\textcolor{keyword}{struct }SomeStruct
\{
   \textcolor{keywordtype}{float} a;
   \textcolor{keywordtype}{float} b;
\};
\textcolor{preprocessor}{#include AAX\_ALIGN\_FILE\_RESET}

\textcolor{comment}{// Somewhere else...}
\textcolor{preprocessor}{#include AAX\_ALIGN\_FILE\_ALG}
\textcolor{keyword}{class }SomeClass
\{
\textcolor{keyword}{public}:
   SomeStruct s; \textcolor{comment}{// Don't do this! Inconsistent between Visual Studio and TI}

   \textcolor{comment}{// other stuff...}
\};
\textcolor{preprocessor}{#include AAX\_ALIGN\_FILE\_RESET}
\end{DoxyCode}
  Listing 3\+: Problematic code\+: nested struct not defined in-\/line


\begin{DoxyCode}
\textcolor{preprocessor}{#include AAX\_ALIGN\_FILE\_ALG}
\textcolor{keyword}{class }SomeClass
\{
\textcolor{keyword}{public}:
   \textcolor{keyword}{struct }SomeStruct
   \{
      \textcolor{keywordtype}{float} a;
      \textcolor{keywordtype}{float} b;
   \} s; \textcolor{comment}{// This is fine - consistent between Visual Studio, clang, and TI}

   \textcolor{comment}{// other stuff...}
\};
\textcolor{preprocessor}{#include AAX\_ALIGN\_FILE\_RESET}
\end{DoxyCode}
  Listing 4\+: Fixed code\+: nested struct defined in-\/line

\hypertarget{a00362_subsubsection__pragma_pack}{}\paragraph{Usage of pragma pack}\label{a00362_subsubsection__pragma_pack}
If you use pragmas to align your structs, then you should know that in most cases it will only decrease the natural struct alignment of a compiler. That means that if you have


\begin{DoxyCode}
\textcolor{preprocessor}{#pragma pack(8)}
\textcolor{keyword}{struct }x
\{
   \textcolor{keywordtype}{char} a;
   \textcolor{keywordtype}{float} b;
\};
\end{DoxyCode}
  Listing 5\+: Example of usage of {\ttfamily \#pragma pack} where it has no effect

then struct x most likely won\textquotesingle{}t be aligned to the 8 byte boundary. Therefore the pack pragma is not really useful for addressing alignment issues. Instead of using pack, one way to guarantee that a structure is double-\/word aligned, is to include at least one double member.


\begin{DoxyCode}
\textcolor{preprocessor}{#pragma pack(8)}
\textcolor{keyword}{struct }x
\{
   \textcolor{keywordtype}{float} a;
   \textcolor{keywordtype}{double} b;
\};
\end{DoxyCode}
  Listing 6\+: Example of usage of {\ttfamily \#pragma pack} where it actually affects the alignment of the structure

In this case data will be double-\/word aligned.

\hypertarget{a00362_subsubsection__dynamic_allocation_of_memory}{}\paragraph{Dynamic allocation of memory in structures and algorithm}\label{a00362_subsubsection__dynamic_allocation_of_memory}
The problem with dynamic allocation is that it\textquotesingle{}s difficult to enforce specific alignment of the resulting block beyond the natural alignment of the structure. Newly allocated blocks are not double-\/word aligned by default. This prevents double-\/word memory access optimizations (see \hyperlink{a00362_subsubsection__additional_data_type_optimizations_}{Additional data type optimizations}) from working.


\begin{DoxyCode}
\textcolor{comment}{// blocks are not aligned to 8-byte boundaries by default. This prevents double-word}
\textcolor{comment}{// memory access optimizations from working}
\textcolor{keywordtype}{float}* floatBlock = \textcolor{keyword}{new} \textcolor{keywordtype}{float}[100];
\textcolor{keyword}{delete}[] floatBlock;

\textcolor{comment}{// Though AAX\_Alignment.h does include some aligned memory allocators to counteract the alignment}
\textcolor{comment}{// problem, their use is still strongly discouraged.}
\textcolor{keywordtype}{float}* floatBlock2 = alignMalloc<float>(100, 8);
\hyperlink{a00288_aa7d7e69902012a6272de3ea9aa0264a9}{alignFree}(floatBlock2);
\end{DoxyCode}
  Listing 7\+: Problems which may arise when using dynamic allocation of memory in algorithm

\hypertarget{a00362_subsubsection__incorrect_use_of_pointer_data}{}\paragraph{Incorrect use of pointer data}\label{a00362_subsubsection__incorrect_use_of_pointer_data}
In general, you should avoid storing pointers to anything in any data structures that are passed between the host and the D\+S\+P. There are many possible problems and bugs that can be caused by this, for example\+:


\begin{DoxyItemize}
\item Often the memory map of packets can change out from under the plug-\/in  
\item It is easy to accidentally reference data in the wrong memory space when setting pointer values  
\item Pointer data types are not explicitly sized (see \hyperlink{a00362_subsubsection__pointer_data_size_incompatibility}{below}.)  
\end{DoxyItemize}

One alternative to using raw data pointers is to store data offsets into a coefficient array rather than using direct pointers to other structure elements. A solution such as this that does not involve pointer data types will almost always end up being easier to implement, easier to troubleshoot, and easier to maintain than a solution that uses pointer data.

That said, if you must use pointer data types in any data structures that are passed between the A\+A\+X host and D\+S\+P components then you should be very careful to avoid the problems listed above.

\hypertarget{a00362_subsubsection__pointer_data_size_incompatibility}{}\paragraph{Pointer data size incompatibility}\label{a00362_subsubsection__pointer_data_size_incompatibility}
Problems due to pointer data size incompatibility can be particularly difficult to debug. Pointer data types are not explicitly sized in C, and, starting with the 64-\/bit Pro Tools 11 release, pointers will have different lengths for host and T\+I binaries. This can cause subtle portability problems in certain circumstances, if proper care is not taken.

Consider the following state block\+:


\begin{DoxyCode}
\textcolor{keyword}{struct }SMyPlugInStateBlock
\{
     \textcolor{keywordtype}{float} mInGain\_Smoothed;
     some\_t* mPointerP;
     \textcolor{keywordtype}{float} mOutGain\_Smoothed;
\};
\end{DoxyCode}


Notice the pointer {\ttfamily m\+Pointer\+P} (the type that it points to is irrelevant for this discussion). Perhaps it is a pointer that can reference different sets of coefficients, or perhaps it points to some sort of global variable. In any case, this pointer is 64-\/bits long on the host, and 32-\/bits long on T\+I.

In most cases, this won\textquotesingle{}t cause a problem because the host simply allocates a bit more space for the state block than the T\+I needs and fills the allocated memory with 0s. But consider the case where we overload \hyperlink{a00018_accef965824c9b158cafb65e59e216b6a}{Reset\+Field\+Data()} to set {\ttfamily m\+Out\+Gain\+\_\+\+Smoothed} to something other than 0\+:


\begin{DoxyCode}
\hyperlink{a00149_a4d8f69a697df7f70c3a8e9b8ee130d2f}{AAX\_Result} MyPlugIn\_Parameters::ResetFieldData (\hyperlink{a00149_ae807f8986143820cfb5d6da32165c9c7}{AAX\_CFieldIndex} inFieldIndex, \textcolor{keywordtype}{void}
       * inData, uint32\_t inDataSize)\textcolor{keyword}{ const}
\textcolor{keyword}{}\{
     \hyperlink{a00149_a4d8f69a697df7f70c3a8e9b8ee130d2f}{AAX\_Result} result;
     \textcolor{keywordflow}{switch} (inFieldIndex)
     \{
        \textcolor{keywordflow}{case} (eMyAlgFieldIndex\_State):
        \{
            memset(inData, 0, inDataSize);
            SMyPlugInStateBlock* stateP = \textcolor{keyword}{static\_cast<}SMyPlugInStateBlock*\textcolor{keyword}{>}(inData);
            stateP->mOutGain\_Smoothed = mOutGain\_Target;
            result = \hyperlink{a00207_a5f8c7439f3a706c4f8315a9609811937aeddbd1bb67e3a66e6af54a4b4a7a57b3}{AAX\_SUCCESS};
            \textcolor{keywordflow}{break};
        \}
        \textcolor{keywordflow}{default}:
        \{
            result = \hyperlink{a00018_accef965824c9b158cafb65e59e216b6a}{AAX\_CEffectParameters::ResetFieldData}(
      inFieldIndex, inData, inDataSize);
            \textcolor{keywordflow}{break};
        \}
     \}
     \textcolor{keywordflow}{return} result;
\}
\end{DoxyCode}


We might be doing this if {\ttfamily m\+Out\+Gain\+\_\+\+Smoothed} was a smoothing parameter and we want to start it at the target gain value (rather than having it smooth from 0.\+0 at instantiation). But if the Host and T\+I can\textquotesingle{}t agree on where in the state block m\+Out\+Gain\+\_\+\+Smooth is located, then the result will be unexpected behavior that is difficult to debug.

The most direct way to avoid this problem is to use an explicitly-\/sized 32-\/bit type for any pointers in your state block\+:


\begin{DoxyCode}
\textcolor{keyword}{struct }SMyPlugInStateBlock
\{
     \textcolor{keywordtype}{float} mInGain\_Smoothed;
     uint32\_t mPointerP;
     \textcolor{keywordtype}{float} mOutGain\_Smoothed;
\};
\end{DoxyCode}


It will be necessary to use {\ttfamily reinterpret\+\_\+cast$<$float$\ast$$>$(state\+P-\/$>$m\+Pointer\+P)} to recast the pointer to a pointer data type on the T\+I, but that should not result in any extra processing cycles.

\hypertarget{a00362_subsubsection__alignment_reference}{}\paragraph{Alignment Reference}\label{a00362_subsubsection__alignment_reference}
These are the data type sizes and default alignments for some common compilers when compiling for 64-\/bit binary formats\+:

\begin{TabularC}{9}
\hline
\rowcolor{lightgray}{\bf }&\multicolumn{2}{p{(\linewidth-\tabcolsep*9-\arrayrulewidth*5)*2/9}|}{\cellcolor{lightgray}\PBS\centering {\bf T\+I }}&\multicolumn{2}{p{(\linewidth-\tabcolsep*9-\arrayrulewidth*5)*2/9}|}{\cellcolor{lightgray}\PBS\centering {\bf M\+S Visual C++ }}&\multicolumn{2}{p{(\linewidth-\tabcolsep*9-\arrayrulewidth*5)*2/9}|}{\cellcolor{lightgray}\PBS\centering {\bf C++ Builder }}&\multicolumn{2}{p{(\linewidth-\tabcolsep*9-\arrayrulewidth*5)*2/9}|}{\cellcolor{lightgray}\PBS\centering {\bf G\+C\+C  }}\\\cline{1-9}
\rowcolor{lightgray}{\bf char }&\PBS\raggedleft 1 byte &1-\/byte aligned &\PBS\raggedleft 1 byte &1-\/byte aligned &\PBS\raggedleft 1 byte &1-\/byte aligned &\PBS\raggedleft 1 byte &1-\/byte aligned  \\\cline{1-9}
\rowcolor{lightgray}{\bf short }&\PBS\raggedleft 2 bytes &2-\/byte aligned &\PBS\raggedleft 2 bytes &2-\/byte aligned &\PBS\raggedleft 2 bytes &2-\/byte aligned &\PBS\raggedleft 2 bytes &2-\/byte aligned  \\\cline{1-9}
\rowcolor{lightgray}{\bf int }&\PBS\raggedleft 4 bytes &4-\/byte aligned &\PBS\raggedleft 4 bytes &4-\/byte aligned &\PBS\raggedleft 4 bytes &4-\/byte aligned &\PBS\raggedleft 4 bytes &4-\/byte aligned  \\\cline{1-9}
\rowcolor{lightgray}{\bf long }&\PBS\raggedleft 4 bytes &4-\/byte aligned &\PBS\raggedleft 8 bytes &8-\/byte aligned &\PBS\raggedleft 8 bytes &8-\/byte aligned &\PBS\raggedleft 8 bytes &8-\/byte aligned  \\\cline{1-9}
\rowcolor{lightgray}{\bf long long }&\PBS\raggedleft 8 bytes &8-\/byte aligned &\PBS\raggedleft 8 bytes &8-\/byte aligned &\PBS\raggedleft 8 bytes &8-\/byte aligned &\PBS\raggedleft 8 bytes &8-\/byte aligned  \\\cline{1-9}
\rowcolor{lightgray}{\bf bool }&\PBS\raggedleft 1 byte &1-\/byte aligned &\PBS\raggedleft 1 byte &1-\/byte aligned &\PBS\raggedleft 1 byte &1-\/byte aligned &\PBS\raggedleft 1 byte &1-\/byte aligned  \\\cline{1-9}
\rowcolor{lightgray}{\bf float }&\PBS\raggedleft 4 bytes &4-\/byte aligned &\PBS\raggedleft 4 bytes &4-\/byte aligned &\PBS\raggedleft 4 bytes &4-\/byte aligned &\PBS\raggedleft 4 bytes &4-\/byte aligned  \\\cline{1-9}
\rowcolor{lightgray}{\bf double }&\PBS\raggedleft 8 bytes &8-\/byte aligned &\PBS\raggedleft 8 bytes &8-\/byte aligned &\PBS\raggedleft 8 bytes &8-\/byte aligned &\PBS\raggedleft 8 bytes &8-\/byte aligned  \\\cline{1-9}
\rowcolor{lightgray}{\bf long double }&\PBS\raggedleft 8 bytes &8-\/byte aligned &\PBS\raggedleft 8 bytes &8-\/byte aligned &\PBS\raggedleft 8 bytes &8-\/byte aligned &\PBS\raggedleft 16 bytes &16-\/byte aligned  \\\cline{1-9}
\rowcolor{lightgray}{\bf pointer }&\PBS\raggedleft 4 bytes &4-\/byte aligned &\PBS\raggedleft 8 bytes &8-\/byte aligned &\PBS\raggedleft 8 bytes &8-\/byte aligned &\PBS\raggedleft 8 bytes &8-\/byte aligned  \\\cline{1-9}
\end{TabularC}


Also here are some useful links to web resources on the topic\+: 
\begin{DoxyItemize}
\item  A good resource for the T\+I D\+S\+P is \href{http://www.ti.com/lit/an/sprab89/sprab89.pdf}{\tt http\+://www.\+ti.\+com/lit/an/sprab89/sprab89.\+pdf} (Section 2 especially). This document includes some graphs of simple alignment examples.  


\item  Another good reference regarding general struct alignment issues is available from publib.\+boulder.\+ibm.\+com\+: \href{http://publib.boulder.ibm.com/infocenter/macxhelp/v6v81/index.jsp?topic=/com.ibm.vacpp6m.doc/compiler/ref/rnpgpack.htm}{\tt http\+://publib.\+boulder.\+ibm.\+com/infocenter/macxhelp/v6v81/index.\+jsp?topic=/com.\+ibm.\+vacpp6m.\+doc/compiler/ref/rnpgpack.\+htm}   
\end{DoxyItemize}



 \hypertarget{a00362_aax_ti_guide_06_ti_optimization_guide}{}\subsection{T\+I Optimization Guide}\label{a00362_aax_ti_guide_06_ti_optimization_guide}
Optimizing A\+A\+X real-\/time algorithms for Avid\textquotesingle{}s T\+I-\/based platforms is very similar to optimizing real-\/time algorithms for any architecture. When developers think about optimization, they often think \char`\"{}\+I want to make my code run faster\char`\"{}. In reality, however, optimization is about making the processor do less. After all, the processor\textquotesingle{}s clock rate is fixed and can only perform a limited number of instructions in a set amount of time. Therefore, our focus in this section will be on helping the compiler produce code with shorter execution paths and make full use of the T\+I chip\textquotesingle{}s architecture.

Modern compilers have become extremely powerful at being able to optimize code, which is fortunate given the complicated architectures of today\textquotesingle{}s D\+S\+P products. In this section we will not focus on instruction-\/level \char`\"{}optimizations\char`\"{} like the one below, which will automatically be done by the compiler. Instead of making our code faster, which it won\textquotesingle{}t, little \char`\"{}tricks\char`\"{} like this really just make code harder to read\+:


\begin{DoxyCode}
\textcolor{keywordtype}{int} y = x;
y = y >> 1; \textcolor{comment}{// y = y / 2; }
\end{DoxyCode}
  Listing 8\+: The kind of optimization that you won\textquotesingle{}t be seeing in this section

Rather, we will focus on refactoring audio processing algorithms to be more efficient and on giving the T\+I compiler better information about the code, pointers, and data it is working with so it can perform more effective compile-\/time optimizations.

Finally, our optimization efforts will focus on the worst-\/case code path. For example, developers often try to optimize algorithms by conditionally bypassing portions of code that may be disabled by particular parameter states. This is counter-\/productive, because the system has to assume a plug-\/in\textquotesingle{}s worst-\/case execution performance regardless of how much time the plug-\/in is actually using. Therefore, in the context of real-\/time algorithms running on A\+A\+X D\+S\+P platforms, it is best to only worry about worst-\/case execution time.

For more information about using T\+I\textquotesingle{}s toolset to profile your code\textquotesingle{}s performance, see \hyperlink{a00365_subsection__cyclessharedtest}{Cycle count performance test}.

\begin{DoxyNote}{Note}
The optimizations described in this section assume that you are using version 7 or higher of T\+I\textquotesingle{}s C6000 Code Generation Tools (C\+G\+Tools). We strongly recommend using v7.\+0.\+5 as earlier versions throw linking errors.
\end{DoxyNote}
\hypertarget{a00362_subsection__optimization_quick_start}{}\subsubsection{Optimization quick start}\label{a00362_subsection__optimization_quick_start}
Here is a quick outline of the general optimization steps for an A\+A\+X D\+S\+P algorithm\+: 
\begin{DoxyEnumerate}
\item Before beginning your D\+S\+P optimizations, make sure that your Native algorithm has basic optimizations in place. In our experience, beginning the T\+I optimization process with a slow or needlessly precise Native algorithm will result in a long porting process. Here are some suggestions for common Native optimizations\+: 
\begin{DoxyItemize}
\item Identify unnecessary double precision  
\item Identify tables that have too high of granularity  
\end{DoxyItemize}
\item Make sure your compiler Release settings enable the compiler to optimize fully and give full optimization comments\+:  {\ttfamily -\/k -\/s -\/pm -\/op3 -\/os -\/o3 -\/mo -\/mw â€“consultant â€“verbose -\/mv67p}  
\item Use the load/update/store design pattern to reduce memory accesses in inner loops  
\item Move any processing that does not directly depend on the audio signal out of the real-\/time algorithm  
\item Declare non-\/changing variables and pointers (both local and in parameter lists) as {\ttfamily const}  
\item Declare non-\/aliased pointers (both local variables and function parameters) as A\+A\+X\+\_\+\+R\+E\+S\+T\+R\+I\+C\+T  
\item Change any {\ttfamily long} variables to{\itshape  } {\ttfamily int}, and change {\ttfamily double} variables to {\ttfamily float} if the reduced precision does not affect signal integrity (usually defined as cancellation with the plug-\/in\textquotesingle{}s Native algorithm.)  
\item Restructure inner processing loops so that they do not contain large conditional statements or other branches  
\item Declare any functions that are called within the innermost processing loop as {\ttfamily inline} in order to allow the inner loops to pipeline  
\item Add loop count information when known, using {\ttfamily \#pragma M\+U\+S\+T\+\_\+\+I\+T\+E\+R\+A\+T\+E(min,max,quant)} 
\end{DoxyEnumerate}

\hypertarget{a00362_subsection__compiler_and_linker_options}{}\subsubsection{Compiler and linker options}\label{a00362_subsection__compiler_and_linker_options}
As with any complex environment, many performance gains on the T\+I rely on the appropriate compiler and linker options. The options documented here will allow C\+G\+Tools to apply its optimization logic to your algorithm.

When tweaking compiler options on the T\+I, keep in mind that, like on any C\+P\+U, it is useless to optimize Debug code or to profile its performance. This is especially true on T\+I processors because of the fact that generated Debug and Release assembly is almost completely different, assuming that heavy optimization options were chosen for the Release configuration.

In general, all recommended compiler options should be set correctly in the A\+A\+X S\+D\+K\textquotesingle{}s example plug-\/in projects, and these settings may be used as a guide for your own plug-\/in projects. See the S\+D\+K files Common\+Plug\+In\+\_\+\+Compiler\+Cmd.\+cmd and Common\+Plug\+In\+\_\+\+Linker\+Cmd.\+cmd for the latest recommended settings.

\hypertarget{a00362_subsubsection__overview_of_optimizationrelated_compiler_options_}{}\paragraph{Overview of optimization-\/related compiler options}\label{a00362_subsubsection__overview_of_optimizationrelated_compiler_options_}
 
\begin{DoxyItemize}
\item {\ttfamily -\/g}  Full symbolic debug. This setting should be used in debug configurations to make stepping through code easier. It should not be defined in release configurations, as it will prevent the compiler from being able to fully optimize code.  


\item {\ttfamily -\/k}  Keep generated .asm files. This should be turned on in release configuraions so that you can use the A\+S\+M output as feedback when making optimization decisions and performance improvements.  


\item {\ttfamily -\/d\char`\"{}\+\_\+\+D\+E\+B\+U\+G\char`\"{}}  Defines the {\ttfamily \+\_\+\+D\+E\+B\+U\+G} preprocessor macro that alters how certain code is generated (asserts, stdlib, etc). This should be turned on in debug configurations only. Note that T\+I does not require N\+D\+E\+B\+U\+G to be defined in release configurations.

\begin{DoxyNote}{Note}
This will eventually be deprecated in favor of the pre-\/defined \char`\"{}\+\_\+\+T\+M\+S320\+C6\+X\char`\"{} macro.
\end{DoxyNote}
 


\item {\ttfamily -\/mv67p}  Specifies that the compiler should build code for the C67x+ chip variant we are using, which has some improvements beyond the original C67x. This option should be enabled in all build configurations that target the H\+D\+X platform.  


\item {\ttfamily -\/s}  Specifies Opt-\/\+C/\+A\+S\+M interlisting. This interweaves modified C-\/code and A\+S\+M in the .A\+S\+M file produced by the {\ttfamily -\/k} option. You should use {\ttfamily -\/s} in release configurations so that the A\+S\+M file can be read more easily.

\begin{DoxyNote}{Note}
Do N\+O\+T use the {\ttfamily -\/ss} option in release configurations. This option will negatively affect optimization
\end{DoxyNote}
 


\item {\ttfamily -\/pm}  Program mode compilation. Instructs the C compiler to compile all files in the same compilation unit, so that it can optimize code further using information from all files being compiled. See \hyperlink{a00362_subsubsection__program_mode_optimization_pm_}{Program Mode optimization (-\/pm)} for more information.  


\item {\ttfamily -\/op3}  A modifier for the -\/pm option, this specifies that there are no external variable references in the project. This option is appropriate for T\+I algorithms, which do have an external function reference (the process entry point) but do not have external variable references. This option allows the compiler to further optimize global variables without worrying whether they will be accessed outside of the compilation unit. See \hyperlink{a00362_subsubsection__program_mode_optimization_pm_}{Program Mode optimization (-\/pm)} for more information  


\item {\ttfamily -\/o3}  File-\/level optimization. This flag gives the compiler full ability to optimize C-\/code by reordering instructions, inlining functions, and performing other optimizations. Note that the resulting A\+S\+M code will be very difficult to parse back into the original C and will make debugging very difficult, so this flag should only be used for Release code. See \hyperlink{a00362_subsubsection__optimization_flags_o_}{Optimization flags (-\/o)} for more information.  


\item {\ttfamily -\/mo}  Use Function Subsections. This instructs the compiler to place all functions into their own separate subsection in the linker map. This allows the linker to remove unused functions in order to reduce memory usage.  


\item {\ttfamily -\/mw}  Generate a single iteration view of S\+P loops. This flag adds important information to the A\+S\+M output file that is useful when optimizing your code for pipelined loops.  


\item {\ttfamily â€“verbose}  Output verbose status messages when compiling files. Though not very useful for humans, verbose output will produce some key information that text parsers can use, such as compiler versions and other details.  


\end{DoxyItemize}

\hypertarget{a00362_subsubsection__overview_of_optimizationrelated_linker_options_}{}\paragraph{Overview of optimization-\/related linker options}\label{a00362_subsubsection__overview_of_optimizationrelated_linker_options_}
 
\begin{DoxyItemize}
\item {\ttfamily â€“relocatable}  Generate a relocatable non-\/executable.  


\item {\ttfamily -\/m\char`\"{}file.\+map\char`\"{}}  Generate a map file. This file contains useful information about the memory footprint of your plug-\/in, which is useful for fixing large plug-\/ins that may not have fit into available program memory.  


\item {\ttfamily -\/w}  Warn about output sections. This flag generates very useful information that tells you if there might be a problem with memory output sections you are trying to generate.  


\item {\ttfamily -\/x}  Exhaustively read libraries. This is a useful flag if you do not want to worry about the order in which you specify required libraries.  


\end{DoxyItemize}

\hypertarget{a00362_subsubsection__optimization_flags_o_}{}\paragraph{Optimization flags (-\/o)}\label{a00362_subsubsection__optimization_flags_o_}
 
\begin{DoxyItemize}
\item Register ({\ttfamily -\/o0})  This option allows for some performance gains over non-\/optimized code by allocating variables to registers, inlining functions declared inline, etc.  


\item Local ({\ttfamily -\/o1})  This option enables local optimizations, with very similar results to the register-\/level optimizations of -\/o0.  


\item Function ({\ttfamily -\/o2})  This is the standard optimization level, and provides large gains over unoptimized code. This optimization level allows function-\/level optimizations such as software pipelining, loop optimization/unrolling, etc.  


\item File (-\/{\ttfamily o3})  This option can provide some speedup beyond function-\/level optimizations, but also mutilates assembly code beyond recognition. At this optimization level the compiler will remove unused functions, simplify code in the case of unused return values, auto-\/inline small functions, etc.  


\end{DoxyItemize}

Like the corresponding Visual Studio options,{\ttfamily -\/o0} and {\ttfamily -\/o1} allow you to step through code line-\/by-\/line for debugging, at the cost of reduced performance. {\ttfamily -\/o2} and {\ttfamily -\/o3} sacrifice the ability to step through code and watch memory in favor of optimized code.

\hypertarget{a00362_subsubsection__program_mode_optimization_pm_}{}\paragraph{Program Mode optimization (-\/pm)}\label{a00362_subsubsection__program_mode_optimization_pm_}
 Program mode optimization gives the compiler further optimization information by compiling all files at once rather than individually. Thus global constants, function implementations, etc. can be made known to the entire program at compilation. This allows the compiler to inline functions more effectively and to determine loop unrolling based on constant loop iterators.

There are a few {\ttfamily -\/pm} options\+:


\begin{DoxyItemize}
\item {\ttfamily -\/pm -\/op0}  Contains functions and variables that are called or modified from outside the source code provided to the compiler.  


\item {\ttfamily -\/pm -\/op1}  Contains variables modified from outside the source code provided to the compiler but does not use functions called from outside the source code. 

 {\itshape  This option is not appropriate for A\+A\+X plug-\/in algorithms, because the algorithm component will be exported and called from outside the compiled source code.}  


\item {\ttfamily -\/pm -\/op2}  Contains no functions or variables that are called or modified from outside the source code provided to the compiler. 

 {\itshape  This option is not appropriate for A\+A\+X plug-\/in algorithms, because the algorithm component will be exported and called from outside the compiled source code.}  


\item {\ttfamily -\/pm -\/op3}  Contains functions that are called from outside the source code provided to the compiler but does not use variables modified from outside the source code.  

 This is the recommended Program Mode optimization level for T\+I plug-\/ins. This optimization level requires that no global variables are used outside of the algorithm callback. In general, any such variables should be passed in to a T\+I algorithm via the algorithm\textquotesingle{}s context structure.  
\end{DoxyItemize}

\hypertarget{a00362_subsubsection__compiler_options_to_avoid_}{}\paragraph{Compiler options to avoid}\label{a00362_subsubsection__compiler_options_to_avoid_}
 The following information was taken from the T\+M\+S320\+C6000 Programmer\textquotesingle{}s Guide\+:


\begin{DoxyItemize}
\item {\ttfamily -\/g/-\/s/-\/ss}  These options limit the amount of optimization across C statements, leading to larger code size and slower program execution.  


\item {\ttfamily -\/mu}  This option disables software pipelining for debugging. If a reduction in code size is necessary, use the {\ttfamily -\/ms2}/{\ttfamily -\/ms3} options. These options will disable software pipelining among their other code size optimizations.  


\item {\ttfamily -\/mz}  This option is obsolete. When using 3.\+00+ compilers, this option will decrease performance and increase code size.  


\end{DoxyItemize}

\hypertarget{a00362_subsection__the_loadupdatestore_pattern}{}\subsubsection{The load-\/update-\/store pattern}\label{a00362_subsection__the_loadupdatestore_pattern}
 The load-\/update-\/store pattern is one of the cornerstones of a fast iterative algorithm. This pattern specifies that locally accessed data should be loaded into memory at the start of processing, accessed during processing, and stored or saved after processing has completed. By using this pattern you will move memory reads and writes outside of your plug-\/in\textquotesingle{}s innermost processing loop, which reduces data dependencies and shortens the critical inner loop.

As an example, consider the following unoptimized filter code\+:


\begin{DoxyCode}
\textcolor{keyword}{inline} \textcolor{keywordtype}{void}
ProcessDirectFormII(\textcolor{keywordtype}{float}* input, \textcolor{keywordtype}{float}* output, \textcolor{keywordtype}{float}* state, \textcolor{keywordtype}{float}*
    coefs, \textcolor{keywordtype}{int} nsamp)
\{
    \textcolor{comment}{// eB0 .. eB2 and eA0, eA1 are just integer enums to partition}
    \textcolor{comment}{// the filter coefficients into A and B}
    \textcolor{keywordflow}{for}(\textcolor{keywordtype}{int} i = 0; i < nsamp; ++i)
    \{
        output[i] = input[i]*coefs[eB0] + state[0];
        state[0] = input[i]*coefs[eB1] + state[1] - output[i]*coefs[eA0];
        state[1] = input[i]*coefs[eB2] - output[i]*coefs[eA1];
    \}
\} 
\end{DoxyCode}
  Listing 9\+: Unoptimized filter algorithm

Notice that in this code there are at least 15 memory accesses per loop iteration! This algorithm will be very inefficient as the value of {\ttfamily nsamp} increases.

The compiler should be able to optimize this algorithm to some extent by pulling certain memory accesses outside of the loop. However, the compiler cannot completely optimize the loop because it must assume that the input/output/state/coefs pointers are aliased in memory. We will discuss the {\ttfamily const} and {\ttfamily restrict} keywords later, which are ways to give the compiler additional information it can use to optimize this loop. However, for now let\textquotesingle{}s focus back on the basic design of this code.

Using load-\/update-\/store, we can refactor this loop to pull the memory accesses outside of the loop\+:


\begin{DoxyCode}
\textcolor{keywordtype}{void}
ProcessDirectFormII (\textcolor{keywordtype}{float}* input, \textcolor{keywordtype}{float}* output, \textcolor{keywordtype}{float}* state, \textcolor{keywordtype}{float} *
    coefs, \textcolor{keywordtype}{int} nsamp)
\{
    \textcolor{comment}{// eB0 .. eB2 and eA0, eA1 are just integer enums to partition}
    \textcolor{comment}{// the filter coefficients into A and B}

    \textcolor{comment}{// ---- LOAD ----}
    \textcolor{keywordtype}{float} coefA0 = coefs [eA0];
    \textcolor{keywordtype}{float} coefA1 = coefs [eA1];
    \textcolor{keywordtype}{float} coefB0 = coefs [eB0];
    \textcolor{keywordtype}{float} coefB1 = coefs [eB1];
    \textcolor{keywordtype}{float} coefB2 = coefs [eB2];

    \textcolor{keywordtype}{float} state0 = state [0];
    \textcolor{keywordtype}{float} state1 = state [1];

    \textcolor{keywordtype}{float} output;

    \textcolor{comment}{// ---- UPDATE ----}
    \textcolor{keywordflow}{for} (\textcolor{keywordtype}{int} i = 0; i < nsamp; ++i)
    \{
        output = input [i]* coefB0 + state0;
        state0 = input [i]* coefB1 + state1 - output * coefA0;
        state1 = input [i]* coefB2 - output * coefA1;
        output [i] = output;
    \}

    \textcolor{comment}{// ---- STORE ----}
    state [0] = state0;
    state [1] = state1;
\} 
\end{DoxyCode}
  Listing 10\+: Refactored filter algorithm with load-\/update-\/store pattern applied. Not fully optimized.

Though the code initially appears longer, you will notice that we have reduced the loop to only 4 memory accesses! Though we have an additional 9 memory accesses outside the loop, they will only occur once per function call, resulting in significant savings at higher values of {\ttfamily nsamp}.

\begin{DoxyNote}{Note}
we are not finished with this loop yet, because we can make some very significant gains by using the {\ttfamily restrict} and {\ttfamily const} keywords, as discussed in the section on \hyperlink{a00362_subsection__c_keywords}{C keywords}.
\end{DoxyNote}
Before moving on from load-\/update-\/store, let\textquotesingle{}s consider how this pattern should be applied to different categories of data that may be provided in an A\+A\+X D\+S\+P processing context\+:


\begin{DoxyItemize}
\item Coefficients and parameters  Coefficients and parameters are read-\/only by definition. As such, they should be loaded into a local variable at the beginning of the algorithm callback and should not be modified further.  


\item Private state  State parameters are writable and may be changed by the algorithm. Therefore, private state data should be loaded into a local variable copy, then stored back into memory after the local copy is updated.  


\item Output  Output is write-\/only, so all calculations may be performed on a local variable and then stored into memory once per loop.  


\end{DoxyItemize}

\hypertarget{a00362_subsection__case_study_iir_filter_implemenation_on_ti_672x_dsps}{}\subsubsection{Case study\+: I\+I\+R filter implemenation on T\+I 672x D\+S\+Ps}\label{a00362_subsection__case_study_iir_filter_implemenation_on_ti_672x_dsps}
 In this section we will examine various I\+I\+R filter implementations as a specific example of the considerations that must be made when optimizing D\+S\+P code for the 672x.

The T\+I 67xx family of D\+S\+Ps is notably different from some other typical D\+S\+P processors, such as the 56k and the Intel F\+P\+U, in that the T\+I D\+S\+P does not have an implicit higher-\/precision multiply-\/accumulate. It is of course capable of double precision accumulation, but this must be coded explicitly. In some ways, this is similar to the Intel S\+S\+E processing unit, which jetisonned the 80-\/bit floating point stack used in the Intel F\+P\+U. The lack of higher precision accumulation in T\+I (and S\+S\+E) can sometimes result in unacceptable quantization noise performance for single precision filter implementations. Luckily, with the right choice of filter structure or coding for explicit double precision accumulation, excellent results can be achieved.

On fixed-\/point D\+S\+Ps such as 56k, Direct Form I (D\+F1) implementation is the standard due to moderately good fixed point scaling properties, decent noise performance, and simple implementation. However, on a 672x D\+S\+P a single precision D\+F1 filter can have terrible noise performance (depending on the filter coefficients and the audio material being processed.) A degenerate case is a D\+F1 highpass filter processing low frequency material; in D\+F1, the feedforward coefficients subtract the previous sample from the current sample, and for low frequency material this produces very small numbers with low precision. Single precision D\+F2 structures also produce similarly poor results in this respect.

One option to improve upon these results is to use double precision throughout the 672x filter implementation. However, this results in a heavy cycle performance penalty due to the high cost of double operations on the T\+I D\+S\+P. Another, often better, option is to use single precision coefficients and state, with double precision accumulation\+:


\begin{DoxyCode}
\textcolor{keywordtype}{float} in, b0, b1, a1, state1;
\textcolor{keywordtype}{double} accum ;
accum = double (b0) * double (in) +
        double (b1) * double (state1) +
        double (a1) * double (accum);
state1 = in; 
\end{DoxyCode}
  Listing 11\+: Mixed-\/precision D\+F1 filter implementation

The T\+I compiler will implement this using the mpysp2dp instruction, since it knows that the operands started out as single precision and end up as double precision. This is considerably faster than going to a full double precision implementation, but it is still relatively slow compared to straight single precision. Making the state double precision will improve noise performance further, with some increase in cycle usage.

Another option that generally gets good results is the single precision D\+F2 Transpose (D\+F2\+T) filter. On T\+I the D\+F2\+T implementation is fast and generally has good noise performance. If you are looking for a simple recommendation that should work well enough for most applications, D\+F2\+T is a good choice.

The optimized C filter library available from T\+I uses the D\+F2 structure in its implementation. Even though D\+F2 has some limitations, this is a good starting point for seeing how to optimize filter code on T\+I; peak performance on T\+I is 2.\+25 cycles per biquad, so it\textquotesingle{}s pretty amazing what can be done (to achieve that level of performance multiple series or parallel biquads need be put in a tight loop.) We have adapted some of this filter code to D\+F2\+T, and still achieved fairly similar cycle performance.

If the single precision D\+F2\+T noise performance is not good enough for your application, then either double precision or one of the myriad other filter structures, such as State Space, Gold-\/\+Rader, Lattice or Zolzer, should do the job. In fact, there is one relatively new filter structure which we think stands out, called the Direct Wave Form (D\+W\+F) filter. Details about this filter structure can be found in {\itshape  Direct Wave Form Digital Filter Structure\+: an Easy Alternative for the Direct Form} by Jean H.\+F. Ritzerfel. According to the author the noise performance is 3d\+B within optimal, it\textquotesingle{}s relatively efficient (5 multiplies per biquad), free of limit cycles, has simple coefficient generation and low coefficient quantization sensitivity. It might just be the perfect filter structure, but we\textquotesingle{}ll let you be the judge of that; keep in mind that all filter structures have some tradeoffs, and the recommendations made here might not be the best for your particular application.

\hypertarget{a00362_subsection__understanding_cgtoolsgenerated_asm_files}{}\subsubsection{Understanding C\+G\+Tools-\/generated A\+S\+M files}\label{a00362_subsection__understanding_cgtoolsgenerated_asm_files}
 The ability to read the A\+S\+M files that are generated by C\+G\+Tools is essential when optimizing a T\+I algorithm. Specifically, the information in these files will allow you to determine if anything is preventing software pipelining from occurring, which is the single most effective form of optimization on the C6727.

To view your project\textquotesingle{}s A\+S\+M file, turn on the {\ttfamily -\/k} compiler option (\char`\"{}\+Keep Generated .\+asm Files\char`\"{}, found under Build Options $>$ Compiler $>$ Assembly in the Code Composer Studio I\+D\+E.) By default, A\+S\+M files will be placed in the same directory as the corresponding source file.

\begin{DoxyNote}{Note}
You should only examine A\+S\+M listings of Release code that has been optimized by the compiler. Debug code should not be optimized.
\end{DoxyNote}
Each A\+S\+M file for a T\+I algorithm callback should contain text that marks the start of the assembly listing for the processing loop. For example\+:


\begin{DoxyCode}
;**********************************************************************
;* FUNCTION NAME: \textcolor{comment}{// [Your algorithm's ProcessProc symbol] \_\_\_\_\_\_\_\_\_\_\_*}
;*\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_*
;* Regs Modified: A0,A1,A2,A3,A4,A5,A6,A7,A8,A9,A10,A11,A12,A13,A14, \_*
;*\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_A15,B0,B1,B2,B3,B4,B5,B6,B7,B8,B9,B10,B11,B12, \_\_\_\_\_*
;* \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_B13,SP,A16,A17,A18,A19,A20,A21,A22,A23,A24,A25, \_\_\_\_*
;*\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_A26,A27,A28,A29,A30,A31,B16,B17,B18,B19,B20,B21, \_\_\_*
;* \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_B22,B23,B24,B25,B26,B27,B28,B29,B30, B31 \_\_\_\_\_\_\_\_\_\_\_*
;* Regs Used\_\_\_\_: A0,A1,A2,A3,A4,A5,A6,A7,A8,A9,A10,A11,A12,A13,A14, \_*
;* \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_A15,B0,B1,B2,B3,B4,B5,B6,B7,B8,B9,B10,B11,B12, \_\_\_\_\_*
;* \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_B13,DP,SP,A16,A17,A18,A19,A20,A21,A22,A23,A24, \_\_\_\_\_*
;* \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_A25,A26,A27,A28,A29,A30,A31,B16,B17,B18,B19,B20, \_\_\_*
;* \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_B21,B22,B23,B24,B25,B26,B27,B28,B29,B30,B31 \_\_\_\_\_\_\_\_*
;* Local Frame Size: 0 Args + 148 Auto + 44 Save = 192 byte \_\_\_\_\_\_\_\_\_\_*
;********************************************************************** 
\end{DoxyCode}
  Listing 12\+: C\+G\+Tools-\/generated header for a processing loop assembly listing

Within this listing, you are looking for several things\+: 
\begin{DoxyEnumerate}
\item Function calls  
\item Branches or control code  
\item Software pipelining notes  
\end{DoxyEnumerate}

\hypertarget{a00362_subsubsection__function_calls_}{}\paragraph{Function calls}\label{a00362_subsubsection__function_calls_}



\begin{DoxyCode}
   [!B0]  CALL  .S1   \_\_divd         ; |213|
|| [!B0]  MVKH  .S2   0x40080000 ,B5 ; |213|
|| [ B0]  MV    .L1X  B10 ,A4        ; |213|
$C$RL9 : ; CALL OCCURS \{\_\_divd\}      ; |213| 
\end{DoxyCode}
  Listing 13\+: Function call in a C\+G\+Tools-\/generated assembly listing

Function calls, such as the call in the listing above, cannot be effectively pipelined. If you find a function call figure out what C instruction it is caused by. Sometimes a function call will be made implicitly, such as when casting from float to int or when doing division. All function calls should be removed from the processing loop or inlined in order for the compiler to optimize effectively.

\hypertarget{a00362_subsubsection__branches_}{}\paragraph{Branches}\label{a00362_subsubsection__branches_}



\begin{DoxyCode}
    NOP          1
    B     .S1    $C$L5                 ; |213|
    NOP          4
    MPYDP .M1X   A5:A4 ,B5:B4 ,A11:A10 ; |213|
||  LDW   .D2T2  *+ SP (124) ,B5       ; |218|
    ; BRANCH OCCURS \{ $C$L5 \}          ; |213| 
\end{DoxyCode}
  Listing 14\+: Branch in a C\+G\+Tools-\/generated assembly listing

Branches can also prevent loop pipelining. If you find a branch in your algorithm\textquotesingle{}s assembly, determine whether it is preventing the compiler from pipelining a loop. If it is preventing pipelining, you must figure out how to rewrite the conditional in your C code so that it will not be compiled into a branch.

\hypertarget{a00362_subsubsection__software_pipelining_notes_}{}\paragraph{Software pipelining notes}\label{a00362_subsubsection__software_pipelining_notes_}
 For each loop the compiler finds and is able to pipeline, the .A\+S\+M file should contain a section similar to the one below\+:

~


\begin{DoxyCode}
;*--------------------------------------------------------------------*
;* SOFTWARE PIPELINE INFORMATION
;*
;* Loop source line : 68
;* Loop opening brace source line : 69
;* Loop closing brace source line : 124
;* Loop Unroll Multiple : 2x
;* Known Minimum Trip Count : 1
;* Known \hyperlink{a00288_a55ac62cf1b543338c58f8dd0d747c56c}{Max} Trip Count Factor : 1
;* Loop Carried Dependency Bound (^) : 15
;* Unpartitioned Resource Bound : 20
;* Partitioned Resource Bound (*) : 20
;* Resource Partition :
;* A- side B- side
;* .L units 0 0
;* .S units 0 1
;* .D units 20* 20*
;* .M units 7 5
;* .X cross paths 5 6
;* .T address paths 20* 20*
;* Long read paths 5 1
;* Long write paths 0 0
;* Logical ops (. LS) 5 4 (.L or .S unit )
;* Addition ops (. LSD) 0 1 (.L or .S or .D unit )
;* Bound (.L .S .LS) 3 3
;* Bound (.L .S .D .LS .LSD) 9 9
;*
;* Searching \textcolor{keywordflow}{for} software pipeline schedule at ...
;* ii = 20 Schedule found with 3 iterations in parallel 
\end{DoxyCode}
  Listing 15\+: Pipelined loop header in a C\+G\+Tools-\/generated assembly listing

These are the important items to note in this listing\+:


\begin{DoxyItemize}
\item {\ttfamily Loop Carried Dependency Bound} and {\ttfamily Partitioned Resource Bound}  The maximum of these numbers is the minimum number of clock cycles one instance of the loop will require in its current form. You can reduce these numbers by performing some of the optimizations listed in this guide.  


\item {\ttfamily Loop Unroll Multiple}  This line will appear if the compiler is partially unrolling the loop to improve performance.  


\end{DoxyItemize}

If a loop section instead displays {\ttfamily Disqualified loop}\+: then some of the conditions required to enable software pipelining have not been met\+:


\begin{DoxyItemize}
\item {\ttfamily -\/o2} or -\/{\ttfamily o3} optimizations must be enabled  
\item The loop cannot contain a function call. Make all called functions inline.  
\item The loop cannot contain any branches or jumps, often caused by large conditional statements  
\item Software pipelining will not work with nested loops; only the innermost loop will be pipelined. You should completely unroll the inner loop or refactor the algorithm so that the loop can be pipelined  
\end{DoxyItemize}

For more information about pipelining and loop/branch optimization, see \hyperlink{a00362_subsection__refactoring_conditionals_and_branches}{Refactoring conditionals and branches}.

\hypertarget{a00362_subsection__c_keywords}{}\subsubsection{C keywords}\label{a00362_subsection__c_keywords}
There are a few keywords in C that give the compiler additional information about the variables you declare and parameters you pass into functions. This allows the compiler to further optimize the code it is compiling, which can result in significant performance gains.

\hypertarget{a00362_subsubsection__const_}{}\paragraph{const}\label{a00362_subsubsection__const_}
 Effective use of {\ttfamily const} lets the compiler know whether pointers, scalars, or objects will remain constant in memory.

Let\textquotesingle{}s add the {\ttfamily const} keyword to the filter function from our example of \hyperlink{a00362_subsection__the_loadupdatestore_pattern}{The load-\/update-\/store pattern}.


\begin{DoxyCode}
\textcolor{keywordtype}{void}
ProcessDirectFormII (
    \textcolor{keyword}{const} \textcolor{keywordtype}{float} * \textcolor{keyword}{const} input, \textcolor{comment}{// read - only}
    \textcolor{keywordtype}{float} * \textcolor{keyword}{const} output, \textcolor{comment}{// read - write}
    \textcolor{keywordtype}{float} * \textcolor{keyword}{const} state, \textcolor{comment}{// read - write}
    \textcolor{keyword}{const} \textcolor{keywordtype}{float} * \textcolor{keyword}{const} coefs , \textcolor{comment}{// read - only}
    \textcolor{keywordtype}{int} nsamp )
\{
    \textcolor{comment}{// eB0 .. eB2 and eA0, eA1 are just integer enums to partition}
    \textcolor{comment}{// the filter coefficients into A and B}

    \textcolor{comment}{// ---- LOAD ----}
    \textcolor{keyword}{const} \textcolor{keywordtype}{float} coefA0 = coefs [ eA0 ];
    \textcolor{keyword}{const} \textcolor{keywordtype}{float} coefA1 = coefs [ eA1 ];
    \textcolor{keyword}{const} \textcolor{keywordtype}{float} coefB0 = coefs [ eB0 ];
    \textcolor{keyword}{const} \textcolor{keywordtype}{float} coefB1 = coefs [ eB1 ];
    \textcolor{keyword}{const} \textcolor{keywordtype}{float} coefB2 = coefs [ eB2 ];

    \textcolor{keywordtype}{float} state0 = state [0];
    \textcolor{keywordtype}{float} state1 = state [1];

    \textcolor{comment}{// ---- UPDATE ----}
    \textcolor{keywordflow}{for} (\textcolor{keywordtype}{int} i =0; i&lt; nsamp; ++i)
    \{
        \textcolor{keyword}{const} \textcolor{keywordtype}{float} output = input [i]* coefB0 + state0 ;
        state0 = input [i]* coefB1 + state1 - output * coefA0 ;
        state1 = input [i]* coefB2 - output * coefA1;
        output [i] = output;
    \}

    \textcolor{comment}{// ---- STORE ----}
    state [0] = state0;
    state [1] = state1;
\} 
\end{DoxyCode}
  Listing 16\+: Refactored filter algorithm with load-\/update-\/store pattern and const keyword applied. 

It is especially important to note that the declaration of {\ttfamily const float output} was moved inside the loop. Why did we do this? Because we see that output is constant over an iteration of the loop, but it does change between iterations. By declaring it {\ttfamily const} inside the loop body we remove the data dependency that existed in output and allow the loop to optimize more effectively.

As demonstrated by this change to {\ttfamily const float output}, {\ttfamily const} is useful for manually breaking dependencies in D\+S\+P code. Variable re-\/use introduces unnecessary data dependencies in code, which can be avoided by using individual local const variables.

\hypertarget{a00362_subsubsection__restrict_}{}\paragraph{restrict}\label{a00362_subsubsection__restrict_}
 The {\ttfamily restrict} keyword tells the compiler that a specific pointer is not aliased, meaning that none of the memory locations accessed by the pointer are read or written to by any other variable within its local scope. This keyword is very important when optimizing T\+I code that involves pointers, as all A\+A\+X algorithms do due to the nature of the algorithm context structure.

{\ttfamily restrict} was introduced with the C99 standard. A\+A\+X plug-\/ins use the {\ttfamily A\+A\+X\+\_\+\+R\+E\+S\+T\+R\+I\+C\+T} keyword, which is a cross-\/platform macro for the C99 standard restrict.

\begin{DoxyNote}{Note}
Now that M\+S\+V\+C has added C99 support to its compiler, {\ttfamily A\+A\+X\+\_\+\+R\+E\+S\+T\+R\+I\+C\+T} will eventually be deprecated in favor of the {\ttfamily restrict} keyword.
\end{DoxyNote}
The following example demonstrates the use of restrict in our filter code.


\begin{DoxyCode}
\textcolor{keywordtype}{void}
ProcessDirectFormII (
    \textcolor{keyword}{const} \textcolor{keywordtype}{float} * \textcolor{keyword}{const} AAX\_RESTRICT input,
    \textcolor{keywordtype}{float} * \textcolor{keyword}{const} AAX\_RESTRICT output,
    \textcolor{keywordtype}{float} * \textcolor{keyword}{const} AAX\_RESTRICT state,
    \textcolor{keyword}{const} \textcolor{keywordtype}{float} * \textcolor{keyword}{const} AAX\_RESTRICT coefs ,
    \textcolor{keywordtype}{int} nsamp )
\{
    \textcolor{comment}{// eB0 .. eB2 and eA0, eA1 are just integer enums to partition}
    \textcolor{comment}{// the filter coefficients into A and B}

    \textcolor{comment}{// ---- LOAD ----}
    \textcolor{keyword}{const} \textcolor{keywordtype}{float} coefA0 = coefs [ eA0 ];
    \textcolor{keyword}{const} \textcolor{keywordtype}{float} coefA1 = coefs [ eA1 ];
    \textcolor{keyword}{const} \textcolor{keywordtype}{float} coefB0 = coefs [ eB0 ];
    \textcolor{keyword}{const} \textcolor{keywordtype}{float} coefB1 = coefs [ eB1 ];
    \textcolor{keyword}{const} \textcolor{keywordtype}{float} coefB2 = coefs [ eB2 ];

    \textcolor{keywordtype}{float} state0 = state [0];
    \textcolor{keywordtype}{float} state1 = state [1];

    \textcolor{comment}{// ---- UPDATE ----}
    \textcolor{keywordflow}{for} (\textcolor{keywordtype}{int} i =0; i&lt; nsamp; ++i)
    \{
        \textcolor{keyword}{const} \textcolor{keywordtype}{float} output = input [i]* coefB0 + state0;
        state0 = input [i]* coefB1 + state1 - output * coefA0;
        state1 = input [i]* coefB2 - output * coefA1;
        output [i] = output;
    \}

    \textcolor{comment}{// ---- STORE ----}
    state [0] = state0;
    state [1] = state1;
\} 
\end{DoxyCode}
  Listing 17\+: Refactored filter algorithm with load-\/update-\/store pattern and const and restrict keywords applied.

\begin{DoxyNote}{Note}

\begin{DoxyItemize}
\item This example applies {\ttfamily restrict }to the algorithm\textquotesingle{}s input and output audio buffer pointers. These pointers do not alias each other in most algorithms, but this may not be the case for all algorithms and should be verified by the developer before applying {\ttfamily restrict}. 


\item The {\ttfamily restrict} keyword is somewhat redundant when used with the load-\/update-\/store pattern. This is because by asserting to the compiler that the pointers are not aliased, it should be able to partially do the load-\/update-\/store refactoring automatically. However, because some compilers have limited or no support for the {\ttfamily restrict} keyword, using the load-\/update-\/store pattern is still recommended.  
\end{DoxyItemize}
\end{DoxyNote}
\hypertarget{a00362_subsubsection__keywords_to_avoid_}{}\paragraph{Keywords to avoid}\label{a00362_subsubsection__keywords_to_avoid_}
 There are some keywords which do more harm than good, but are still being used either due to legacy code or developer superstitions. These keywords should not be used in A\+A\+X plug-\/ins.


\begin{DoxyItemize}
\item {\ttfamily register}  The {\ttfamily register} keyword is a suggestion to the compiler that a certain variable will be accessed frequently and should be stored in a register rather than a memory location. Use this keyword only when you are sure that the compiler is placing a frequently-\/used variable in memory when it would be advantageous to keep it in a register. Note that the {\ttfamily register} keyword has no effect if the C\+G\+Tools optimizations are enabled.  


\item {\ttfamily static}  In C, the {\ttfamily static} keyword tells the compiler to initialize the variable at compilation time and retain the value between calls. Though there are some valid situations to use the {\ttfamily static} keyword, its use in A\+A\+X plug-\/ins on all platforms is extremely limited. One of its most \char`\"{}popular\char`\"{} uses, declaring local variables inside a function as {\ttfamily static} in order to achieve a type of global counter, should never be used in \hyperlink{a00288}{A\+A\+X} algorithm code. If you are using {\ttfamily static} to make a local variable hold its variable across calls to a function, it is always preferable to either pass it in to the function as a modifiable parameter or declare it as a member variable of the method (if C++).  


\end{DoxyItemize}

\hypertarget{a00362_subsection__data_types}{}\subsubsection{Data types}\label{a00362_subsection__data_types}
The T\+I C672x+ is a 32-\/bit floating point D\+S\+P platform, and has a few peculiarities that you should be aware of.


\begin{DoxyItemize}
\item Use {\ttfamily int} instead of {\ttfamily long}  Integers of type {\ttfamily long int} are 40 bits wide on T\+I, and are very inefficient. Always use the {\ttfamily int} data type (or, even better, the C99-\/standard {\ttfamily int32\+\_\+t}) instead.  


\item Use {\ttfamily float} instead of {\ttfamily double}  Double-\/precision floating-\/point data types have a significant performance penalty on T\+I processors. Use {\ttfamily float} instead of {\ttfamily double} wherever possible, as long as this substitution does not affect signal integrity or cancellation.  


\item Use unsigned values when referencing memory  In general, explicitly typed pointers should always be used to reference memory. If you do have need of a generic memory representation, use an unsigned integer to avoid implicit conversion costs.  


\end{DoxyItemize}

\hypertarget{a00362_subsubsection__unintended_data_type_conversions_}{}\paragraph{Unintended data type conversions}\label{a00362_subsubsection__unintended_data_type_conversions_}
 When developing for the T\+I platform it is important to keep an eye out for unintended type conversions, and especially for implicit double-\/precision instructions. The following points are helpful for both program efficiency and for future maintenance of the code, since they clarify the developer\textquotesingle{}s understanding of how the code should operate, e.\+g. by specifying that a cast is occurring, and make it obvious that steps such as data type conversions are an intentional part of the algorithm. 
\begin{DoxyItemize}
\item Explicitly declare constants as single-\/precision. For example, use {\ttfamily 0.\+0f} instead of {\ttfamily 0.\+0}. Often a compiler will be able to do this automatically at compile time, but it is better to be explicit with your intended precision.  
\item If any casts are required in your code, make them explicit. For example, {\ttfamily float output = (float)double\+Var} as opposed to {\ttfamily float output = double\+Var}.  
\item Use single-\/precision math.\+h functions (such as {\ttfamily fabsf()}) instead of the double-\/precision equivalents ({\ttfamily fabs()}).  
\item Do not directly reference memory addresses using integer data types; instead, use a pointer data type. If an integer data type is required, use an unsigned 32-\/bit type.  
\end{DoxyItemize}

To help ensure that you are not violating these principles, always be aware of any warnings generated by the compiler. In particular, do not ignore warnings related to \char`\"{}implicit conversion from \textquotesingle{}double\textquotesingle{} to \textquotesingle{}float\textquotesingle{}\char`\"{} or \char`\"{}implicit conversion from \textquotesingle{}double\textquotesingle{} to \textquotesingle{}int\textquotesingle{}\char`\"{}; these warnings may indicate that you are declaring a double when a float would be just as good.

In the final stages of optimization, examine the generated assembly code to make sure there are no unintended double-\/precision instructions or memory accesses.

\hypertarget{a00362_subsubsection__additional_data_type_optimizations_}{}\paragraph{Additional data type optimizations}\label{a00362_subsubsection__additional_data_type_optimizations_}
 The A\+A\+X S\+D\+K includes cross-\/platform macros that can be used to convert two single-\/precision float loads to one double-\/precision load. The coefficient smoothing case study below includes an example use case for these macros.


\begin{DoxyCode}
\textcolor{keyword}{const} \textcolor{keywordtype}{float} * pTable = &SmoothCoefTable[address];
\hyperlink{a00271_a7eb399409be7572c8bd589395c450cdc}{AAX\_ALIGNMENT\_HINT}(pTable,8);
\textcolor{keywordtype}{float} firstCoef  = \hyperlink{a00271_a30b9af679d91539e6aa0871d36c4b024}{AAX\_LO}(*pTable);
\textcolor{keywordtype}{float} secondCoef = \hyperlink{a00271_a51ea059e820f6ca326531adb132183c3}{AAX\_HI}(*pTable);
\end{DoxyCode}
  Listing 18\+: Example of using A\+A\+X macros for converting two {\ttfamily float} loads to one {\ttfamily double} load.

In this example the \hyperlink{a00271_a7eb399409be7572c8bd589395c450cdc}{A\+A\+X\+\_\+\+A\+L\+I\+G\+N\+M\+E\+N\+T\+\_\+\+H\+I\+N\+T} macro checks whether data is aligned on a 8-\/byte boundary, then the double word is loaded, and finally the \hyperlink{a00271_a30b9af679d91539e6aa0871d36c4b024}{A\+A\+X\+\_\+\+L\+O} and \hyperlink{a00271_a51ea059e820f6ca326531adb132183c3}{A\+A\+X\+\_\+\+H\+I} macros get the double word\textquotesingle{}s first and second ({\ttfamily float}) parts.

If {\ttfamily Smooth\+Coef\+Table} consists of floats and is 8-\/byte aligned, then this scenario will work fine for loads when {\ttfamily address} is even. This raises the question about how to load double word from {\ttfamily \&Smooth\+Coef\+Table\mbox{[}address\mbox{]}}, when {\ttfamily address} is odd. Since this kind of optimization is most useful for loading data from external memory, where the C\+P\+U savings of a single double word load vs two 32-\/bit loads is greatest, then one trick which can help is to trade off memory (as external memory is plentiful) for performance. Specifically, {\ttfamily Smooth\+Coef\+Table} can be orginized in a such way that for every member of this table, except the first and the last ones, there will be two consequent entries.


\begin{DoxyCode}
\textcolor{keyword}{const} int32\_t size = 4;
\textcolor{comment}{// instead of this classic variant...}
\textcolor{keyword}{const} \textcolor{keywordtype}{float} SmoothCoefTable[size] = \{
    -0.1, -0.2, -0.3, -0.4
\}

\textcolor{comment}{// ...table can be organized this way}
\textcolor{keyword}{const} \textcolor{keywordtype}{float} SmoothCoefTable[size*2 - 2] = \{
    -0.1, -0.2, 
    -0.2, -0.3,
    -0.3, -0.4,
    -0.4,  0.0 \textcolor{comment}{/* last member is dummy */}
\}
\end{DoxyCode}
  Listing 19\+: Example of restructuring the table so that it can be easily used in the optimization scenario given above.

In this case the number of loads will be halved at the cost of doubling the size of the table. If the table is located in external memory then the additional memory requirement can be an excellent trade-\/off for the performance gained.

\hypertarget{a00362_subsection__case_study_efficient_parameter_smoothing_at_single_and_double_precision}{}\subsubsection{Case study\+: Efficient parameter smoothing at single and double precision}\label{a00362_subsection__case_study_efficient_parameter_smoothing_at_single_and_double_precision}
 Coefficient smoothing (\char`\"{}de-\/zippering\char`\"{}) can often be one of the most difficult parts of a plug-\/in to optimize for real-\/time operation. This is especially true in cases when full double-\/precision smoothing filters have been used in a plug-\/in\textquotesingle{}s Native code, with the possibility of very small coefficients. In these cases it can be difficult to optimize the smoothing code while also satisfying requirements for audio data parity between the plug-\/in\textquotesingle{}s Native and D\+S\+P configurations.

~


\begin{DoxyCode}
\textcolor{keywordtype}{double} * \textcolor{keyword}{const} AAX\_RESTRICT deZipper = dzCoefsP->mDeZip [ch ][0];
\textcolor{keyword}{const} \textcolor{keywordtype}{double} * AAX\_RESTRICT coefs = myCoefsP->mBiqCoefsBuf [0];

\textcolor{comment}{// Double - precision}
\textcolor{keywordflow}{for} (\textcolor{keywordtype}{int} i = 0; i < eNumBiquads * eNumCoefs ; ++i)
\{
    \textcolor{keywordtype}{double} dz = deZipper [i];
    dz += zeroCoef * ( coefs [i] - deZipper [i]);
\} 
\end{DoxyCode}
  Listing 20\+: Example of double-\/precision smoothing.

In this section we will describe three specific approaches that may be taken to perform optimized real-\/time smoothing without compromising sound quality.

\hypertarget{a00362_subsubsection__method_1_clamped_singleprecision_smoothing_}{}\paragraph{Method 1\+: Clamped single-\/precision smoothing}\label{a00362_subsubsection__method_1_clamped_singleprecision_smoothing_}
 The simplest approach for optimization of a double-\/precision smoothing filter is to replace it with modified single-\/precision smoothing. Unfortunately, we have found that this approach can lead to glitches and instability at higher sample rates when adjusting controls due to transient innacuraccies in the smoothing.


\begin{DoxyCode}
\textcolor{keywordtype}{double} * \textcolor{keyword}{const} AAX\_RESTRICT deZipper = dzCoefsP->mDeZip [ch ][0];
\textcolor{keyword}{const} \textcolor{keywordtype}{double} * AAX\_RESTRICT coefs = myCoefsP->mBiqCoefsBuf [0];

\textcolor{comment}{// Method 1 - single - precision}
\textcolor{keywordflow}{for} (\textcolor{keywordtype}{int} i = 0; i < eNumBiquads * eNumCoefs ; ++i)
\{
    \textcolor{keywordtype}{float} dz = deZipper [i];
    dz += zeroCoef * ( coefs [i] - deZipper [i]);

    \textcolor{comment}{// If the de -zip step is so small that the coefficient doesn't change then clamp}
    \textcolor{comment}{// the value to the target to ensure we are using exactly the desired value .}
    deZipper [i] = (dz == deZipper [i]) ? coefs [i] : dz;
\} 
\end{DoxyCode}
  Listing 21\+: Example of clamped single-\/precision smoothing.

\hypertarget{a00362_subsubsection__method_2_mixedprecision_smoothing_}{}\paragraph{Method 2\+: Mixed-\/precision smoothing}\label{a00362_subsubsection__method_2_mixedprecision_smoothing_}
 To resolve the stability issues at high sample rates, the state may be accumulated at double-\/precision. This results in mixed-\/precision operations that are much faster on T\+I D\+S\+Ps than full double-\/precision calculations, though still slower than single-\/precision.


\begin{DoxyCode}
\textcolor{keywordtype}{float} * \textcolor{keyword}{const} AAX\_RESTRICT deZipper = dzCoefsP->mDeZip [ch ][0];
\textcolor{keywordtype}{double} * \textcolor{keyword}{const} AAX\_RESTRICT deZipState = dzCoefsP->mDZState [ch][0];
\textcolor{keyword}{const} \textcolor{keywordtype}{float} * AAX\_RESTRICT coefs = myCoefsP->mBiqCoefsBuf [0];

\textcolor{comment}{// Method 2 - partial double precision}
\textcolor{preprocessor}{# pragma UNROLL ( CBiquad::eNumCoefs )}
\textcolor{keywordflow}{for}(\textcolor{keywordtype}{int} i = 0; i < eNumBiquads * eNumCoefs ; i ++)
\{
    \textcolor{keywordtype}{double} dz = deZipState [i];
    dz += zeroCoef * ((coefs [i]) - ( deZipper [i]));
    deZipState [i] = dz;
    deZipper [i] = float (dz);
\} 
\end{DoxyCode}
  Listing 22\+: Example of mixed-\/precision smoothing.

\hypertarget{a00362_subsubsection__method_3_loop_unrolling_and_doubleword_memory_accesses_}{}\paragraph{Method 3\+: Loop unrolling and double-\/word memory accesses}\label{a00362_subsubsection__method_3_loop_unrolling_and_doubleword_memory_accesses_}
 Further performance gains can be made by unrolling the loop and using double word memory accesses. This code is faster, but is still not as fast as full single-\/precision.


\begin{DoxyCode}
\textcolor{keywordtype}{float} * \textcolor{keyword}{const} AAX\_RESTRICT deZipper = dzCoefsP->mDeZip [ch][0];
\textcolor{keywordtype}{double} * \textcolor{keyword}{const} AAX\_RESTRICT deZipState = dzCoefsP->mDZState [ch][0];
\textcolor{keyword}{const} \textcolor{keywordtype}{float} * AAX\_RESTRICT coefs = myCoefsP->mBiqCoefsBuf [0];

\textcolor{comment}{// Method 3 - partial double precision - unrolled with double-precision memory accesses for(int i = 0; i <
       (eNumBiquads * eNumCoefs); i +=2 )}
\{
    \textcolor{keywordtype}{double} dz0 = deZipState [i];
    \textcolor{keywordtype}{double} dz1 = deZipState [i+1];
    dz0 += zeroCoef * (\hyperlink{a00271_a30b9af679d91539e6aa0871d36c4b024}{AAX\_LO} ( coefs [i]) - \hyperlink{a00271_a30b9af679d91539e6aa0871d36c4b024}{AAX\_LO} ( deZipper [i]));
    dz1 += zeroCoef * ( \hyperlink{a00271_a51ea059e820f6ca326531adb132183c3}{AAX\_HI} ( coefs [i]) - \hyperlink{a00271_a51ea059e820f6ca326531adb132183c3}{AAX\_HI} ( deZipper [i]));
    deZipState [i] = dz0;
    deZipper [i] = float (dz0);
    deZipState [i+1] = dz1;
    deZipper [i+1] = float (dz1);
\} 
\end{DoxyCode}
  Listing 23\+: Example of loop unrolling and double-\/precision memory accesses for smoothing optimization.

\hypertarget{a00362_subsubsection__coefficient_smoothing_example_summary_}{}\paragraph{Coefficient smoothing example summary}\label{a00362_subsubsection__coefficient_smoothing_example_summary_}
 
\begin{DoxyItemize}
\item Full single-\/precision smoothing (method 1) is an excellent and simple solution for gain coefficients and other scalar values which are not extremely sensitive to coefficient quantization at small values. This method does not always reach the target value, so clamping should be used to ensure signal integrity.  
\item Mixed-\/precision smoothing (method 2) uses slightly more C\+P\+U, but gives full double precision accuracy. This approach should generally be used for E\+Qs and other sensitive coefficients.  
\item Further low-\/level optimizations are also possible via manual loop unrolling and double-\/precision memory access (method 3).  
\end{DoxyItemize}

\hypertarget{a00362_subsection__refactoring_conditionals_and_branches}{}\subsubsection{Refactoring conditionals and branches}\label{a00362_subsection__refactoring_conditionals_and_branches}
 \begin{DoxyNote}{Note}
For more detailed information on how to reduce or eliminate the use of branches in algorithms, see section 5.\+2 of the {\bfseries Hand-\/\+Tuning Loops and Control Code on the T\+M\+S320\+C6000} guide provided by T\+I.
\end{DoxyNote}
An important technique in refactoring algorithms to enhance loop performance is to reduce or eliminate conditionals and branches in code. The T\+I compiler focuses a lot of its optimization energy on keeping its pipeline full of inside loops. However, it cannot pipeline a loop if the one of the following is true\+:


\begin{DoxyItemize}
\item The loop contains a branch  
\item The loop contains a function call  
\item The loop is too long  
\end{DoxyItemize}

To demonstrate this, we will again begin with an unoptimized example\+:


\begin{DoxyCode}
\textcolor{keywordflow}{for} ( \textcolor{keywordtype}{int} i = 0; i &lt; numSamples ; ++i)
\{
    \textcolor{keywordflow}{if} (! bypass )
    \{
        \textcolor{keyword}{const} \textcolor{keywordtype}{float} filtOutput1 = input [i] * coef0 + state0 * coef1 ;
        \textcolor{keyword}{const} \textcolor{keywordtype}{float} filtOutput2 = filtOutput1 * coef2 + state1 * coef3 ;
        output [i] = filtOutput2 ;
    \}
    \textcolor{keywordflow}{else}
    \{
        output [i] = input [i];
    \}
\} 
\end{DoxyCode}
  Listing 24\+: Another unoptimized filter algorithm.

Though trivial, this example illustrates the problem with conditionals inside of loops. In T\+I assembly, conditional code usually translates into code branches, which prevents loops from pipelining effectively see \hyperlink{a00362_subsection__understanding_cgtoolsgenerated_asm_files}{Understanding C\+G\+Tools-\/generated A\+S\+M files}. Let\textquotesingle{}s refactor the loop in our example to reduce the size of its conditional branch\+:


\begin{DoxyCode}
\textcolor{keywordflow}{for} (\textcolor{keywordtype}{int} i = 0; i &lt; numSamples ; ++i)
\{
    \textcolor{keyword}{const} \textcolor{keywordtype}{float} filtOutput1 = input [i] * coef0 + state0 * coef1 ;
    \textcolor{keyword}{const} \textcolor{keywordtype}{float} filtOutput2 = filtOutput1 * coef2 + state1 * coef3 ;
    output [i] = filtOutput2 ;

    \textcolor{keywordflow}{if} ( bypass )
    \{
        output [i] = input [i];
    \}
\} 
\end{DoxyCode}
  Listing 25\+: Filter algorithm with a refactored conditional branch.

At first, it may seem wasteful to perform the filter calculation if {\ttfamily bypass} will simply throw away the result. In reality, however, the opposite is true\+: as a real-\/time algorithm, this code is constrained by its maximum, worst-\/case cycle count. It is important to understand this point\+: essentially, the cycle count of the plug-\/in is always its worst-\/case performance.

By reducing the algorithm\textquotesingle{}s maximum cycle count we are therefore reducing waste, even though we are increasing the plug-\/in\textquotesingle{}s cycle count when it is bypassed. In fact, the ideal scenario for most algorithms is to use only one code path (and, consequentially, a single deterministic cycle count) despite the fact that this can result in worse performance for some specific states. To state this fundamental principle in a different way\+:

 {\itshape The performance of specific states in an A\+A\+X D\+S\+P algorithm is not relevant if there is another possible state with worse performance.} 

Going back to our optimized example, you may also notice that the conditional still exists. Doesn\textquotesingle{}t this create a branch in the assembly code as well and prevent pipelining?

In the case of very brief conditionals such as this, the answer is usually no. On T\+I processors, most instructions can be executed conditionally, depending on the value of a control register. Thus, the single assignment {\ttfamily (output = input)} inside this conditional will reduce to a few conditional instructions without having to execute a branch. As a result, the T\+I compiler will be able to efficiently pipeline this loop.

That said, it is occasionally necessary to eliminate conditionals entirely. One effective solution for these situations is to execute the branched logic algorithmically rather than conditionally. To demonstrate this approach, here is our filter example again, this time with the the conditional completely eliminated from the loop\+:


\begin{DoxyCode}
\textcolor{keywordflow}{for} (\textcolor{keywordtype}{int} i = 0; i &lt; numSamples ; ++i)
\{
    \textcolor{keyword}{const} \textcolor{keywordtype}{float} filtOutput1 = input [i] * coef0 + state0 * coef1 ;
    \textcolor{keyword}{const} \textcolor{keywordtype}{float} filtOutput2 = filtOutput1 * coef2 + state1 * coef3 ;
    output [i] = (! bypass ) * filtOutput2 + bypass * input [i];
\} 
\end{DoxyCode}
  Listing 26\+: Filter algorithm with branching logic executed algorithmically.

This code is shorter and completely eliminates the conditional from inside the loop body. However, there is an associated cost in readability, in that it is not initially obvious how exactly {\ttfamily bypass} affects the output. This is of course a tradeoff that you will need to consider on a case-\/by-\/case basis. In general, we encourage you to consider this technique only when you have verified in the assembly code that simply reducing the size of the conditional is not enough to achieve effective instruction pipelining.

Another useful technique for optimizing loops is to use {\ttfamily pragma M\+U\+S\+T\+\_\+\+I\+T\+E\+R\+A\+T\+E} and {\ttfamily pragma P\+R\+O\+B\+\_\+\+I\+T\+E\+R\+A\+T\+E} (see more about these pragmas in \hyperlink{a00362_subsubsection__loop_controls_}{Loop controls}), which help the compiler guess the number of iterations for the loop. It is extremely useful when you know the exact number of the iterations, and this number never changes during plug-\/in processing. For example, this is applicable for the loops which iterate through the audio samples in the input and output buffers. The number of input samples is always constant for an A\+A\+X D\+S\+P plug-\/in algorithm; the buffer length must be described with the option \hyperlink{a00283_a6571f4e41a5dd06e4067249228e2249ea09fbd1cbcae0e86ad81005258dc1b67e}{A\+A\+X\+\_\+e\+Property\+\_\+\+D\+S\+P\+\_\+\+Audio\+Buffer\+Length} for each D\+S\+P component in the plug-\/in\textquotesingle{}s description.

The following code example shows an algorithm processing function template. For convenience, this function template takes the audio buffer length as a template parameter\+:


\begin{DoxyCode}
\textcolor{keyword}{template}<\textcolor{keywordtype}{int} kAudioWindowSize>
\textcolor{keywordtype}{void} \hyperlink{a00149_aaa22112139aa627574b1ef562f579d43}{AAX\_CALLBACK}
Example\_AlgorithmProcessFunction( SExample\_Alg\_Context * \textcolor{keyword}{const} inInstancesBegin [], \textcolor{keyword}{const} \textcolor{keywordtype}{void} * 
      inInstancesEnd)
\{
   \textcolor{keywordflow}{for} (SExample\_Alg\_Context * \textcolor{keyword}{const} * walk = inInstancesBegin; walk != inInstancesEnd; ++walk)
   \{
      SExample\_Alg\_Context* \textcolor{keyword}{const} AAX\_RESTRICT contextP = *walk;
      \textcolor{keyword}{const} \textcolor{keywordtype}{float} * \textcolor{keyword}{const} AAX\_RESTRICT inputP = contextP->mInputPP;
      \textcolor{keywordtype}{float} * \textcolor{keyword}{const} AAX\_RESTRICT outputP = contextP->mOutputPP;

\textcolor{preprocessor}{      #pragma MUST\_ITERATE( kAudioWindowSize, kAudioWindowSize, kAudioWindowSize )}
      \textcolor{keywordflow}{for} (int32\_t i = 0; i < kAudioWindowSize; ++i)
      \{
         outputP[i] = inputP[i];
      \}
   \}
\} 
\end{DoxyCode}
  Listing 27\+: Optimizing loop using pragma M\+U\+S\+T\+\_\+\+I\+T\+E\+R\+A\+T\+E.

Note that the audio buffer length property takes a \hyperlink{a00206_ab33e0f1ecf04ca4161fa8d8de5845d67}{A\+A\+X\+\_\+\+E\+Audio\+Buffer\+Length\+D\+S\+P} value. The values of this enum are set to the power-\/of-\/two for each buffer length, so in this case the {\ttfamily k\+Audio\+Window\+Size} value would be set to match {\ttfamily 2 $<$$<$ A\+A\+X\+\_\+e\+Property\+\_\+\+D\+S\+P\+\_\+\+Audio\+Buffer\+Length} when compiling this algorithm callback into the T\+I D\+L\+L

The same optimization can be used for the loops that iterate through input/output channels, as demonstrated by the Demo\+Dist example plug-\/in.

\hypertarget{a00362_subsection__case_study_pipeline_refactoring_in_avids_eq3_and_dyn3_plugins}{}\subsubsection{Case study\+: pipeline refactoring in Avid\textquotesingle{}s E\+Q3 and Dyn3 plug-\/ins}\label{a00362_subsection__case_study_pipeline_refactoring_in_avids_eq3_and_dyn3_plugins}
 While optimizing the \char`\"{}stock\char`\"{} Pro Tools equalization and dynamics processors we came across many real-\/world optimization scenarios that will be applicable to a broad variety of plug-\/ins. In this section we will consider specific techniques that we used to enable software pipelining of these algorithms by the T\+I compiler, including an in-\/depth look at the pseudo-\/speculative execution approach used in our Dyn3 plug-\/in\textquotesingle{}s polynomial gain calculation loop.

\hypertarget{a00362_subsubsection__move_individual_processing_operations_into_separate_loops_}{}\paragraph{Move individual processing operations into separate loops}\label{a00362_subsubsection__move_individual_processing_operations_into_separate_loops_}
 Oftentimes a sample-\/by-\/sample iterative loop that is not software pipelining can be broken up into individual loops that incrementally apply changes to the audio buffer. These smaller loops have a much better chance of being successfully pipelined by the compiler. In E\+Q3, moving our biquad audio processing stages to dedicated loops that do not include coefficient smoothing or other tasks resulted in large performance gains.

\hypertarget{a00362_subsubsection__avoid_pipeline_dependencies_}{}\paragraph{Avoid pipeline dependencies}\label{a00362_subsubsection__avoid_pipeline_dependencies_}
 The goal of the above optimization is to allow the compiler to successfully pipeline each iterative loop. However, even a pipelined loop may be optimized further. One of the best ways of optimizing loops is to keep the processor busy while pipeline dependencies are cleared.

For example, in E\+Q3 we found that it was better to perform the plug-\/in\textquotesingle{}s input and output meter calculations in the same loop rather than separating them out into individual loops. This is because each meter calculation has a dependency on its previous value, which puts a dependency in the pipeline. Doing both at the same time gives the process more to do while waiting for the next value. In Dyn3 we had similar results merging table lookup, attack, and release loops into a single iterative loop. As long as the loop is still successfully pipelined by the compiler, these \char`\"{}larger\char`\"{} loops tended to have much better performance due to the reduction in blocking dependencies.

\hypertarget{a00362_subsubsection__detailed_example_of_loop_optimization_in_dyn3_}{}\paragraph{Detailed example of loop optimization in Dyn3}\label{a00362_subsubsection__detailed_example_of_loop_optimization_in_dyn3_}
 At this point it will be helpful to go into greater detail about our optimizations for Dyn3\textquotesingle{}s polynomial gain calculation loop, because the increase in performance was quite large and is fairly representative of other algorithms. The unoptimized code took 43 cycles to execute one iteration of the loop. After rearranging the code it now takes 6 cycles. The basic problem was numerous pipeline dependencies\+: the {\itshape  Loop Carried Dependency Bound} was 42 cycles, yet the {\itshape  Partitioned Resource Bound} was 4 cycles. In other words, if all of these dependencies were removed the loop could potentially execute in 4 cycles.


\begin{DoxyCode}
2760 ;* SOFTWARE PIPELINE INFORMATION
2761 ;*
2762 ;* Loop source line : 199
2763 ;* Loop opening brace source line : 200
2764 ;* Loop closing brace source line : 213
2765 ;* Known Minimum Trip Count : 4
2768 ;* Loop Carried Dependency Bound (^) : 42
2769 ;* Unpartitioned Resource Bound : 4
2770 ;* Partitioned Resource Bound (*) : 4
2785 ;*
2786 ;* Searching \textcolor{keywordflow}{for} software pipeline schedule at ...
2787 ;* ii = 42 Did not find schedule
2788 ;* ii = 43 Schedule found with 1 iterations in parallel
2789 ;* Done

\textcolor{keywordflow}{for} (\textcolor{keywordtype}{int} i =0; i&lt; kAudioWindowSize ; i++) \textcolor{comment}{// cSmoothingBlockSize}
\{
    \textcolor{keyword}{const} \textcolor{keywordtype}{float} * smoothCoeffs = stateP -&gt; mSmoothedPoly ;

    \textcolor{keywordtype}{float} logEnv = logEnvArray [i]; \textcolor{comment}{// logEnvArray [ fIdx +i];}
    logEnv -= smoothThrLow ;

    \textcolor{keywordflow}{if}( logEnv &gt;= 0.0 f) \textcolor{comment}{// In the knee}
        smoothCoeffs += eCpdPolyOrder ;
    \textcolor{keywordflow}{if}( logEnv &gt;= 0.0 f) \textcolor{comment}{// In the knee}
        logEnv -= smoothThrLowDelta ;
    \textcolor{keywordflow}{if}( logEnv &gt;= 0.0 f) \textcolor{comment}{// In the linear GR stage}
        smoothCoeffs += eCpdPolyOrder ;

    \textcolor{keyword}{const} \textcolor{keywordtype}{float} filteredLogEnv = smoothCoeffs [ eCpdPolyCoeffsC ] +
        logEnv *( smoothCoeffs [ eCpdPolyCoeffsB ] +
        smoothCoeffs [ eCpdPolyCoeffsA ]* logEnv );
    filtLogEnvArray [i] = filteredLogEnv + smoothedMakeupGain ;
\} 
\end{DoxyCode}
  Listing 28\+: Dyn3\textquotesingle{}s unoptimized polynomial gain calculation loop and asm listing.


\begin{DoxyItemize}
\item {\ttfamily log\+Env -\/= smooth\+Thr\+Low }  {\itshape  depends on the result of {\ttfamily log\+Env\+Array\mbox{[}i\mbox{]}}} {\ttfamily }  


\item {\ttfamily if(log\+Env $>$= 0.\+0f) }  {\itshape  depends on the result of {\ttfamily log\+Env -\/= smooth\+Thr\+Low}} {\ttfamily }  


\item {\ttfamily log\+Env -\/= smooth\+Thr\+Low\+Delta }  {\itshape  depends on the result of {\ttfamily log\+Env -\/= smooth\+Thr\+Low}} {\ttfamily }  


\item {\ttfamily Thrid if(log\+Env $>$= 0.\+0f) }  {\itshape  depends on the result of {\ttfamily log\+Env -\/= smooth\+Thr\+Low\+Delta}} {\ttfamily }  


\item {\ttfamily Second smooth\+Coeffs += e\+Cpd\+Poly\+Order }  {\itshape  depends on the result of the first {\ttfamily smooth\+Coeffs += e\+Cpd\+Poly\+Order}} {\ttfamily }  


\item {\ttfamily log\+Env$\ast$smooth\+Coeffs\mbox{[}e\+Cpd\+Poly\+Coeffs\+B\mbox{]} }  {\itshape  depends on the result of {\ttfamily log\+Env -\/= smooth\+Thr\+Low\+Delta}} {\ttfamily }  


\item {\ttfamily smooth\+Coeffs\mbox{[}e\+Cpd\+Poly\+Coeffs\mbox{]}, etc. }  {\itshape  depend on the result of the second {\ttfamily smooth\+Coeffs += e\+Cpd\+Poly\+Order}} {\ttfamily }  


\item {\ttfamily filtered\+Log\+Env+smoothed\+Makeup\+Gain }  {\itshape  depends on the result of {\ttfamily filtered\+Log\+Env = smooth\+Coeffs\mbox{[}e\+Cpd\+Poly\+Coeffs\+C\mbox{]}}}  


\item {\ttfamily filt\+Log\+Env\+Array\mbox{[}i\mbox{]} }  {\itshape  depends on the result of {\ttfamily filtered\+Log\+Env + smoothed\+Makeup\+Gain}}  


\end{DoxyItemize}

And I don\textquotesingle{}t think that even covers every case, but you get the idea. The bottom line is there is no way this loop can pipeline well. In contrast, here is the optimized code and listing file output once these dependencies have been removed\+:


\begin{DoxyCode}
2476 ;* Loop opening brace source line : 167
2477 ;* Loop closing brace source line : 179
2446 ;* Known Minimum Trip Count : 4
2482 ;* Loop Carried Dependency Bound (^) : 1
2483 ;* Unpartitioned Resource Bound : 4
2484 ;* Partitioned Resource Bound (*) : 4
2512 ;* ii = 6 Schedule found with 5 iterations in parallel

\textcolor{keywordflow}{for} (\textcolor{keywordtype}{int} i =0; i&lt; cProcessingBlockSize ; i++)
\{
    \textcolor{keywordtype}{float} logEnv = logEnvArray [i];
    \textcolor{keywordtype}{float} logEnvThrHi = logEnv - smoothThrHigh ;
    \textcolor{keyword}{const} \textcolor{keywordtype}{float} gainSlope = smoothThrSlope +
        logEnv * smoothSlope ;
    \textcolor{keyword}{const} \textcolor{keywordtype}{float} gainKnee = smoothKneeC +
        logEnvThrHi *( smoothKneeB +
        smoothKneeA * logEnvThrHi );

    \textcolor{keyword}{const} \textcolor{keywordtype}{bool} bKnee = ( logEnv &gt; smoothThrLow );
    \textcolor{keyword}{const} \textcolor{keywordtype}{bool} bSlope = ( logEnv &gt; smoothThrHigh );

    \textcolor{keywordtype}{float} filteredLogEnv = bKnee ? gainKnee : 0.0f;
    filteredLogEnv = bSlope ? gainSlope : filteredLogEnv ;
    filtLogEnvArray [i] = filteredLogEnv ;
\} 
\end{DoxyCode}
  Listing 29\+: Dyn3\textquotesingle{}s optimized polynomial gain calculation loop and asm listing

In this case {\ttfamily gain\+Slope} is only dependent on the loading of {\ttfamily log\+Env}, so that can begin almost immediately. {\ttfamily Gain\+Knee} must wait for {\ttfamily log\+Env\+Thr\+Hi}, but {\ttfamily gain\+Slope} can be calculated during that time. {\ttfamily b\+Knee} and {\ttfamily b\+Slope} are also only dependent on {\ttfamily log\+Env}, and start right away. The main dependency is {\ttfamily filtered\+Log\+Env} which is dependent on {\ttfamily b\+Knee} and {\ttfamily gain\+Knee} and then {\ttfamily b\+Slope} and {\ttfamily gain\+Slope}. Anyhow, this is far fewer dependencies. Here is another version which runs in exactly the same number of cycles. (In fact, under the hood it may be creating the same asm code; we have not compared instruction-\/by-\/instruction.)


\begin{DoxyCode}
\textcolor{keywordflow}{for} (\textcolor{keywordtype}{int} i =0; i&lt; kAudioWindowSize ; i++)
\{
    \textcolor{keywordtype}{float} logEnv = logEnvArray [i];
    \textcolor{keywordtype}{float} logEnvThrHi = logEnv - smoothThrHigh ;

    \textcolor{keyword}{const} \textcolor{keywordtype}{bool} bKnee = ( logEnv &gt; thrLow );
    \textcolor{keyword}{const} \textcolor{keywordtype}{bool} bSlope = ( logEnv &gt; thrHigh );

    \textcolor{keywordtype}{float} filteredLogEnv = bKnee ?
        kneeC + logEnvThrHi *( kneeB + kneeA * logEnvThrHi ) :
        0.0 f;
    filteredLogEnv = bSlope ?
        thrSlope + logEnv * slope :
        filteredLogEnv ;
    filtLogEnvArray [i] = filteredLogEnv ;
\} 
\end{DoxyCode}
  Listing 30\+: An alternative optimization for Dyn3\textquotesingle{}s polynomial gain calculation loop.

\hypertarget{a00362_subsubsection__but_what_about_native__}{}\paragraph{But what about Native?}\label{a00362_subsubsection__but_what_about_native__}
 You might expect this altered code to execute well on a T\+I D\+S\+P but poorly on x86. However, keep in mind that a large degree of speculative execution is used on Intel\textquotesingle{}s processors. This means that pipeline dependencies due to conditionals can be broken because multiple paths are executed. In these cases, only one of the results is used and the others are thrown away. In other words, if you saw pseudo code showing the literal execution of the unoptimized code above on Intel then it would probably look a lot like the optimized code. The lesson? For T\+I it is important to rearrange your code so that essentially it implements speculative execution as much as possible, and if applied correctly this optimization should not negatively impact your plug-\/in\textquotesingle{}s native performance.

\hypertarget{a00362_subsection__case_study_additional_optimization_lessons_from_eq3_and_dyn3}{}\subsubsection{Case study\+: Additional optimization lessons from E\+Q3 and Dyn3}\label{a00362_subsection__case_study_additional_optimization_lessons_from_eq3_and_dyn3}
 The pipeline optimization example above is just one example, and the following techniques also helped us achieve many-\/fold increases in performance. Note that many of these techniques are discussed in greater detail in the sections above.

\hypertarget{a00362_subsubsection__watch_the_assembly_listing_}{}\paragraph{Watch the assembly listing}\label{a00362_subsubsection__watch_the_assembly_listing_}
 In the process of optimizing these plug-\/ins we found their asm listing files very helpful, especially the {\itshape  Loop Carried Dependency Bound} and the {\itshape  Partitioned Resource Bound} information. The listing file shows how many cycles the code is taking to execute, and we could make an estimate of how far away we were from the optimal implementation by seeing how well the pipeline is being utilized.

\hypertarget{a00362_subsubsection__divide_processing_tasks_over_multiple_calls_}{}\paragraph{Divide processing tasks over multiple calls}\label{a00362_subsubsection__divide_processing_tasks_over_multiple_calls_}
 In the old R\+T\+A\+S version of E\+Q3 the coefficients were updated (smoothed) every 8 samples. Initially, this was changed to every 4 samples in the A\+A\+X version in order to easily work with 4-\/sample blocks on H\+D\+X. However, we were able to achieve better results by adding \char`\"{}ping pong\char`\"{} logic that alternates between smoothing the first and second half of the coefficients on each pass. To make this work in our odd-\/banded E\+Q we had to pad the smoothing coefficients by one biquad\textquotesingle{}s worth to make an even number of biquads, but regardless of this inefficiency we still achieved performance gains.

\hypertarget{a00362_subsubsection__eliminate_branches_that_block_pipelining_}{}\paragraph{Eliminate branches that block pipelining}\label{a00362_subsubsection__eliminate_branches_that_block_pipelining_}
 Eliminating large conditional branches is critical to optimal performance on T\+I. This can be an especially tempting pitfall for developers who are used to coding only for x86 processors.

Consider the \char`\"{}ping pong\char`\"{} optimization described above. This logic does not break pipelining because the conditional logic that checks the state of the flag does not result in a large branch; once the ping pong value is set, the exact same logic operates in every processing callback. If instead we used an if statement to determine which \char`\"{}side\char`\"{} should execute, this would prevent pipelining optimizations and would seriously impact performance.

\hypertarget{a00362_subsubsection__remove_doubleprecision_operations_where_they_are_not_required_}{}\paragraph{Remove double-\/precision operations where they are not required}\label{a00362_subsubsection__remove_doubleprecision_operations_where_they_are_not_required_}
 Here is some coefficient smoothing code from our pre-\/optimization E\+Q3 algorithm. This code was embedded in the inner biquad processing loop\+:


\begin{DoxyCode}
\textcolor{preprocessor}{# pragma UNROLL ( CBiquad::eNumCoefs )}
\textcolor{keywordflow}{for} (\textcolor{keywordtype}{int} k = 0; k < CBiquad::eNumCoefs; ++k)
\{
    \textcolor{keywordtype}{double} &dz = deZipper[k];
    \hyperlink{a00288_aaf103dc75b68b6c4f6792dd26f9b4fd0}{AAX::DeDenormal} (dz);
    step[k] = zeroCoef * ( coefs[k] - dz);
\}
 
\textcolor{preprocessor}{# pragma UNROLL ( CBiquad::eNumCoefs )}
\textcolor{keywordflow}{for}(\textcolor{keywordtype}{int} k = 0; k < CBiquad::eNumCoefs; ++k)
\{
    \textcolor{keywordtype}{double} nm1\_dz = deZipper[k]; \textcolor{comment}{// read state}
    nm1\_dz += step[k];
    biquadCoefs[k] = \textcolor{keyword}{static\_cast<} \textcolor{keywordtype}{float} \textcolor{keyword}{>} ( nm1\_dz );
    deZipper[k] = nm1\_dz ; \textcolor{comment}{// write state}
\} 
\end{DoxyCode}
  Listing 31\+: Unoptimized coefficient smoothing in E\+Q3

To optimize this code, we converted the logic to use single-\/precision de-\/zipper values. However, this resulted in a sonic difference due to the fact that the smoothed coefficients would not necessarily ramp all the way to the correct target value. To solve that we added a conditional \char`\"{}clamp\char`\"{} that halts the smoothing once there is no difference between the 32-\/bit smoothed value and the target value. On examination of the assembler output, we found that this conditional pipelines very well.


\begin{DoxyCode}
\textcolor{preprocessor}{# pragma UNROLL ( CBiquad::eNumCoefs )}
\textcolor{keywordflow}{for}(\textcolor{keywordtype}{int} i = 0; i < (cMaxNumBiquadsWithPad / 2) * CBiquad::eNumCoefs; ++i)
\{
    \textcolor{keywordtype}{float} dz = deZipper[i];
    dz += zeroCoef * ( coefs[i] - deZipper[i]);
    deZipper[i] = (dz == deZipper[i]) ? coefs[i] : dz; \textcolor{comment}{// clamp}
\} 
\end{DoxyCode}
  Listing 32\+: Optimized coefficient smoothing in E\+Q3

\hypertarget{a00362_subsubsection__make_coefficients_contiguous_}{}\paragraph{Make coefficients contiguous}\label{a00362_subsubsection__make_coefficients_contiguous_}
 We were able to achieve significant performance gains in iterative loops like the smoothing code shown above by ensuring that all of the coefficients that would be accessed by the loop are contiguous in memory. In addition, note that in the optimized code there is only one loop, which iterates {\ttfamily Num\+Biquads$\ast$\+Num\+Coefs} times. This optimization is possible due to the fact that each filter\textquotesingle{}s coefficients are contiguous in the {\ttfamily coefs} array.

\hypertarget{a00362_subsubsection__use_aax_restrict_wherever_applicable_}{}\paragraph{Use A\+A\+X\+\_\+\+R\+E\+S\+T\+R\+I\+C\+T wherever applicable}\label{a00362_subsubsection__use_aax_restrict_wherever_applicable_}
 We have found that the {\ttfamily restrict} keyword is vital for optimal performance on T\+I D\+S\+Ps. For example, the parameter smoothing logic in our Dyn3 plug-\/in was reduced from 18 cycles to 3 cycles per loop iteration simply by the addition of this keyword to the applicable pointer variables.

For more information about the {\ttfamily restrict} keyword, see \hyperlink{a00362_subsubsection__restrict_}{restrict}.

\hypertarget{a00362_subsubsection__be_aware_of_shell_overhead_}{}\paragraph{Be aware of shell overhead}\label{a00362_subsubsection__be_aware_of_shell_overhead_}
 In the T\+I Shell there is code that loops through every buffered coefficient F\+I\+F\+O before every sample buffer in order to swap the algorithm\textquotesingle{}s context field pointers to a new set of coefficients if one is available. This uses a nominal number of cycles per buffered port, which can add up very quickly in small plug-\/ins.

For example, before our optimizations E\+Q3 used eight individual buffered coefficient blocks. On investigation, we found that the shell overhead from managing these buffers added up to be roughly equivalent to the algorithm\textquotesingle{}s total processing cycles! To work around this we merged the 8 coefficient blocks into one large block. The trade-\/off of this optimization is that more work must be done on the host to re-\/generate and copy the whole coefficient state every time any parameter changes, so this is an optimization that should be applied only when appropriate for the individual plug-\/in.\+For example, before our optimizations E\+Q3 used eight individual buffered coefficient blocks. On investigation, we found that the shell overhead from managing these buffers added up to be roughly equivalent to the algorithm\textquotesingle{}s total processing cycles! To work around this we merged the 8 coefficient blocks into one large block. The trade-\/off of this optimization is that more work must be done on the host to re-\/generate and copy the whole coefficient state every time any parameter changes, so this is an optimization that should be applied only when appropriate for the individual plug-\/in.

\hypertarget{a00362_subsubsection__watch_for_opportunities_to_merge_or_eliminate_operations_}{}\paragraph{Watch for opportunities to merge or eliminate operations}\label{a00362_subsubsection__watch_for_opportunities_to_merge_or_eliminate_operations_}
 Keep an eye out for unnecessary processing stages performed by your algorithm. Gain stages, phase toggles, and \char`\"{}dummy\char`\"{} coefficients are particularly good candidates for this kind of optimization. For example\+:


\begin{DoxyItemize}
\item In our E\+Q3 plug-\/in, we found that we could achieve significant performance improvement by merging the plug-\/in\textquotesingle{}s input and output gain stages with the overall gain of the first and last biquads. As a side benefit, this reduced the total quantization noise in the algorithm.  
\item In our Dyn3 plug-\/in, we found that we were applying smoothing logic to filter coefficients that would always be zero.  
\item When we looked more closely at Dyn3 we found that we were also computing and discarding sidechain filter information for the L\+F\+E, which is not part of the sidechain  
\end{DoxyItemize}

\hypertarget{a00362_subsubsection__read_the_ti_documentation_}{}\paragraph{Read the T\+I documentation}\label{a00362_subsubsection__read_the_ti_documentation_}
 There are many helpful optimization resources available from Texas Instruments. Out of all of the T\+I optimization documents we encountered, we found the {\itshape Hand-\/\+Tuning Loops and Control Code on the T\+M\+S320\+C6000} guide to be the most helpful and complete.

\hypertarget{a00362_subsection__optimization_on_the_hdx_platform}{}\subsubsection{Optimization on the H\+D\+X platform}\label{a00362_subsection__optimization_on_the_hdx_platform}
 \hypertarget{a00362_subsubsection__interrupt_latency_}{}\paragraph{Interrupt latency}\label{a00362_subsubsection__interrupt_latency_}
 Besides the large latency due to context switching (lots of data file registers to store) and the pipeline (many stages), interrupts can be disabled around pipelined loops, which cannot be interrupted. This can be controlled with the -\/mi=X compiler option, which will disallow unsafe pipelining for loops that are longer than X cycles. See T\+I\textquotesingle{}s documentation (S\+P\+R\+U187\+O Section 2.\+12) for more details and references regarding this behavior.

\hypertarget{a00362_subsubsection__external_memory_access_}{}\paragraph{External memory access}\label{a00362_subsubsection__external_memory_access_}
 A loop which performs many reads and writes may require access to external memory. In this scenario, the loop may take 10\textquotesingle{}s or even 100\textquotesingle{}s of times longer to execute than the compiler expects it to!

There are two options for dealing with this\+: 
\begin{DoxyEnumerate}
\item Search and destroy these loops individually 
\begin{DoxyItemize}
\item Move all the data used by the loop to internal R\+A\+M.  
\item Use H\+D\+X\textquotesingle{}s D\+M\+A facilities for external memory accesses.  
\item {\ttfamily \#pragma F\+U\+N\+C\+\_\+\+I\+N\+T\+E\+R\+R\+U\+P\+T\+\_\+\+T\+H\+R\+E\+S\+H\+O\+L\+D} can be used to disable pipelining on a case by case basis.  
\end{DoxyItemize}
\item For modules that are known to have these loops but are not worth hand optimizing, then turn off pipelined loop optimization altogether. ({\ttfamily -\/mu aka â€“disable\+\_\+software\+\_\+pipelining}).  
\end{DoxyEnumerate}

\begin{DoxyNote}{Note}
This is only a problem in the C67(0-\/2)x I\+S\+Ax used on the H\+D\+X platform. In The C64xx and C674x I\+S\+A, there is an S\+P\+L\+O\+O\+P command which can buffer the branches within pipelined loops to allow them to be interruptable.
\end{DoxyNote}
\hypertarget{a00362_subsection__code_composer_studio_optimization_tools}{}\subsubsection{Code Composer Studio optimization tools}\label{a00362_subsection__code_composer_studio_optimization_tools}
 \hypertarget{a00362_subsubsection__compiler_consultant_}{}\paragraph{Compiler Consultant}\label{a00362_subsubsection__compiler_consultant_}
 The Compiler Consultant tool can be used to suggest additional optimizations.

{\itshape  To enable the Compiler Consultant in Code Composer Studio, do the following\+:} 
\begin{DoxyEnumerate}
\item Set an optimization level of {\ttfamily -\/o2} or {\ttfamily -\/o3} (Found in C\+C\+Sv4 under Build Options $>$ Compiler $>$ Basic)  
\item Set the â€“consultant\+: {\ttfamily Generate Compiler Consultant Advise} switch (Found in C\+C\+Sv4 under Build Options $>$ Compiler $>$ Feedback)  
\end{DoxyEnumerate}

\hypertarget{a00362_subsubsection__optimization_information_file_}{}\paragraph{Optimization information file}\label{a00362_subsubsection__optimization_information_file_}
 Optimization information files can be generated in Code Composer Studio by selecting the option Build Options $>$ Compiler $>$ Feedback $>$ Opt Info File. Optimization information files have an .nfo extension and are placed into the project\textquotesingle{}s intermediate build products directory. In general, these files list function call-\/graph information and describe whether or not individual functions can be inlined. 

 \hypertarget{a00362_aax_ti_guide_07_error_codes}{}\subsection{Error Codes}\label{a00362_aax_ti_guide_07_error_codes}
The following appendices document error codes that are specific to plug-\/in hosting in Pro Tools H\+D\+X and other A\+A\+X platforms based on the T\+I D\+S\+P environment.

\hypertarget{a00362_subsection__138xx_dhm_core_dsp_errors}{}\subsubsection{-\/138xx\+: D\+H\+M Core D\+S\+P errors}\label{a00362_subsection__138xx_dhm_core_dsp_errors}
 These errors relate to routing and assignment problems on Pro Tools H\+D\+X hardware. Plug-\/ins should never be able to trigger these error codes, which indicate low-\/level problems in the system.

\begin{TabularC}{2}
\hline
\multicolumn{2}{|p{(\linewidth-\tabcolsep*2-\arrayrulewidth*1)*2/2}|}{\multirow{1}{\linewidth}{~\newline
   }}\\\cline{1-2}
\multicolumn{2}{|p{(\linewidth-\tabcolsep*2-\arrayrulewidth*1)*2/2}|}{\multirow{1}{\linewidth}{{\bfseries Table 1\+: D\+H\+M Core D\+S\+P error codes}   }}\\\cline{1-2}
\multicolumn{2}{|p{(\linewidth-\tabcolsep*2-\arrayrulewidth*1)*2/2}|}{\multirow{1}{\linewidth}{~\newline
   }}\\\cline{1-2}
\rowcolor{lightgray}\multirow{1}{\linewidth}{{\bf Value  }}&\multirow{1}{\linewidth}{{\bf Definition   }}\\\cline{1-2}
\multirow{1}{\linewidth}{-\/13801  }&\multirow{1}{\linewidth}{{\ttfamily e\+P\+S\+Error\+\_\+\+C\+T\+I\+D\+S\+P\+\_\+\+Wrong\+Sample\+Rate}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/13802  }&\multirow{1}{\linewidth}{{\ttfamily e\+P\+S\+Error\+\_\+\+C\+T\+I\+D\+S\+P\+\_\+\+No\+Free\+Streams}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/13803  }&\multirow{1}{\linewidth}{{\ttfamily e\+P\+S\+Error\+\_\+\+C\+T\+I\+D\+S\+P\+\_\+\+Stream\+Creation\+Timeout}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/13804  }&\multirow{1}{\linewidth}{{\ttfamily e\+P\+S\+Error\+\_\+\+C\+T\+I\+D\+S\+P\+\_\+\+Stream\+Destruction}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/13805  }&\multirow{1}{\linewidth}{{\ttfamily e\+P\+S\+Error\+\_\+\+C\+T\+I\+D\+S\+P\+\_\+\+Inactive\+Stream}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/13806  }&\multirow{1}{\linewidth}{{\ttfamily e\+P\+S\+Error\+\_\+\+C\+T\+I\+D\+S\+P\+\_\+\+Stream\+Corrupted}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/13807  }&\multirow{1}{\linewidth}{{\ttfamily e\+P\+S\+Error\+\_\+\+C\+T\+I\+D\+S\+P\+\_\+\+Queue\+Full}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/13808  }&\multirow{1}{\linewidth}{{\ttfamily e\+P\+S\+Error\+\_\+\+C\+T\+I\+D\+S\+P\+\_\+\+Null\+Pointer}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/13809  }&\multirow{1}{\linewidth}{{\ttfamily e\+P\+S\+Error\+\_\+\+C\+T\+I\+D\+S\+P\+\_\+\+Wrong\+Stream\+I\+D}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/13810  }&\multirow{1}{\linewidth}{{\ttfamily e\+P\+S\+Error\+\_\+\+C\+T\+I\+D\+S\+P\+\_\+\+Image\+Error}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/13811  }&\multirow{1}{\linewidth}{{\ttfamily e\+P\+S\+Error\+\_\+\+C\+T\+I\+D\+S\+P\+\_\+\+Reset\+Error}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/13812  }&\multirow{1}{\linewidth}{{\ttfamily e\+P\+S\+Error\+\_\+\+C\+T\+I\+D\+S\+P\+\_\+\+Image\+Verify}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/13813  }&\multirow{1}{\linewidth}{{\ttfamily e\+P\+S\+Error\+\_\+\+C\+T\+I\+D\+S\+P\+\_\+\+D\+S\+P\+Already\+In\+Boot\+Or\+Reset}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/13814  }&\multirow{1}{\linewidth}{{\ttfamily e\+P\+S\+Error\+\_\+\+C\+T\+I\+D\+S\+P\+\_\+\+Trigger\+Interrupt}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/13815  }&\multirow{1}{\linewidth}{{\ttfamily e\+P\+S\+Error\+\_\+\+C\+T\+I\+D\+S\+P\+\_\+\+Buffer\+Size\+Not\+Aligned}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/13816  }&\multirow{1}{\linewidth}{{\ttfamily e\+P\+S\+Error\+\_\+\+C\+T\+I\+D\+S\+P\+\_\+\+Timeout\+Waiting\+For\+H\+P\+I\+C}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/13817  }&\multirow{1}{\linewidth}{{\ttfamily e\+P\+S\+Error\+\_\+\+C\+T\+I\+D\+S\+P\+\_\+\+Set\+U\+H\+P\+I\+Error}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/13818  }&\multirow{1}{\linewidth}{{\ttfamily e\+P\+S\+Error\+\_\+\+C\+T\+I\+D\+S\+P\+\_\+\+U\+H\+P\+I\+Not\+Ready}   }\\\cline{1-2}
\end{TabularC}


\hypertarget{a00362_subsection__140xx_aax_host_errors}{}\subsubsection{-\/140xx\+: A\+A\+X Host errors}\label{a00362_subsection__140xx_aax_host_errors}
 These errors relate to logic failures in the A\+A\+X host software. These errors can be due to plug-\/in bugs or system configuration problems.

\begin{TabularC}{2}
\hline
\multicolumn{2}{|p{(\linewidth-\tabcolsep*2-\arrayrulewidth*1)*2/2}|}{\multirow{1}{\linewidth}{~\newline
   }}\\\cline{1-2}
\multicolumn{2}{|p{(\linewidth-\tabcolsep*2-\arrayrulewidth*1)*2/2}|}{\multirow{1}{\linewidth}{{\bfseries Table 2\+: A\+A\+X Host Software error codes}   }}\\\cline{1-2}
\multicolumn{2}{|p{(\linewidth-\tabcolsep*2-\arrayrulewidth*1)*2/2}|}{\multirow{1}{\linewidth}{~\newline
   }}\\\cline{1-2}
\rowcolor{lightgray}\multirow{1}{\linewidth}{{\bf Value  }}&\multirow{1}{\linewidth}{{\bf Definition   }}\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14001  }&\multirow{1}{\linewidth}{{\ttfamily k\+A\+A\+X\+H\+\_\+\+Result\+\_\+\+Warning}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14003  }&\multirow{1}{\linewidth}{{\ttfamily k\+A\+A\+X\+H\+\_\+\+Result\+\_\+\+Unsupported\+Platform}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14004  }&\multirow{1}{\linewidth}{{\ttfamily k\+A\+A\+X\+H\+\_\+\+Result\+\_\+\+Effect\+Not\+Registered}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14005  }&\multirow{1}{\linewidth}{{\ttfamily k\+A\+A\+X\+H\+\_\+\+Result\+\_\+\+Incomplete\+Instantiation\+Request}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14006  }&\multirow{1}{\linewidth}{{\ttfamily k\+A\+A\+X\+H\+\_\+\+Result\+\_\+\+No\+Shell\+Mgr\+Loaded}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14007  }&\multirow{1}{\linewidth}{{\ttfamily k\+A\+A\+X\+H\+\_\+\+Result\+\_\+\+Unknown\+Exception\+Loading\+T\+I\+Plug\+In}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14008  }&\multirow{1}{\linewidth}{{\ttfamily k\+A\+A\+X\+H\+\_\+\+Result\+\_\+\+Effect\+Components\+Missing}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14009  }&\multirow{1}{\linewidth}{{\ttfamily k\+A\+A\+X\+H\+\_\+\+Result\+\_\+\+Bad\+Legacy\+Plug\+In\+I\+D\+Index}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14010  }&\multirow{1}{\linewidth}{{\ttfamily k\+A\+A\+X\+H\+\_\+\+Result\+\_\+\+Effect\+Factory\+Inited\+Too\+Many\+Times}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14011  }&\multirow{1}{\linewidth}{{\ttfamily k\+A\+A\+X\+H\+\_\+\+Result\+\_\+\+Instance\+Not\+Found\+When\+Deinstantiating}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14012  }&\multirow{1}{\linewidth}{{\ttfamily k\+A\+A\+X\+H\+\_\+\+Result\+\_\+\+Failed\+To\+Register\+Effect\+Package}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14013  }&\multirow{1}{\linewidth}{{\ttfamily k\+A\+A\+X\+H\+\_\+\+Result\+\_\+\+Plug\+In\+Signature\+Not\+Valid}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14014  }&\multirow{1}{\linewidth}{{\ttfamily k\+A\+A\+X\+H\+\_\+\+Result\+\_\+\+Exception\+During\+Instantiation}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14015  }&\multirow{1}{\linewidth}{{\ttfamily k\+A\+A\+X\+H\+\_\+\+Result\+\_\+\+Shuffle\+Cancelled}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14016  }&\multirow{1}{\linewidth}{{\ttfamily k\+A\+A\+X\+H\+\_\+\+Result\+\_\+\+No\+Packet\+Target\+Registered}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14017  }&\multirow{1}{\linewidth}{{\ttfamily k\+A\+A\+X\+H\+\_\+\+Result\+\_\+\+Exception\+Reconnecting\+After\+Shuffle}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14018  }&\multirow{1}{\linewidth}{{\ttfamily k\+A\+A\+X\+H\+\_\+\+Result\+\_\+\+Effect\+Module\+Creation\+Failed}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14019  }&\multirow{1}{\linewidth}{{\ttfamily k\+A\+A\+X\+H\+\_\+\+Result\+\_\+\+Accessing\+Uninitialized\+Component}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14020  }&\multirow{1}{\linewidth}{{\ttfamily k\+A\+A\+X\+H\+\_\+\+Result\+\_\+\+T\+I\+Component\+Instantiation\+Postponed}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14021  }&\multirow{1}{\linewidth}{{\ttfamily k\+A\+A\+X\+H\+\_\+\+Result\+\_\+\+Failed\+To\+Register\+Effect\+Package\+Not\+Authorized}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14022  }&\multirow{1}{\linewidth}{{\ttfamily k\+A\+A\+X\+H\+\_\+\+Result\+\_\+\+Failed\+To\+Register\+Effect\+Package\+Wrong\+Architecture}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14023  }&\multirow{1}{\linewidth}{{\ttfamily k\+A\+A\+X\+H\+\_\+\+Result\+\_\+\+Plugin\+Built\+Against\+Incompatible\+S\+D\+K\+Version}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14023  }&\multirow{1}{\linewidth}{{\ttfamily k\+A\+A\+X\+H\+\_\+\+Result\+\_\+\+Plugin\+Built\+Against\+Incompatible\+S\+D\+K\+Version}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14100\textsuperscript{$\ast$}  }&\multirow{1}{\linewidth}{{\ttfamily k\+A\+A\+X\+H\+\_\+\+Result\+\_\+\+Invalid\+Argument\+Value}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14101\textsuperscript{$\ast$}  }&\multirow{1}{\linewidth}{{\ttfamily k\+A\+A\+X\+H\+\_\+\+Result\+\_\+\+Name\+Not\+Found\+In\+Page\+Table}   }\\\cline{1-2}
\end{TabularC}


\textsuperscript{$\ast$}Overlaps with \hyperlink{a00362_subsection__141xx_ti_system_errors}{-\/141xx\+: T\+I System errors} definitions

\hypertarget{a00362_subsection__141xx_ti_system_errors}{}\subsubsection{-\/141xx\+: T\+I System errors}\label{a00362_subsection__141xx_ti_system_errors}
 These errors relate to logic failures in the T\+I management software and generally indicate a failure in the H\+D\+X system services such as buffered message queues, context management, and callback timing.

\begin{TabularC}{2}
\hline
\multicolumn{2}{|p{(\linewidth-\tabcolsep*2-\arrayrulewidth*1)*2/2}|}{\multirow{1}{\linewidth}{~\newline
   }}\\\cline{1-2}
\multicolumn{2}{|p{(\linewidth-\tabcolsep*2-\arrayrulewidth*1)*2/2}|}{\multirow{1}{\linewidth}{{\bfseries Table 3\+: T\+I system error codes}   }}\\\cline{1-2}
\multicolumn{2}{|p{(\linewidth-\tabcolsep*2-\arrayrulewidth*1)*2/2}|}{\multirow{1}{\linewidth}{~\newline
   }}\\\cline{1-2}
\rowcolor{lightgray}\multirow{1}{\linewidth}{{\bf Value  }}&\multirow{1}{\linewidth}{{\bf Definition   }}\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14101  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Error\+Not\+Impl}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14102  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Error\+Memory}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14103  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Error\+Param}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14104  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Error\+Null}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14105  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Error\+Communication}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14106  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Error\+Illegal\+Access}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14107  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Error\+Direct\+Access\+Of\+Fifo\+Blocks\+Unsupported}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14108  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Error\+Port\+Id\+Out\+Of\+Bounds}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14109  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Error\+Port\+Type\+Does\+Not\+Support\+Direct\+Access}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14110  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Error\+F\+I\+F\+O\+Full}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14111  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Error\+R\+P\+C\+Time\+Out\+On\+D\+S\+P}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14112  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Error\+Shell\+Mgr\+Chip\+\_\+\+Segs\+Dont\+Match\+Addrs}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14113  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Error\+On\+Chip\+R\+P\+C\+Not\+Registered}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14114  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Error\+Unexpected\+Buffer\+Length}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14115  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Error\+Unexpected\+Entry\+Point\+Name}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14116  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Error\+Port\+I\+D\+Too\+Large\+For\+Context\+Block}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14117  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Error\+Mixer\+Delay\+Not\+Supported\+For\+Plug\+Ins}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14118  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Error\+Shell\+Failed\+To\+Start\+Up}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14119  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Error\+Unexpected\+Condition}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14120  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Error\+Shell\+Not\+Running\+When\+Expected}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14121  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Error\+Failed\+To\+Create\+New\+P\+I\+Instance}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14122  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Error\+Unknown\+P\+I\+Instance}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14123  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Error\+Too\+Many\+Instances\+For\+Single\+Buffer\+Processing}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14124  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Error\+No\+D\+S\+Ps}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14125  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Bad\+D\+S\+P\+I\+D}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14126  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Bad\+P\+I\+Context\+Write\+Block\+Size}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14128  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Instance\+Init\+Failed}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14129  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Same\+Module\+Loaded\+Twice\+On\+Same\+Chip}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14130  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Could\+Not\+Open\+Plug\+In\+Module}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14130  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Could\+Not\+Open\+Plug\+In\+Module}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14131  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Plug\+In\+Module\+Missing\+Dependcies}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14132  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Plug\+In\+Module\+Loadable\+Segment\+Count\+Mismatch}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14133  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Plug\+In\+Module\+Load\+Failure}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14134  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Out\+Of\+On\+Chip\+Debugging\+Space}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14135  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Missing\+Alg\+Entry\+Point}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14136  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Invalid\+Running\+Status}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14137  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Exception\+Running\+Instantiation}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14138  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+T\+I\+Shell\+Binary\+Not\+Found}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14139  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Timeout\+Waiting\+For\+T\+I\+Shell}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14140  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+Swap\+Script\+Timeout}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14141  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+T\+I\+D\+S\+P\+Module\+Not\+Found}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14142  }&\multirow{1}{\linewidth}{{\ttfamily e\+T\+I\+Sys\+T\+I\+D\+S\+P\+Read\+Error}   }\\\cline{1-2}
\end{TabularC}


\hypertarget{a00362_subsection__142xx_didl_errors}{}\subsubsection{-\/142xx\+: D\+I\+D\+L errors}\label{a00362_subsection__142xx_didl_errors}
 These errors all relate to the dynamic library loading system that manages E\+L\+F D\+L\+L binaries on Pro Tools H\+D\+X hardware. For example, a {\ttfamily e\+D\+I\+D\+L\+\_\+\+File\+Not\+Found} error will be raised if the E\+L\+F D\+L\+L name specified by an Effect\textquotesingle{}s Describe code does not match any D\+L\+L that is present in the plug-\/in\textquotesingle{}s bundle.

\begin{TabularC}{2}
\hline
\multicolumn{2}{|p{(\linewidth-\tabcolsep*2-\arrayrulewidth*1)*2/2}|}{\multirow{1}{\linewidth}{~\newline
   }}\\\cline{1-2}
\multicolumn{2}{|p{(\linewidth-\tabcolsep*2-\arrayrulewidth*1)*2/2}|}{\multirow{1}{\linewidth}{{\bfseries Table 4\+: D\+I\+D\+L error codes}   }}\\\cline{1-2}
\multicolumn{2}{|p{(\linewidth-\tabcolsep*2-\arrayrulewidth*1)*2/2}|}{\multirow{1}{\linewidth}{~\newline
   }}\\\cline{1-2}
\rowcolor{lightgray}\multirow{1}{\linewidth}{{\bf Value  }}&\multirow{1}{\linewidth}{{\bf Definition   }}\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14201  }&\multirow{1}{\linewidth}{{\ttfamily e\+D\+I\+D\+L\+\_\+\+File\+Not\+Found}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14202  }&\multirow{1}{\linewidth}{{\ttfamily e\+D\+I\+D\+L\+\_\+\+File\+Not\+Open}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14203  }&\multirow{1}{\linewidth}{{\ttfamily e\+D\+I\+D\+L\+\_\+\+File\+Already\+Open}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14204  }&\multirow{1}{\linewidth}{{\ttfamily e\+D\+I\+D\+L\+\_\+\+Invalid\+Elf\+File}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14205  }&\multirow{1}{\linewidth}{{\ttfamily e\+D\+I\+D\+L\+\_\+\+Image\+Not\+Found}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14206  }&\multirow{1}{\linewidth}{{\ttfamily e\+D\+I\+D\+L\+\_\+\+Symbol\+Not\+Found}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14207  }&\multirow{1}{\linewidth}{{\ttfamily e\+D\+I\+D\+L\+\_\+\+Dependency\+Not\+Loaded}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14208  }&\multirow{1}{\linewidth}{{\ttfamily e\+D\+I\+D\+L\+\_\+\+Bad\+Alignment}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14209  }&\multirow{1}{\linewidth}{{\ttfamily e\+D\+I\+D\+L\+\_\+\+Not\+Implemented}   }\\\cline{1-2}
\end{TabularC}


\hypertarget{a00362_subsection__144xx_hdx_hardware_errors}{}\subsubsection{-\/144xx\+: H\+D\+X hardware errors}\label{a00362_subsection__144xx_hdx_hardware_errors}
 These errors relate to failures on the H\+D\+X hardware itself. Plug-\/ins should never be able to trigger these error codes, which indicate low-\/level problems in the system.

\begin{TabularC}{2}
\hline
\multicolumn{2}{|p{(\linewidth-\tabcolsep*2-\arrayrulewidth*1)*2/2}|}{\multirow{1}{\linewidth}{~\newline
   }}\\\cline{1-2}
\multicolumn{2}{|p{(\linewidth-\tabcolsep*2-\arrayrulewidth*1)*2/2}|}{\multirow{1}{\linewidth}{{\bfseries Table 5\+: H\+D\+X hardware error codes}   }}\\\cline{1-2}
\multicolumn{2}{|p{(\linewidth-\tabcolsep*2-\arrayrulewidth*1)*2/2}|}{\multirow{1}{\linewidth}{~\newline
   }}\\\cline{1-2}
\rowcolor{lightgray}\multirow{1}{\linewidth}{{\bf Value  }}&\multirow{1}{\linewidth}{{\bf Definition   }}\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14401  }&\multirow{1}{\linewidth}{{\ttfamily e\+Berlin\+Image\+Error}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14402  }&\multirow{1}{\linewidth}{{\ttfamily e\+Berlin\+Image\+Write\+Error}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14403  }&\multirow{1}{\linewidth}{{\ttfamily e\+Berlin\+Invalid\+Args}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14404  }&\multirow{1}{\linewidth}{{\ttfamily e\+Berlin\+Cant\+Get\+T\+M\+S\+Channel}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14405  }&\multirow{1}{\linewidth}{{\ttfamily e\+Berlin\+Chunk\+Write\+Error}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14406  }&\multirow{1}{\linewidth}{{\ttfamily e\+Berlin\+Chunk\+Read\+Error}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14407  }&\multirow{1}{\linewidth}{{\ttfamily e\+Berlin\+Invalid\+Req\+I\+D}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14408  }&\multirow{1}{\linewidth}{{\ttfamily e\+Berlin\+D\+S\+P\+In\+Reset\+Error}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14409  }&\multirow{1}{\linewidth}{{\ttfamily e\+Berlin\+D\+S\+P\+Time\+Out}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14410  }&\multirow{1}{\linewidth}{{\ttfamily e\+Berlin\+Incorrect\+Tdm\+Cable\+Wiring}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14411  }&\multirow{1}{\linewidth}{{\ttfamily e\+Berlin\+Invalid\+Clock}   }\\\cline{1-2}
\end{TabularC}


\hypertarget{a00362_subsection__145xx_dhm_isochronous_audio_engine_errors}{}\subsubsection{-\/145xx\+: D\+H\+M isochronous audio engine errors}\label{a00362_subsection__145xx_dhm_isochronous_audio_engine_errors}
 These errors relate to failures within the H\+D\+X audio engine software. Plug-\/ins should never be able to trigger these error codes, which indicate low-\/level problems in the system.

\begin{TabularC}{2}
\hline
\multicolumn{2}{|p{(\linewidth-\tabcolsep*2-\arrayrulewidth*1)*2/2}|}{\multirow{1}{\linewidth}{~\newline
   }}\\\cline{1-2}
\multicolumn{2}{|p{(\linewidth-\tabcolsep*2-\arrayrulewidth*1)*2/2}|}{\multirow{1}{\linewidth}{{\bfseries Table 6\+: D\+H\+M isochronous audio engine error codes}   }}\\\cline{1-2}
\multicolumn{2}{|p{(\linewidth-\tabcolsep*2-\arrayrulewidth*1)*2/2}|}{\multirow{1}{\linewidth}{~\newline
   }}\\\cline{1-2}
\rowcolor{lightgray}\multirow{1}{\linewidth}{{\bf Value  }}&\multirow{1}{\linewidth}{{\bf Definition   }}\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14500  }&\multirow{1}{\linewidth}{{\ttfamily e\+Dsi\+Isoch\+Engine\+Generic\+Error}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14501  }&\multirow{1}{\linewidth}{{\ttfamily e\+Dsi\+Isoch\+Engine\+Wrong\+Channel\+Number}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14502  }&\multirow{1}{\linewidth}{{\ttfamily e\+Dsi\+Isoch\+Engine\+Tx\+Ring\+Full}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14503  }&\multirow{1}{\linewidth}{{\ttfamily e\+Dsi\+Isoch\+Engine\+Rx\+Ring\+Not\+Ready}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14504  }&\multirow{1}{\linewidth}{{\ttfamily e\+Dsi\+Isoch\+Engine\+Wrong\+Number\+Of\+Samples\+Request}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14505  }&\multirow{1}{\linewidth}{{\ttfamily e\+Dsi\+Isoch\+Engine\+Unrecognized\+Sample\+Rate}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14506  }&\multirow{1}{\linewidth}{{\ttfamily e\+Dsi\+Isoch\+Engine\+Unsupported\+Sample\+Size\+Bytes}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14507  }&\multirow{1}{\linewidth}{{\ttfamily e\+Dsi\+Isoch\+Engine\+Unsupported\+Number\+Of\+Channels}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14508  }&\multirow{1}{\linewidth}{{\ttfamily e\+Dsi\+Isoch\+Engine\+Unsupported\+Sample\+Rate}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14509  }&\multirow{1}{\linewidth}{{\ttfamily e\+Dsi\+Isoch\+Engine\+D\+M\+A\+Already\+Enabled}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14510  }&\multirow{1}{\linewidth}{{\ttfamily e\+Dsi\+Isoch\+Engine\+D\+M\+A\+Already\+Disabled}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14511  }&\multirow{1}{\linewidth}{{\ttfamily e\+Dsi\+Isoch\+Engine\+Interrupt\+Handler\+Already\+Installed}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14512  }&\multirow{1}{\linewidth}{{\ttfamily e\+Dsi\+Isoch\+Engine\+Bad\+Card\+Record}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14513  }&\multirow{1}{\linewidth}{{\ttfamily e\+Dsi\+Isoch\+Engine\+Cant\+Set\+Value\+During\+Streaming}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14514  }&\multirow{1}{\linewidth}{{\ttfamily e\+Dsi\+Isoch\+Engine\+Streaming\+Already\+Started}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14515  }&\multirow{1}{\linewidth}{{\ttfamily e\+Dsi\+Isoch\+Engine\+Streaming\+Already\+Stopped}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14516  }&\multirow{1}{\linewidth}{{\ttfamily e\+Dsi\+Isoch\+Engine\+Streaming\+Cant\+Be\+Started}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14517  }&\multirow{1}{\linewidth}{{\ttfamily e\+Dsi\+Isoch\+Engine\+Unsupported\+Samples\+Per\+Interrupt}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14518  }&\multirow{1}{\linewidth}{{\ttfamily e\+Dsi\+Isoch\+Engine\+Cant\+Set\+Samples\+Per\+Interrupt}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14519  }&\multirow{1}{\linewidth}{{\ttfamily e\+Dsi\+Isoch\+Engine\+Interrupt\+Loop\+Already\+Exists}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14520  }&\multirow{1}{\linewidth}{{\ttfamily e\+Dsi\+Isoch\+Engine\+Global\+D\+M\+A\+Disabled}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14521  }&\multirow{1}{\linewidth}{{\ttfamily e\+Dsi\+Isoch\+Engine\+Active\+Interrupt\+Mask\+Already\+Enabled}   }\\\cline{1-2}
\multirow{1}{\linewidth}{-\/14522  }&\multirow{1}{\linewidth}{{\ttfamily e\+Dsi\+Isoch\+Engine\+S\+D\+I0\+Errors}   }\\\cline{1-2}
\end{TabularC}


\hypertarget{a00362_subsection__30xxx_dynamic_error_codes}{}\subsubsection{-\/30xxx\+: Dynamically-\/generated error codes}\label{a00362_subsection__30xxx_dynamic_error_codes}
 Errors in the -\/30xxx range are dynamically generated codes, and thus the same failure point could generate a different error code depending on the order in which errors occurred. These kinds of error codes are used heavily by the T\+I Shell Manager, the host component that interacts with the onâ€“\+D\+S\+P shell environment.

If one of these error codes is being generated by the T\+I Shell Manager (the most common case) then you should be able to get more information about the failure by enabling the following \hyperlink{a00364}{Digi\+Trace} logging facility\+:

{\ttfamily D\+T\+F\+\_\+\+T\+I\+S\+H\+E\+L\+L\+M\+G\+R=file@D\+T\+P\+\_\+\+N\+O\+R\+M\+A\+L}

or, within the D\+S\+H tool\+:

{\ttfamily enable\+\_\+trace\+\_\+facility \mbox{[}D\+T\+F\+\_\+\+T\+I\+S\+H\+E\+L\+L\+M\+G\+R, D\+T\+P\+\_\+\+N\+O\+R\+M\+A\+L\mbox{]}}

This should result in a log with more information such as the name of the failing plug-\/in, the dynamically generated error code, and a string description of its meaning. Depending on the failure case, the D\+A\+E dish command {\ttfamily getlastdsploaderror} can also sometimes be used to retrieve the description string for a dynamically-\/generated error if it was the last error generated during the D\+S\+P loading operation.

 Collaboration diagram for T\+I Guide\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=265pt]{a00362}
\end{center}
\end{figure}
